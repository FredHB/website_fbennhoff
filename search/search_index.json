{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Biography","text":""},{"location":"#about-head","title":"Frederik Bennhoff","text":"<p>PhD Candidate in Economics</p> <p>University of Z\u00fcrich</p> <p> </p>"},{"location":"#at-a-glance","title":"at a glance","text":"<p>I am a PhD candidate in Economics at the University of Zurich (UZH) and I hold a MPhil in Economic Research from the University of Cambridge. In Fall 2024, I have been a visiting PhD at the London School of Economics (host: Johannes Spinnewijn), and I am currently (2025) researching at the Dutch National Bank (DNB) as a PhD intern. I will visit Paris School of Economics in Spring 2026 (host: Gabriel Zucman). My supervisors at UZH are Florian Scheuer and Felix K\u00fcbler.</p> <p>I work on two strands of research: First, bringing together fields of public finance and traditional finance, and second, understanding firms in the macro-economy. I will be on the job market in 2026. </p>"},{"location":"#research-summary","title":"research summary","text":"<p>I spend half of my time working on novel ways to understand the wealth and tax implications of capital gains. Understanding how households build wealth through investment, and how these investments are shaped by tax policy, has strong implications on how extreme wealth and poverty persists across generations. In my job market paper (w.i.p.), I show how to asset choices are distorted by capital gains taxation systems, and how having access to sufficiently rich capital markets allows undermining capital gains taxation. In a related project with Florian Scheuer we are modeling how the practice of forgiving capital gains taxes at the time of death of the original owner affects portfolio choices, and renders capital gains taxes regressive. We show how some (widely discussed) changes in the tax code can undo regressivity, without provoking strong behavioral responses. Finally, jointly with Lorenzo Ranaldi, Moritz Kuhn and Florian Scheuer, we examine the Dutch Household Survey. Our goal is to elicit the mechanisms through which households gain from investments.</p> <p>I use the other half to examine the link between firm behavior and aggregate output. Igli Bajo, Alessandro Ferrari and I are shedding light on theoretical and empirical underpinnings of macroeconomic cleansing effects. We research under what conditions firm exit induced by a crisis can improve long-run productivity. Additionally, together with Timo Haber and Niklas Schmitz, I am uncovering firm-level reactions to shocks. We show that left-skewed responses to shocks are driven by the reactions of large firms, and prove a tight theoretical relationship between such skewness and firm market power. </p> <p>During 2019-2021 I was an economist (pre-doctoral fellow) at the Center for the Economics of Human Development at University of Chicago for Prof. James J. Heckman. My research from this period was mainly focused on labor economics and the evaluation of social programs.</p> <p></p>"},{"location":"courses/bmetrics/","title":"Bayesian Econometrics","text":"<p>This course is targeted at PhD students and practitioners, who would like to use Python to deploy state-of-the-art Bayesian econometric models for their (Macro-)economic research.</p> <p>The github page associated with the course can be found here: </p> <p></p>"},{"location":"courses/bmetrics/BayReg/","title":"Bayesian Regression","text":"<p>In this notebook we write a module suitable for two essential Bayesian Regression models. A linear regression model with the natural conjugate prior and a linear regression model with the independent Normal-Gamma prior over regression coefficients \\beta and regression precision (inverse standard deviation), h.</p> <p>Here is a list of functionalities we wish to implement in this course:</p> <ol> <li>Given a dataset (y, X), calculate the posterior distribution of \\beta for the natural conjugate and the independent NG prior.</li> <li>To do (1), implement a Gibbs sampler of the posterior for any function f(\\beta | y) since the NG prior cannot be handled analytically</li> <li>Since analytical results for the natural conjugate are possible, include methods to obtain these</li> <li>Include prediction methods for \\hat y |y, X.</li> <li>Allow for heteroskedasticity in the errors.</li> </ol>"},{"location":"courses/bmetrics/BayReg/#writing-down-a-bayesian-regression-model","title":"Writing down a Bayesian Regression Model","text":"<p>The baseline model is (\\mathrm{dim}(\\beta) = k) </p>      y = X\\beta + w, w \\sim N(0_N, h^{-1} I_N)  <p>where by convention, X first column are ones. We use the model from Bayesian Econometric Methods by Gary Koop, Dale J. Poirier, and Justin L. Tobias.</p> <p>We make the following definitions, where \\nu is the degrees of freedom, \\hat \\beta is the OLS estimate of \\beta and s^2 is the OLS estimate of the variance: </p>   \\begin{align*}     \\nu = N - k \\\\     \\hat{\\beta} = (X'X)^{-1} X'y, \\\\     s^2 = \\frac{(y - X\\hat{\\beta})'(y - X\\hat{\\beta})}{\\nu}. \\end{align*}  <p>Then, the likelihood of the data given h, \\beta is</p>      p(y|\\beta, h) = \\frac{1}{(2\\pi)^{K/2}}     \\left\\{     h^{k/2} \\exp\\left[-\\frac{h}{2} (\\beta - \\hat{\\beta})' X'X (\\beta - \\hat{\\beta})\\right]     \\right\\}     \\left\\{     h^{\\nu/2} \\exp\\left[-\\frac{h \\nu}{2 s^2}\\right]     \\right\\} \\\\     \\propto \\left\\{     h^{k/2} \\exp\\left[-\\frac{h}{2} (\\beta - \\hat{\\beta})' X'X (\\beta - \\hat{\\beta})\\right]     \\right\\}     \\left\\{     h^{\\nu/2} \\exp\\left[-\\frac{h \\nu}{2 s^2}\\right]     \\right\\}.  <p>Task [concentrated likelihood]: </p> <p>Write a function to compute the concentrated log-likelihood for \\beta without the scaling term. One obtains a concentrated likelihood by substuting out other parameters for their maximum-likelihood estimate.</p> <pre><code>import numpy as np\nfrom numba import jit, njit, prange\n# simulate some data\nX = np.random.rand(1000, 3)\nX[:, 0] = 1. # intercept\nbeta = np.array([1, 2, 3], dtype=np.float64)\ny = X @ beta + np.random.normal(0, 1, size =1000)\n</code></pre> <p>Solution [concentrated likelihood]: </p> <p>First, note that the MLE of \\sigma^2 = h^{-1} is s^2. Find the MLE of  \\sigma^2  conditional on  \\beta :</p>  \\hat{\\sigma}^2(\\beta) = \\frac{(y - X\\beta){\\prime}(y - X\\beta)}{N}.  <p>Now, substitute \\hat{\\sigma}^2(\\beta) back into the likelihood:</p>      p(y | \\beta) = \\frac{1}{(2\\pi)^{N/2}} \\left(\\frac{1}{\\hat{\\sigma}^2(\\beta)}\\right)^{N/2} \\exp\\left(-\\frac{1}{2\\hat{\\sigma}^2(\\beta)} (y - X\\beta){\\prime}(y - X\\beta)\\right).  <p>Then  $$     p(y | \\beta) \\propto \\left((y - X\\beta)^{\\prime}(y - X\\beta)\\right)^{-N/2}. $$</p> <pre><code>@jit(nopython=True)\ndef ols_solution(X, y):\n    N = y.shape[0]\n    K = X.shape[1]\n    XX = X.T @ X\n    nu = N - K\n    beta_hat = np.linalg.solve(XX, X.T @ y)\n    s_sq = 1/nu * (y - X @ beta_hat).T @ (y - X @ beta_hat)\n    return beta_hat, s_sq, nu, N, K, XX\n\n\n@jit(nopython=True)\ndef clhood_beta(beta, y, X):\n    N = y.shape[0]\n    ssr = (y - X @ beta).T @ (y - X @ beta)\n    return (np.log(ssr))*(-N/2)\n</code></pre> <pre><code># try it out\nbeta_hat, s_sq, nu, N, K, XX = ols_solution(X, y)\nprint(f'ols beta_hat: {beta_hat}')\nclhood_beta(beta, y, X)\nprint(f'concentrated log-likelihood: {clhood_beta(beta_hat, y, X)}')\n</code></pre> <pre><code>ols beta_hat: [0.86907181 2.14332413 3.06126176]\nconcentrated log-likelihood: -3450.6575608188514\n</code></pre>"},{"location":"courses/bmetrics/BayReg/#the-natural-conjugate-prior","title":"The Natural Conjugate Prior","text":"<p>We begin with a natural normal-gamma conjugate prior. This means:</p> <ul> <li>\\beta conditional on h is multivariate Normal:</li> </ul> \\beta | h \\sim N(\\underline\\beta, h^{-1} \\underline V) <ul> <li>Prior for error precision, h, is Gamma:  </li> </ul> h \\sim G(\\underline s^{-2}, \\underline \\nu) <p>Note that we parametrize the Gamma distribution in terms of mean and degrees of freedom: \\underline s^{-2} and \\underline \\nu, respectively.</p> <ul> <li>One writes for Normal-Gamma distribution:</li> </ul> \\beta, h \\sim NG\\left(\\underline \\beta, \\underline V, \\underline s^{-2}, \\underline \\nu\\right) <ul> <li>\\underline \\beta, \\underline V, \\underline s^{-2}, and \\underline \\nu are prior hyperparameter values chosen by the researcher.</li> </ul> <p>The posterior for the NG-prior is:</p> \\beta, h | y \\sim NG\\left(\\overline{\\beta}, \\overline{V}, \\overline{s}^{-2}, \\overline{\\nu}\\right), <p>where: </p> \\begin{align*}\\overline{V} &amp;= \\left(\\underline V^{-1} + X'X\\right)^{-1}, \\\\   \\overline{\\beta} &amp;= \\overline{V} \\left(\\underline V^{-1}\\beta + X'X\\hat{\\beta}\\right), \\\\   \\overline{\\nu} &amp;= \\underline\\nu + N   \\end{align*}  <p>And \\overline{s}^{-2} is defined through:  </p> \\overline{s}^2 = \\frac{\\underline\\nu \\underline s^2 + \\nu s^2 + (\\hat{\\beta} - \\beta)' \\left[\\underline V + (X'X)^{-1}\\right]^{-1} (\\hat{\\beta} - \\beta)}{\\overline{\\nu}}. <p>Task [natural conjugate posterior]:</p> <p>Write a function to obtain the posterior parameters \\overline V, \\overline \\beta, \\overline \\nu, \\overline{s}^2</p> <p>Definition (gamma distribution).</p> <p>A continuous random variable Y has a gamma distribution with mean \\mu &gt; 0 and degrees of freedom \\nu &gt; 0, denoted by Y \\sim \\gamma(\\mu, \\nu), if its p.d.f. is:</p>  f_\\gamma(y | \\mu, \\nu) \\equiv  \\begin{cases}      c_\\gamma^{-1} y^{\\frac{\\nu}{2} - 1} \\exp\\left(-\\frac{y \\nu}{2\\mu}\\right), &amp; \\text{if } 0 &lt; y &lt; \\infty, \\\\     0, &amp; \\text{otherwise}, \\end{cases}  <p>where the integrating constant is given by:</p>  c_\\gamma = \\left(\\frac{2\\mu}{\\nu}\\right)^{\\frac{\\nu}{2}} \\Gamma\\left(\\frac{\\nu}{2}\\right),  <p>and \\Gamma(a) is the Gamma function (see Poirier, 1995, p. 98).</p> <pre><code># some dummy parameters\nnuprior = 500\nVprior_inv = np.eye(K)\ns_sqprior = 1\nbeta_prior = np.zeros(K)\n\n@jit(nopython=True)\ndef posterior_params(beta_prior, Vprior_inv, s_sqprior, nuprior, beta_hat, s_sq, nu, N, XX):\n    K = XX.shape[0]\n    Vpost_inv = Vprior_inv + XX\n    beta_post = np.linalg.solve(Vpost_inv, Vprior_inv @ beta_prior + XX @ beta_hat)\n    nupost = nuprior + N\n    s_sqpost = (nuprior * s_sqprior \\\n        + nu * s_sq \\\n        + (beta_hat - beta_prior).T @ Vprior_inv \\\n        @ np.linalg.solve(np.eye(K) + np.linalg.inv(Vprior_inv @ XX), (beta_hat - beta_prior))\n        ) / nupost\n    return beta_post,Vpost_inv, s_sqpost, nupost\n\nbetapost, Vpost_inv, s_sqpost, nupost = posterior_params(beta_prior, Vprior_inv, s_sqprior, nuprior, beta_hat, s_sq, nu, N, XX)\n</code></pre> <pre><code>%%timeit\nposterior_params(beta_prior, Vprior_inv, s_sqprior, nuprior, beta_hat, s_sq, nu, N, XX)\n</code></pre> <pre><code>3.69 \u03bcs \u00b1 345 ns per loop (mean \u00b1 std. dev. of 7 runs, 100,000 loops each)\n</code></pre> <p>The marginal posterior for \\beta: is a multivariate t-distribution</p> \\beta | y \\sim t\\left(\\overline{\\beta}, \\overline{s}^2 \\overline{V}, \\overline{\\nu}\\right). <p>For such holds </p> E(\\beta | y) = \\overline{\\beta} <p>and</p> \\text{var}(\\beta | y) = \\frac{\\overline{\\nu} \\overline{s}^2}{\\overline{\\nu} - 2} \\overline{V}. <p>Intuition: Posterior mean and variance are a weighted average of information in the prior and the data.</p> <p>Task [marginal posterior]:</p> <p>Write a function which will compute the marginal posterior for \\beta.</p> <pre><code>from scipy.stats import multivariate_t\ndef mposterior_beta(betapost, Vpost_inv, s_sq, nupost):\n    Vpost =  np.linalg.inv(Vpost_inv)\n    t = multivariate_t(betapost, s_sq *Vpost, df=nupost)\n    betapost_var = nupost * s_sq * Vpost/(nupost - 2) # variance of the t-distribution\n    return betapost, betapost_var, t, Vpost # mean, variance, t-distribution, covariance matrix of posterior\n\n# check that it works\nmposterior_beta(betapost, Vpost_inv, s_sqpost, nupost)\n</code></pre> <pre><code>(array([0.89285165, 2.12517763, 3.03015342]),\n array([[ 0.00671138, -0.00550244, -0.00587363],\n        [-0.00550244,  0.01109588, -0.00023851],\n        [-0.00587363, -0.00023851,  0.01206552]]),\n &lt;scipy.stats._multivariate.multivariate_t_frozen at 0x157873640&gt;,\n array([[ 0.00666605, -0.00546527, -0.00583395],\n        [-0.00546527,  0.01102093, -0.0002369 ],\n        [-0.00583395, -0.0002369 ,  0.01198402]]))\n</code></pre> <p>Finally, we wish to initialize the regression model with a diffuse prior: \\underline{V} = c I_K with c large. We modularize our regression model to handle instances of it better.</p> <p>Task [<code>BayesianRegressionNC</code> class]:</p> <ol> <li> <p>Write a class <code>BayesianRegressionNC</code> which features methods <code>set_prior</code>, <code>get_posterior</code> and <code>get_mposterior</code> which set the prior, and calculate posterior and marginal posterior, respectively, for the natural conjugate. Make use of the <code>ols_solution</code> function whenever you can, and use <code>multivariate_t</code> from the <code>scipy</code> library.</p> </li> <li> <p>Add a <code>predict</code> method which takes a matrix <code>X_new</code> as input.</p> </li> </ol> <pre><code>class BayesianRegressionNC():\n    def __init__(self, y, X):\n        \"\"\"Initialize the class with data\n        y: the dependent variable\n        X: the independent variables\n        \"\"\"\n        self.y = y\n        self.X = X\n        self.beta_hat, self.s_sq, self.nu, self.N, self.K, self.XX = ols_solution(X, y)\n        self.ols = {\n            'beta': self.beta_hat,\n            's_sq': self.s_sq,\n            'nu': self.nu\n        }\n        self.prior = {\n            'beta': None,\n            'nu': None,\n            's_sq': None,\n            'V_inv': None\n        }\n        self.posterior = { # posterior for beta and h\n            'beta': None,\n            'V_inv': None,\n            's_sq': None,\n            'nu': None\n        }\n        self.mposterior = { # marginal posterior for beta\n            'beta': None,\n            'beta_var': None,\n            't': None,\n            'V': None\n        }\n        #self.betaprior, self.nuprior, self.s_sqprior, self.Vprior_inv = None, None, None, None\n\n    def set_prior(self, betaprior, Vprior_inv, s_sqprior, nuprior):\n        \"\"\"Set the prior parameters\"\"\"\n        self.prior = {\n            'beta': betaprior,\n            'nu': nuprior,\n            's_sq': s_sqprior,\n            'V_inv': Vprior_inv\n        }\n\n    def get_posterior(self):\n        \"\"\"Set the posterior parameters\"\"\"\n        betaprior = self.prior['beta']\n        Vprior_inv = self.prior['V_inv']\n        s_sqprior = self.prior['s_sq']\n        nuprior = self.prior['nu']\n\n        betapost, Vpost_inv, s_sqpost, nupost = posterior_params(betaprior, Vprior_inv, s_sqprior, nuprior, self.beta_hat, self.s_sq, self.nu, self.N, self.XX)\n        self.posterior = {\n            'beta': betapost,\n            'V_inv': Vpost_inv,\n            's_sq': s_sqpost,\n            'nu': nupost\n        }\n\n    def get_mposterior(self):\n        \"\"\"Set the marginal posterior parameters\"\"\"\n        betapost, Vpost_inv, s_sqpost, nupost = self.posterior['beta'], self.posterior['V_inv'], self.posterior['s_sq'], self.posterior['nu']\n        betapost, betapost_var, t, Vpost = mposterior_beta(betapost, Vpost_inv, s_sqpost, nupost)\n        self.mposterior = {\n            'beta': betapost,\n            'beta_var': betapost_var,\n            't': t,\n            'V': Vpost\n        }\n\n    def predict(self,Xnew):\n        \"\"\"Predict the dependent variable for new data using the posterior\"\"\"\n        mean = Xnew @ self.mposterior['beta']\n        s_sq, nu = self.posterior['s_sq'], self.posterior['nu']\n        V = s_sq * (np.eye(Xnew.shape[0]) + Xnew @ np.linalg.inv(self.posterior['V_inv']) @ Xnew.T)\n        predictions = {\n            'y_hat': mean,\n            'V': V,\n            't': multivariate_t(mean, V, df=nu)\n        }\n        return predictions\n</code></pre> <p>Let\u2019s try out the new class. Set a diffuse prior, and obtain posterior and marginal posterior. Play around with the code to ensure that when setting the diffuse prior, the posterior mean approaches the OLS solution.</p> <pre><code>## initialize the class\nbmod = BayesianRegressionNC(y, X)\n\n## set the prior\nbmod.set_prior(np.zeros(X.shape[1]), \n               np.eye(X.shape[1])*1E-5, \n               1, \n               0)\n\n## get the posterior given y and X\nbmod.get_posterior()\n\n## get the marginal posterior for beta\nbmod.get_mposterior()\n\n## check the results\nprint(bmod.posterior, bmod.mposterior, bmod.ols, bmod.prior)\n\n## prediction\nXnew = np.random.rand(2, 3)\npredictions = bmod.predict(Xnew)\nprint(predictions)\n</code></pre> <pre><code>{'beta': array([0.86907205, 2.14332394, 3.06126144]), 'V_inv': array([[1000.00001   ,  507.08542046,  497.32198302],\n       [ 507.08542046,  346.65378599,  253.72723223],\n       [ 497.32198302,  253.72723223,  329.56200832]]), 's_sq': 0.9935805373327228, 'nu': 1000} {'beta': array([0.86907205, 2.14332394, 3.06126144]), 'beta_var': array([[ 0.00674628, -0.00553757, -0.00591707],\n       [-0.00553757,  0.01112504, -0.00020868],\n       [-0.00591707, -0.00020868,  0.01211065]]), 't': &lt;scipy.stats._multivariate.multivariate_t_frozen object at 0x4bde56230&gt;, 'V': array([[ 0.00677629, -0.0055622 , -0.00594339],\n       [-0.0055622 ,  0.01117453, -0.00020961],\n       [-0.00594339, -0.00020961,  0.01216452]])} {'beta': array([0.86907181, 2.14332413, 3.06126176]), 's_sq': 0.9965702467624876, 'nu': 997} {'beta': array([0., 0., 0.]), 'nu': 0, 's_sq': 1, 'V_inv': array([[1.e-05, 0.e+00, 0.e+00],\n       [0.e+00, 1.e-05, 0.e+00],\n       [0.e+00, 0.e+00, 1.e-05]])}\n{'y_hat': array([4.6031991 , 2.62950475]), 'V': array([[0.99743727, 0.00130722],\n       [0.00130722, 0.99907623]]), 't': &lt;scipy.stats._multivariate.multivariate_t_frozen object at 0x4bded7dc0&gt;}\n</code></pre>"},{"location":"courses/bmetrics/BayReg/#prediction-and-monte-carlo-integration","title":"Prediction and Monte Carlo Integration","text":"<p>We now wish to calculate the probability of the some event by Monte Carlo integration, e.g.</p>  Pr(\\hat{y}(X^*_1) \\in A | X).  <p>Consider for example the case where</p>  A = [0.9\\cdot \\hat{y}(X^*_2), 1.5 \\cdot \\hat{y}(X^*_2)]. <p>We now write a quick Monte-Carlo method to simulate this probability from our predictive density.</p> <pre><code># First, simulate some predictions from the model\nsims = predictions['t'].rvs(100_000)\n\n# Second, calculate a boolean vector that is True if the first element is in A\nbool = (sims[:, 0] &gt; sims[:, 1]*0.9) * (sims[:, 0] &lt; sims[:, 1]*1.5)\n\n# Third, calculate the proportion of True values\np = bool.mean()\nprint(\"Prob(A):\", p)\n</code></pre> <pre><code>Prob(A): 0.3087\n</code></pre> <p>To finish this section, also plot the simulations and mark the draws which fall into A.</p> <pre><code>import matplotlib.pyplot as plt\nn_plot = 10_000\nfig, ax = plt.subplots(1,1)\nax.scatter(sims[:n_plot, 0], sims[:n_plot, 1], marker='.', alpha=0.1, c=bool[:n_plot])\nax.set_title('Simulated posterior predictive distribution')\nax.set_xlabel(r'$\\hat{y}(X^*_1)$')\nax.set_ylabel(r'$\\hat{y}(X^*_2)$')\nplt.show()\n</code></pre> <p></p>"},{"location":"courses/bmetrics/BayReg/#independent-normal-gamma-priors-and-heteroskedastic-errors","title":"Independent Normal-Gamma Priors and Heteroskedastic Errors","text":""},{"location":"courses/bmetrics/BayReg/#model-set-up","title":"Model Set-Up","text":"<p>Keeping the Normal linear regression model, we now assume independence of \\beta, h. As a consequence, the posterior will not have a closed form solution anymore, and we will need to write a routine - the Gibbs sampler - which allows us to draw samples from the posterior. We also include heteroskedasticity by intrducing a random diagonal matrix, \\Omega. That is,</p>      \\epsilon \\sim N(0_N, h^{-1}\\Omega)  <p>Now assume that </p>      p(\\beta, h, \\Omega) = p(\\beta)p(h)p(\\Omega)  <p>with</p>      \\beta \\sim N(\\underline \\beta, \\underline V), \\\\     h \\sim G(\\underline s^2, \\underline \\nu), \\\\     \\Omega = diag(\\lambda_1^{-1}, ..., \\lambda_N^{-1}), \\\\     p(\\lambda) = \\prod_i f_G(\\lambda_i | 1, \\nu_\\lambda),  <p>where f_G is the Gamma pdf. The difference to the natural conjugate prior is that \\underline V is now the prior covariance of \\beta, independent of h.</p> <p>Parameter-Posteriors</p> <p>The joint posterior of \\beta, h does not take form of a nice, closed form density. However, the conditional posterior for \\beta can be written as</p>      \\beta | y, h, \\Omega \\sim N(\\overline \\beta,\\overline V),   <p>where</p>      \\overline V = \\big( \\underline V^{-1} + h X'\\Omega^{-1}X \\big)^{-1}, \\\\     \\overline \\beta  = \\overline V \\big( \\underline V^{-1} \\underline\\beta + h X'\\Omega^{-1}X\\hat{\\beta}(\\Omega) \\big).  <p>\\hat{\\beta}(\\Omega) is the GLS estimator. The conditional posterior for h takes a simple form, too:  </p>      h | y, \\beta, \\Omega \\sim G\\left(\\overline{s}^{-2}, \\overline{\\nu}\\right)  <p>where:  </p>      \\overline{\\nu} = N + \\underline\\nu  <p>and:  </p>      \\overline{s}^2 = \\frac{(y - X\\beta)'(y - X\\beta) + \\underline\\nu \\underline s^2}{\\overline{\\nu}}  <p>Generally, the conditional posterior for \\Omega is given by</p>      p(\\Omega | y,\\beta, h) \\propto p(\\Omega) |\\Omega|^{-\\frac{1}{2}} \\exp\\big( - \\frac{h}{2} (y - X\\beta)'\\Omega^{-1}(y - X\\beta) \\big).  <p>In the model with Gamma distributed \\lambda_i, one obtains </p>      p(\\lambda_i | y, h, \\beta, \\nu_\\lambda) = f_G\\bigg( \\lambda_i \\big| \\frac{\\nu_\\lambda + 1}{h \\epsilon_i^2 + \\nu_\\lambda}, \\nu_\\lambda +1  \\bigg)  <p>The conditional posteriors do not directly tell us about p(\\beta, h, \\Omega | y). Because we are interested in p(\\beta, h | y) (or p(\\beta | y) and p(h | y)), and not the posterior conditionals, we use a posterior simulator, called the Gibbs sampler, which uses conditional posteriors to produce random draws, \\beta^{(s)} and h^{(s)} for s = 1, \\dots, S. (For a formal introduction to the Gibbs sampler, the Wikipedia article is helpful.) These can be averaged to produce estimates of posterior properties just as with Monte Carlo integration.</p>"},{"location":"courses/bmetrics/BayReg/#hyperparameters-and-m-h-random-walk","title":"Hyperparameters and M-H Random Walk","text":"<p>The parameter \\nu_\\lambda is a hyperparameter, to which we assign a prior, too. One can show that if it follows an exponential prior, then its posterior density is, up to a constant factor: </p>      p(\\nu_\\lambda | y, \\beta, h, \\lambda) \\propto \\left(\\frac{\\nu_\\lambda}{2}\\right)^{\\frac{N \\nu_\\lambda}{2}} \\Gamma\\left(\\frac{\\nu_\\lambda}{2}\\right)^{-N} \\exp(-\\eta \\nu_\\lambda),  <p>where</p>      \\eta = \\frac{1}{\\underline \\nu_\\lambda} + 0.5 \\sum_{i=1}^{N} (-\\ln(\\lambda_i) + \\lambda_i).  <p>The obvious question is: How can we sample from p(\\nu_\\lambda | y, \\beta, h, \\lambda)? To do so, we us a Metropolis-Hastings Random Walk algorithm (MHRW). The Metropolis-Hastings random walk algorithm is a Markov Chain Monte Carlo (MCMC) method used to generate samples from a probability distribution when direct sampling is difficult. In general terms, the algorithm aims to sample from a target distribution $ \\pi(x) $ when its normalization constant is unknown or intractable.</p> <p>Algorithm Steps</p> <ol> <li> <p>Initialize: Start at an initial state x_0.</p> </li> <li> <p>Proposal Step: Generate a proposed new state x' using a proposal distribution q(x' | x), often symmetric (e.g., a normal distribution centered at the current state).    $$    x\u2019 = x + \\epsilon \\quad \\text{where } \\epsilon \\sim N(0, \\sigma^2)    $$</p> </li> <li> <p>Acceptance Probability: Compute the acceptance ratio:    $$    \\alpha = \\min\\left(1, \\frac{\\pi(x\u2019) \\cdot q(x | x\u2019)}{\\pi(x) \\cdot q(x\u2019 | x)}\\right)    $$  </p> </li> </ol> <p>For symmetric proposal distributions where q(x' | x) = q(x | x'), this simplifies to:  </p> <p>$$    \\alpha = \\min\\left(1, \\frac{\\pi(x\u2019)}{\\pi(x)}\\right)    $$</p> <ol> <li>Accept/Reject: Generate a uniform random number u \\sim U(0, 1).  </li> <li>If u \\leq \\alpha, accept the proposal and set x_{t+1} = x'.</li> <li> <p>Otherwise, reject the proposal and set x_{t+1} = x.</p> </li> <li> <p>Repeat: Continue the process for N iterations to build a Markov chain of samples.</p> </li> </ol> <p>The Markov chain eventually converges to the target distribution \\pi(x). The random walk proposal (e.g., normal step) ensures local exploration. Choosing the step size (via the proposal variance \\sigma^2) balances mixing and efficiency.</p> <p>Task [Metropolis-Hastings]: Write and illustrate the MHRW algorithm by sampling from a double-exponential (Laplace) distribution.</p> <p>Solution:</p> <pre><code># Define the target distribution: Double Exponential (Laplace) Distribution\ndef target_density(x):\n    # Double exponential (Laplace) PDF with mean=0, b=1\n    return 0.5 * np.exp(-abs(x))\n\n# Metropolis-Hastings Random Walk Algorithm\ndef metropolis_hastings(target_density, proposal_std, num_samples, initial_state=0):\n    samples = [initial_state]\n    current_state = initial_state\n\n    for i in range(num_samples - 1):\n        # Step 1: Propose a new state using a normal distribution centered at current state\n        proposed_state = np.random.normal(current_state, proposal_std)\n\n        # Step 2: Calculate acceptance probability\n        acceptance_ratio = target_density(proposed_state) / target_density(current_state)\n        acceptance_prob = min(1, acceptance_ratio)\n\n        # Step 3: Accept or reject the proposal\n        if np.random.uniform(0, 1) &lt; acceptance_prob:\n            current_state = proposed_state  # Accept proposal\n\n        # Step 4: Store the current state\n        samples.append(current_state)\n\n    return np.array(samples)\n\n# Parameters\nproposal_std = 1.0   # Standard deviation of the proposal distribution\nnum_samples = 10000  # Number of samples to generate\n\n# Run the MHRW sampling\nsamples = metropolis_hastings(target_density, proposal_std, num_samples)\n\n# Plot the histogram of samples\nx = np.linspace(-10, 10, 1000)\nplt.figure(figsize=(8, 5))\nplt.hist(samples, bins=100, density=True, alpha=0.9, color='skyblue', label='MHRW Samples')\nplt.plot(x, target_density(x), 'r-', label='True Double-Exponential PDF')\nplt.xlabel('x')\nplt.ylabel('Density')\nplt.legend()\nplt.title('MHRW Sampling from Double-Exponential Distribution')\nplt.show()\n</code></pre> <p></p> <p>We see that the MHRW sampler yields correlated samples between sample i and i+1. Note that x_{i+1} | x_i is not Laplace (\\pi(x)) distributed. Only the unconditional distribution, i.e. the histogram of \\{x_1, ..., x_N\\} approximately resembles the density \\pi(x). We can see the correlation by plotting the time path of samples. Because of its presence, the MHRW method may require sample replications.</p> <pre><code># Plot the time evolution of samples\nplt.figure(figsize=(8, 5))\nsample_ids = np.arange(len(samples))\nplt.plot(np.arange(num_samples-100, num_samples), samples[-100:], 'b-', alpha=0.6, label='Sample Path', marker='o', markersize=5, markerfacecolor='red')\n\nplt.xlabel('Sample ID')\nplt.ylabel(r'Sample Value $x$')\nplt.title('Time Evolution of MHRW Samples (last 100 samples)')\nplt.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"courses/bmetrics/BayReg/#coding-the-full-model","title":"Coding the Full Model","text":"<p>Let\u2019s code the model through a series of tasks.</p> <p>Task [GLS estimator]:</p> <p>Write a GLS estimator \\hat{\\beta}(\\Omega), which takes the heteroskedasticity matrix \\Omega as given. Recall that \\Omega is diagonal.</p> <p>Task [posterior parameters]:</p> <p>Write a (set of) functions, which compute the conditional posterior parameters for \\beta, h, \\Omega.</p> <pre><code>@jit(nopython=True)\ndef gls_solution(X, y, Omega):\n    # supply only the diagonal of Omega to avoid costly computation\n    P = Omega**(-0.5)\n    Xg = X * P[:, np.newaxis]\n    yg = y * P\n    N = y.shape[0]\n    K = X.shape[1]\n    XX = Xg.T @ Xg\n    nu = N - K\n    beta_hat = np.linalg.solve(XX, Xg.T @ yg)\n    s_sq = 1/nu * (yg - Xg @ beta_hat).T @ (yg - Xg @ beta_hat)\n    return beta_hat, s_sq, nu, N, K, XX\n\ndef gls_dict_wrapper(X, y, Omega):\n    beta_hat, s_sq, nu, N, K, XOmega_invX = gls_solution(X, y, Omega)\n    gls_dict = {\n        'beta': beta_hat,\n        's_sq': s_sq,\n        'nu': nu,\n        'N': N,\n        'K': K,\n        'XOmega_invX': XOmega_invX\n    }\n    return gls_dict\n\n\nprint(f\"{'OLS estimator':&lt;40}\", ols_solution(X, y)[0])\n\nOmega = np.ones(X.shape[0]) # stable variance\nprint(f\"{'GLS estimator, stable variance':&lt;40}\", gls_solution(X, y, Omega)[0])\n\nOmega = np.arange(1, X.shape[0] + 1) # increasing variance\nprint(f\"{'GLS estimator, increasing variance':&lt;40}\", gls_solution(X, y, Omega)[0])\n</code></pre> <pre><code>OLS estimator                            [0.86907181 2.14332413 3.06126176]\nGLS estimator, stable variance           [0.86907181 2.14332413 3.06126176]\nGLS estimator, increasing variance       [0.94638503 2.29210031 2.59479426]\n</code></pre> <p>Task [Gibbs sampler (a)] Code up functions (e.g., <code>sample_beta</code>, <code>sample_P</code> and <code>sample_h</code>) to sample \\beta, \\Omega and h from their conditional posterior distributions. </p> <pre><code>from scipy.special import gammaln\n\n@jit(nopython=True)\ndef numba_sum(X):\n    sum = 0\n    for i in range(len(X)):\n        sum += X[i]\n    return sum\n\n## SAMPLING BETAS\n# beta given y, h, Omega\n@jit(nopython=True)\ndef cond_post_param_beta(h, P_root, beta_pri, V_inv_pri, X, y):\n    # precision matrix, P =&gt; P_root^2\n    Xg = X * P_root[:, np.newaxis]\n    yg = y * P_root\n    V_inv_pst = V_inv_pri + h * Xg.T @ Xg\n    rhs = V_inv_pri @ beta_pri + h * Xg.T @ yg\n    beta_pst = np.linalg.solve(V_inv_pst, rhs)  # Solve V_inv_out @ x = rhs\n    return beta_pst, V_inv_pst # return posteriors for beta\n\n# sample from the conditional posterior for beta\ndef sample_beta(h, P_root, beta_pri, V_inv_pri, X, y):\n    beta_pst, V_inv_pst = cond_post_param_beta(h, P_root, beta_pri, V_inv_pri, X, y)\n    return np.random.multivariate_normal(mean=beta_pst, cov=np.linalg.inv(V_inv_pst))\n\n@jit(nopython=True)\ndef get_res(y, X, beta):\n    return y - X @ beta\n\n## SAMPLING H\n@jit(nopython=True)\ndef cond_post_param_h(P_root, resid, nu_pri, s_sq_pri):\n    N = P_root.shape[0]\n    nu_pst = nu_pri + N\n    residg = resid * P_root # transform the residuals\n    s_sq_pst = residg.T @ residg \n    s_sq_pst = s_sq_pst + nu_pri * s_sq_pri\n    s_sq_pst = s_sq_pst / nu_pst\n    return s_sq_pst, nu_pst\n\ndef sample_h(P_root, resid, nu_pri, s_sq_pri):\n    s_sq_pst, nu_pst = cond_post_param_h(P_root, resid, nu_pri, s_sq_pri)\n    shape = nu_pst / 2\n    scale = 2 * s_sq_pst**(-1) / nu_pst\n    return np.random.gamma(shape=shape, scale=scale)\n\n## SAMPLING P\n@jit(nopython=True)\ndef cond_post_param_P(nu_lambda, resid, h): \n    dof_lambda = nu_lambda + 1\n    mu_lambda = (nu_lambda + 1)/(h * resid**2 + nu_lambda)\n    return mu_lambda, dof_lambda \n\ndef sample_P(resid, h, nu_lambda):\n    mu_lambda, dof_lambda = cond_post_param_P(nu_lambda, resid, h)\n    shape = dof_lambda/2\n    scale = 2 * mu_lambda / dof_lambda # this is a vector\n    return np.random.gamma(shape, scale) # returns [... \u03bb_i ...]\n</code></pre> <p>Task [Gibbs sampler (b)] Code up a function <code>sample_nu_lambda_new</code> to sample the next \\nu_\\lambda from its conditional distribution. It is not necessary to fully nest the MHRW algorithm within the Gibbs sampler. Instead, the Gibbs sampler will run exactly one step of the Metropolis Hastings algorithm, hence <code>sample_nu_lambda_new</code> must take in the \\nu_\\lambda from the previous Gibbs sampling iteration.</p> <pre><code>## SAMPLING NU_LAMBDA\n@jit(nopython=True)\ndef cond_post_param_nu_lambda(P, nu_lambda_pri):\n    \"\"\"Compute the parameter eta for the density of the posterior of nu_lambda\n        given the current state of P (np.array)\n\n        P = [\u03bb1, ..., \u03bbN]\n    \"\"\"\n    lx = -np.log(P) + P\n    eta = 1/nu_lambda_pri + 0.5 * numba_sum(lx)\n    return eta\n\ndef dof_density_prop_log(nu, eta, N):\n    p = np.log(nu / 2)*(N * nu / 2) + gammaln(nu / 2)*(-N) + (-eta * nu)\n    return p\n\ndef dof_density_ratio(nu_lambda_new, nu_lambda_old, eta, N):\n    return np.exp(dof_density_prop_log(nu_lambda_new, eta, N) - dof_density_prop_log(nu_lambda_old, eta, N))\n\n# instead of the acceptance sampling, we use the random walk MH.\ndef sample_nu_lambda_new(nu_lambda_old, P, nu_lambda_pri, MH_param=1.):\n    N = P.shape[0] # number of obs = number of latent lambdas\n\n    ## Use M-H step to draw new value for nu_lambda vector\n    # 1. Propose a new value\n    nu_lambda_new = nu_lambda_old + np.random.normal(scale=MH_param) # random walk MH  \n\n    # 2. Calculate the ratio of densities\n    if nu_lambda_new &gt; 0 : # ensure it is positive\n        eta = cond_post_param_nu_lambda(P, nu_lambda_pri) # parameter in the density\n        acc_ratio = dof_density_ratio(nu_lambda_new, nu_lambda_old, eta, N) ###  \n    else:\n        acc_ratio = 0.\n\n    # 3. Accept or reject the new values\n    if acc_ratio &gt;= 1.:\n        accept = True\n    elif acc_ratio == 0.:\n        accept = False\n    else:\n        accept = np.random.rand() &lt; acc_ratio\n\n    # 4. Return the new values, accepted or not\n    return accept * nu_lambda_new + (1-accept) * nu_lambda_old, accept\n</code></pre>"},{"location":"courses/bmetrics/BayReg/#gibbs-sampler","title":"Gibbs sampler","text":"<p>We now assemble the Gibbs sampler. The algorithm can be spelled out as follows:</p> <p>Initialize: \\beta^{(0)} = \\beta^{OLS}, h^{(0)} = \\hat{\\sigma}^2, \\Omega^{(0)} = diag(\\lambda_1^{-1}, ..., \\lambda_N^{-1}) = diag(1/\\boldsymbol{\\lambda}^{(0)}), \\boldsymbol{\\lambda}^{(0)} = 1.</p> <ol> <li>Initialize:</li> <li>\\beta^{(0)} = \\beta^{OLS}</li> <li>h^{(0)} = \\hat{\\sigma}^2</li> <li>\\Omega^{(0)} = \\operatorname{diag}(\\lambda_1^{-1}, \\dots, \\lambda_N^{-1}) = \\operatorname{diag}(1/\\boldsymbol{\\lambda}^{(0)})</li> <li> <p>\\boldsymbol{\\lambda}^{(0)} = 1 (vector of ones)</p> </li> <li> <p>Iterate for t = 1, 2, \\dots, T (number of iterations):</p> </li> </ol> <p>Step 1: Update \\beta^{(t)} (regression coefficients):    Sample \\beta^{(t)} from the conditional posterior:    $$    \\beta^{(t)} \\mid \\mathbf{y}, \\mathbf{X}, h^{(t-1)}, \\Omega^{(t-1)}, \\nu_\\lambda^{(t-1)} \\sim N(\\overline \\beta,\\overline V)    $$</p> <p>Step 2: Update h^{(t)} (variance hyperparameter):    Sample h^{(t)} from the conditional posterior:    $$    h^{(t)} \\mid \\mathbf{y}, \\mathbf{X}, \\beta^{(t)}, \\nu_\\lambda^{(t-1)} \\sim  G\\left(\\overline{s}^{-2}, \\overline{\\nu}\\right)    $$</p> <p>Step 3: Update \\boldsymbol{\\lambda}^{(t)}, \\Omega^{(t)} (heteroskedasticity parameters):    For each i = 1, \\dots, N, sample:    $$    \\lambda_i^{(t)} \\mid \\mathbf{y}, \\mathbf{X}, \\beta^{(t)}, h^{(t)}, \\nu_\\lambda^{(t-1)} \\sim f_G\\bigg( \\lambda_i \\big| \\frac{\\nu_\\lambda + 1}{h \\epsilon_i^2 + \\nu_\\lambda}, \\nu_\\lambda +1  \\bigg)    $$</p> <p>Step 4: Update \\Omega^{(t)} (diagonal precision matrix):    Set:    $$    \\nu_\\lambda^{(t)} \\mid \\mathbf{y}, \\mathbf{X}, \\beta^{(t)}, h^{(t)}, \\boldsymbol{\\lambda}^{(t)}, \\nu_\\lambda^{(t-1)} \\sim p(\\nu_\\lambda | y, \\beta, h, \\lambda)    $$</p> <ol> <li>Repeat steps 1 through 4 until (distributional) convergence or for T iterations.</li> </ol> <p>Let\u2019s also include an argument which switches off heteroskedasticity of the model.</p> <pre><code>def gibbs_sampler(X, y, priors, heteroskedastic=True,draws=10_000, burn_in=1_000, MH_params={'sigma': .25}):\n    MH_sigma = MH_params['sigma']\n    N, _ = X.shape\n    gls_dict = gls_dict_wrapper(X, y, np.array([1.0]*N))\n\n    # initialize the parameters\n    gibbs = {\n        'betas': [gls_dict['beta']],\n        'h': [1/gls_dict['s_sq']],\n        'Ps': [np.array([1.0]*N)],\n        'nu_lambda': [priors['nu_lambda']], # \u03bb: prior mean dof,\n        'mh_acceptances': [] # counts the number of accepted proposals in the M-H step\n    }\n    P_root_sample = gibbs['Ps'][-1]**0.5 # initialize the square root of precision matrix\n\n    for i in range(draws+burn_in):\n\n        # sample beta given h, Omega, \u03bd_\u03bb\n        beta_sample = sample_beta(\n                                gibbs['h'][-1],      # h: sampled precision\n                                P_root_sample,       # \u03bb: (root of) last precision sample\n                                priors['beta'],      # \u03b2: prior mean\n                                priors['V_inv'],     # \u03b2: prior precision matrix\n                                X,\n                                y)\n        resid = get_res(y, X, beta_sample)\n        gibbs['betas'].append(beta_sample)\n\n        # sample h given beta, Omega, \u03bd_\u03bb\n        h_sample = sample_h(P_root_sample,      # \u03bb: (root of) last precision sample\n                            resid,              # \u03b2: residuals from sampled beta \n                            priors['nu'],       # h: prior dof\n                            priors['s_sq'])     # h: prior\n        gibbs['h'].append(h_sample)\n\n        if not heteroskedastic:\n            continue\n\n        # sample \u03bd_\u03bb given beta, h, Omega\n        nu_lambda_sample, mh_acceptance = sample_nu_lambda_new(gibbs['nu_lambda'][-1], \n                                                               gibbs['Ps'][-1], \n                                                               priors['nu_lambda'], \n                                                               MH_sigma)\n        gibbs['nu_lambda'].append(nu_lambda_sample)\n        gibbs['mh_acceptances'].append(mh_acceptance)\n\n        # sample lambdas/Omega given beta, h, \u03bd_\u03bb\n        P_sample = sample_P(resid,                      # \u03b2: residuals from sampled beta \n                                gibbs['h'][-1],         # h: sampled precision\n                                gibbs['nu_lambda'][-1]) # \u03bb: last dof sample\n        gibbs['Ps'].append(P_sample) \n        P_root_sample = P_sample**0.5\n\n    # discard burn-in\n    gibbs['betas'] = gibbs['betas'][burn_in:]\n    gibbs['h'] = gibbs['h'][burn_in:]\n    gibbs['Ps'] = gibbs['Ps'][burn_in:]\n    gibbs['nu_lambda'] = gibbs['nu_lambda'][burn_in:]\n    return gibbs\n</code></pre> <pre><code># priors (hyperparameters)\nK = X.shape[1]\npriors = {\n    'beta': np.zeros(K),        # beta: zero mean for beta\n    'V_inv': np.eye(K)*1E-5,    # beta: weak prior for beta\n    's_sq': 1,                  # h:    expected precision is 1 = 1/s_sq\n    'nu': 4,                    # h:    dof\n    'nu_lambda': 25              # \u03bb:    prior mean dof\n}\n\n%timeit gibbs_sampler(X, y, priors, draws=1_000, burn_in=1_000, MH_params={'sigma': .5})\n%timeit gibbs_sampler(X, y, priors, draws=10_000, burn_in=1_000, MH_params={'sigma': .5})\n%timeit gibbs_sampler(X, y, priors, draws=100_000, burn_in=1_000, MH_params={'sigma': .5})\n</code></pre> <pre><code>303 ms \u00b1 51.4 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n1.41 s \u00b1 71.1 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n12.4 s \u00b1 308 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</code></pre>"},{"location":"courses/bmetrics/BayReg/#parallel-gibbs-sampler","title":"Parallel Gibbs Sampler","text":"<p>To speed things up and get a little practice in parallel computing, let\u2019s parallelize the Gibbs sampler using <code>joblib</code>.</p> <pre><code>from joblib import Parallel, delayed\ndef draw_gibbs_sample(gibbs, priors, y, X, heteroskedastic=True, mh_params={'sigma': .25}):\n    MH_sigma = mh_params['sigma']\n    P_root = gibbs['Ps'][-1]**0.5 # precision matrix\n\n    # sample beta given h, Omega, \u03bd_\u03bb\n    beta_sample = sample_beta(\n                            gibbs['h'][-1],      # h: sampled precision\n                            P_root,              # \u03bb: (root of) last precision sample\n                            priors['beta'],      # \u03b2: prior mean\n                            priors['V_inv'],     # \u03b2: prior precision matrix\n                            X,\n                            y)\n    resid = get_res(y, X, beta_sample)\n\n    # sample h given beta, Omega, \u03bd_\u03bb\n    h_sample = sample_h(P_root,      # \u03bb: (root of) last precision sample\n                        resid,              # \u03b2: residuals from sampled beta \n                        priors['nu'],       # h: prior dof\n                        priors['s_sq'])     # h: prior\n\n    if not heteroskedastic:\n        return beta_sample, h_sample, gibbs['Ps'][-1], gibbs['nu_lambda'][-1], 0\n\n    # sample \u03bd_\u03bb given beta, h, Omega\n    nu_lambda_sample, mh_acceptance = sample_nu_lambda_new(gibbs['nu_lambda'][-1], \n                                                            gibbs['Ps'][-1], \n                                                            priors['nu_lambda'], \n                                                            MH_sigma)\n\n    # sample lambdas/Omega given beta, h, \u03bd_\u03bb\n    P_sample = sample_P(resid,                      # \u03b2: residuals from sampled beta \n                        gibbs['h'][-1],         # h: sampled precision\n                        gibbs['nu_lambda'][-1]) # \u03bb: last dof sample\n    gibbs['Ps'].append(P_sample) \n\n    return beta_sample, h_sample, P_sample, nu_lambda_sample, mh_acceptance\n\ndef merge_dictionaries(dict_list):\n    master_dict = {}\n\n    for d in dict_list:\n        for key, value in d.items():\n            if key not in master_dict:\n                master_dict[key] = []\n            master_dict[key].extend(value)  # Unpack the list and append the elements\n\n    return master_dict\n\ndef gibbs_sampler_parallel(X, y, priors, heteroskedastic=True, draws=10_000, burn_in=1_000, n_jobs=5, mh_params={'sigma': .25}):\n    N, _ = X.shape\n    ols = gls_dict_wrapper(X, y, np.array([1.0]*N))\n\n    # initialize the parameters\n    gibbs = {\n        'betas': [ols['beta']],\n        'h': [1/ols['s_sq']],\n        'Ps': [np.array([1.0]*N)],\n        'nu_lambda': [priors['nu_lambda']], # \u03bb: prior mean dof,\n        'mh_acceptances': [] # counts the number of accepted proposals in the M-H step\n    }\n\n    # burn in\n    for i in range(burn_in):\n        beta_sample, h_sample, P_sample, nu_lambda_sample, _ = draw_gibbs_sample(gibbs, priors, y, X, heteroskedastic, mh_params)\n\n        gibbs['betas'].append(beta_sample)\n        gibbs['h'].append(h_sample)\n        gibbs['Ps'].append(P_sample)\n        gibbs['nu_lambda'].append(nu_lambda_sample)\n\n    # discard burn-in\n    gibbs['betas'] = gibbs['betas'][burn_in:]\n    gibbs['h'] = gibbs['h'][burn_in:]\n    gibbs['Ps'] = gibbs['Ps'][burn_in:]\n\n    # draw samples\n    draws_per_job = int(np.ceil(draws / n_jobs))\n    def draw_samples_parallel(gibbs):\n        gibbs_local = gibbs.copy()\n        for j in range(draws_per_job):\n            beta_sample, h_sample, P_sample, nu_lambda_sample, mh_acceptance = draw_gibbs_sample(gibbs_local, priors, y, X, heteroskedastic, mh_params) \n            gibbs_local['betas'].append(beta_sample)\n            gibbs_local['h'].append(h_sample)\n            gibbs_local['Ps'].append(P_sample)\n            gibbs_local['nu_lambda'].append(nu_lambda_sample)\n            gibbs_local['mh_acceptances'].append(mh_acceptance)\n        gibbs_local['betas'].pop(0) # remove the first element (burn in element)\n        gibbs_local['h'].pop(0)\n        gibbs_local['Ps'].pop(0)\n        gibbs_local['nu_lambda'].pop(0)\n\n        return gibbs_local\n\n    results = Parallel(n_jobs=n_jobs)(delayed(draw_samples_parallel)(gibbs) for _ in range(n_jobs))\n    gibbs = merge_dictionaries(results)\n\n    return gibbs\n</code></pre> <pre><code># priors (hyperparameters)\nK = X.shape[1]\npriors = {\n    'beta': np.zeros(K),        # beta: zero mean for beta\n    'V_inv': np.eye(K)*1E-5,    # beta: weak prior for beta\n    's_sq': 1,                  # h:    expected precision is 1 = 1/s_sq\n    'nu': 4,                    # h:    dof\n    'nu_lambda': 25              # \u03bb:    prior mean dof\n}\n\ngibbs = gibbs_sampler_parallel(X, y, priors, heteroskedastic=False, draws=10_000, burn_in=50_000, n_jobs=1, mh_params={'sigma': .5})\nnp.array(gibbs['mh_acceptances']).mean(),np.array(gibbs['nu_lambda']).mean() #if heteroskedastic=False, the acceptance rate is 0 and nu_lambda has no effect \n</code></pre> <pre><code>(0.0, 25.0)\n</code></pre> <pre><code>%time gibbs = gibbs_sampler_parallel(X, y, priors, draws=1_000_000, burn_in=1_000, n_jobs=5, mh_params={'sigma': .5})\n%time gibbs = gibbs_sampler_parallel(X, y, priors, draws=1_000_000, burn_in=1_000, n_jobs=15, mh_params={'sigma': .5})\n</code></pre> <pre><code>CPU times: user 9.87 s, sys: 18.7 s, total: 28.6 s\nWall time: 1min 15s\nCPU times: user 11.5 s, sys: 44.7 s, total: 56.2 s\nWall time: 2min 3s\n</code></pre>"},{"location":"courses/bmetrics/BayReg/#visualization","title":"Visualization","text":"<p>We can now e.g. plot the joint distribution of the (\\beta_1, \\beta_2). Also visualize the posterior probability that \\beta_2 &lt; \\beta_1</p> <pre><code># take some samples\nbetas_samples = np.array(gibbs['betas'][-10_000:])\n</code></pre> <pre><code># lets plot the simulated joint distribution of the first two betas\nbool = betas_samples[ :, 0] &gt; 0.6*betas_samples[:, 1]\nfig, ax = plt.subplots(1,1)\nax.scatter(betas_samples[:, 0], betas_samples[:, 1], marker='.', alpha=0.1, c=bool)\nax.set_title('Simulated posterior distribution of beta')\nax.set_xlabel(r'$\\beta_1$')\nax.set_ylabel(r'$\\beta_2$')\nplt.show()\nprint(\"prob = \", bool.mean())\n</code></pre> <p></p> <pre><code>prob =  0.001\n</code></pre>"},{"location":"courses/bmetrics/BayReg/#a-full-class-bayesianregressioninghet","title":"A Full Class <code>BayesianRegressionIngHet</code>","text":"<p>Now that the Gibbs sampler is completed, we should package up our functions and write a class for the independent NG prior with heteroskedasticity. We can then deploy the code easily for estimation problems.</p> <pre><code>class BayesianRegressionIngHet():\n    def __init__(self, X, y, priors, heteroskedastic=True):\n        self.X = X\n        self.y = y\n        self.priors = priors\n        self.gibbs = None\n        self.heteroskedastic = heteroskedastic\n\n    def run_gibbs(self, draws=10_000, burn_in=1_000, n_jobs=5, mh_params={'sigma': 1.}):\n        self.mh_params = mh_params\n        self.gibbs = gibbs_sampler_parallel(self.X, self.y, self.priors, draws=draws, burn_in=burn_in, n_jobs=n_jobs, heteroskedastic=self.heteroskedastic, mh_params=mh_params)\n        _,_ = self.get_posterior_stats()\n\n    def get_posterior_stats(self):\n        assert self.gibbs is not None, \"Run Gibbs sampler first!\"\n        betas = np.array(self.gibbs['betas'])\n        betas_mean = betas.mean(axis=0)\n        betas_cov = np.cov(betas, rowvar=False)\n        h_mean = np.mean(self.gibbs['h'])\n        nu_lambda_mean = np.mean(self.gibbs['nu_lambda'])\n        nu_lambda_var = np.var(self.gibbs['nu_lambda'])\n        self.posterior_stats = {\n            'betas_mean': betas_mean,\n            'betas_cov': betas_cov,\n            'h_mean': h_mean,\n            'nu_lambda_mean': nu_lambda_mean,\n            'nu_lambda_var': nu_lambda_var\n        }\n\n        return betas_mean, betas_cov\n\n    def summarize_posterior(self):\n        means, sds  = self.posterior_stats['betas_mean'], mod.posterior_stats['betas_cov'].diagonal()**0.5\n        means       = np.append(means, [self.posterior_stats['nu_lambda_mean']])\n        sds         = np.append(sds, [self.posterior_stats['nu_lambda_var']**0.5])\n\n        names = [f'\u03b2{i}' for i in range(1, len(means))] + ['\u03bd_\u03bb']\n\n        # Print the header\n        print(f\"{'coef':&lt;10} {'val':&gt;10} {'sd':&gt;10}\")\n\n        # Print each row\n        for name, mean, sd in zip(names, means, sds):\n            print(f\"{name:&lt;10} {mean:&gt;10.4f} {sd:&gt;10.4f}\")\n\n        print(\"M-H acceptance rate:\", f\"{np.array(self.gibbs['mh_acceptances']).mean():0.4f}\")\n</code></pre>"},{"location":"courses/bmetrics/BayReg/#applications","title":"Applications","text":""},{"location":"courses/bmetrics/BayReg/#house-prices","title":"House Prices","text":"<p>We use data supplied on the textbook website. We investigate the degree of heteroskedasticity by Gibbs sampling \\nu_\\lambda. Note that this regression model is somewhat equivalent to a linear regression with fat-tailed, t-distributed errors with \\nu_\\lambda degrees of freedom. That is exactly the model you would get if you integrate out \\lambda_i. Thus, Gibbs sampling \\nu_\\lambda allows us to evaluate the fat-tailedness of our data.</p> <pre><code>import pandas as pd\n# URL of the data\nurl = 'https://web.ics.purdue.edu/~jltobias/HPRICE.TXT'\n# Read the data into a pandas DataFrame\ndf = pd.read_csv(url, sep='\\s+')\n# turn data into numpy arrays\ny = df['%price'].to_numpy()\nX = df[['lot_siz', '#bed', '#bath', '#stor']].to_numpy()\nX = np.column_stack((np.ones(X.shape[0]), X))  # add intercept\ndf.head()\n</code></pre> %price lot_siz #bed #bath #stor drive. recroom b-ment gas aircond #gar desireloc 0 42000 5850 3 1 2 1 0 1 0 0 1 0 1 38500 4000 2 1 1 1 0 0 0 0 0 0 2 49500 3060 3 1 1 1 0 0 0 0 0 0 3 60500 6650 3 1 2 1 1 0 0 0 0 0 4 61000 6360 2 1 1 1 0 0 0 0 0 0 <pre><code># fix some priors\npriors = {\n    'beta': np.array([0.,\n                      10,\n                      5_000,\n                      10_000,\n                      10_000]), # beta: zero mean for beta\n    'V_inv': np.diag(np.array([10_000, 5, 2_500, 5_000, 5_000], dtype=float)**(-2)),     # beta: weak prior for beta USE THE PRIOR SUPPLIED IN THE BOOK\n    's_sq': 1/4*1E8,            # h:    expected precision is 1 = 1/s_sq\n    'nu': 5,                    # h:    dof\n    'nu_lambda': 25             # \u03bb:    hypothesized dof (fat-tailedness of error variance) \n}\n</code></pre> <pre><code>mod = BayesianRegressionIngHet(X, y, priors, heteroskedastic=True)\nmod.run_gibbs(draws=100_000, burn_in=25_000, n_jobs=10, mh_params={'sigma': 0.5})\nmod.get_posterior_stats()\nmod.summarize_posterior()\n</code></pre> <pre><code>coef              val         sd\n\u03b21          -457.7392  2907.1692\n\u03b22             5.2368     0.3596\n\u03b23          2125.2660   966.4355\n\u03b24         14917.1624  1652.3078\n\u03b25          8121.5951   852.2948\n\u03bd_\u03bb            4.4905     1.7443\nM-H acceptance rate: 0.4954\n</code></pre> <pre><code>plt.hist( np.array(mod.gibbs['nu_lambda']), bins=500, density=True, color='red')\nplt.title(r\"$\\nu_\\lambda$ Draws\")\nplt.xlim(0, 10)\nplt.show()\n</code></pre> <p></p>"},{"location":"courses/bmetrics/BayReg/#is-real-gdp-oscillatory-andor-explosive","title":"Is Real GDP Oscillatory and/or Explosive?","text":"<p>Geweke (1988, Journal of Business and Economic Statistics)</p> <p>We investigate whether real GDP oscillates (the lag polynomial has an imaginary root) or is explosive (the lag polynomial has at least one root within the unit cycle) in an AR(p) model. The model is </p> <p>$$      y_t = \\beta_1 + \\sum_{j=1}^p \\beta_{1+j} y_{t-j} + \\varepsilon_t, $$ with independent prior and no heteroskedasticity.</p> <pre><code>import pandas_datareader.data as web\nimport os\n\nstart, end = '1947-01-01', '2025-01-01' # '2005-07-01'\n\n# Fetch the GDPC1 time series data from FRED\ndf = web.DataReader('GDPC1', 'fred', api_key=os.getenv('FRED_API_KEY'), start=start, end=end)\ndf.head()\ndf['log_GDP'] = np.log(df['GDPC1'])\ndf['log_GDP'].plot(title='US Real GDP (log scale)', legend=False)\nplt.show()\n</code></pre> <p></p> <pre><code># Manipulate the data to create a time series regression\ndef lagged_time_series_df(y, num_lags, index=None):\n    X = np.zeros((y.shape[0], num_lags+1))\n    for i in range(1, num_lags+1):\n        X[i:, i] = y[:-i]\n    X[:, 0] = 1 # intercept\n    X = X[num_lags:, :] # remove the first few rows with NaNs\n    y = y[num_lags:] # remove the first few rows with NaNs\n    df = pd.DataFrame(np.column_stack((y, X)), columns=['y'] + ['const'] + [f'lag_{i}' for i in range(1, num_lags+1)], index=index[num_lags:])\n    return df\n\ndf_ts = lagged_time_series_df(df['log_GDP'].to_numpy(), 3, index=df.index)\ndf_ts.head()\n</code></pre> y const lag_1 lag_2 lag_3 DATE 1947-10-01 7.699141 1.0 7.683603 7.685653 7.688309 1948-01-01 7.714089 1.0 7.699141 7.683603 7.685653 1948-04-01 7.730478 1.0 7.714089 7.699141 7.683603 1948-07-01 7.736207 1.0 7.730478 7.714089 7.699141 1948-10-01 7.737339 1.0 7.736207 7.730478 7.714089 <p>Now, set up a dictionary for priors and run the Gibbs sampler.</p> <pre><code>priors = {\n    'beta': np.array([0.,\n                      0,\n                      0,\n                      0]), # beta: zero mean for beta\n    'V_inv': np.diag((1E6*np.ones([4], dtype=float))**(-2)),     # beta: weak prior\n    's_sq': 1,           # h:    expected precision is 1 = 1/s_sq\n    'nu': 0,             # h:   \n    'nu_lambda': 1000    # \u03bb:    dont matter, no heteroskedasticity\n}\n\nmod = BayesianRegressionIngHet(df_ts[['const', 'lag_1', 'lag_2', 'lag_3']].to_numpy(), df_ts['y'].to_numpy(), \n                               priors, \n                               heteroskedastic=False)\nmod.run_gibbs(draws=1_000_000, burn_in=25_000, n_jobs=1)\n</code></pre> <pre><code>mod.get_posterior_stats()\nmod.summarize_posterior()\n</code></pre> <pre><code>coef              val         sd\n\u03b21             0.0248     0.0085\n\u03b22             1.1008     0.0571\n\u03b23            -0.0206     0.0851\n\u03b24            -0.0822     0.0569\n\u03bd_\u03bb         1000.0000     0.0000\nM-H acceptance rate: 0.0000\n</code></pre> <pre><code>def roots_test(sample):\n    b = sample.copy()\n    b = -b[::-1]\n    b[-1] = 1\n    roots = np.roots(b)\n    oscillatory_event = (np.imag(roots) != np.zeros(len(roots))).sum() &gt;= 2\n    out_unit_circle_event = np.min(np.abs(roots)) &lt; 1\n    return oscillatory_event, out_unit_circle_event\n\ndef roots_test_parallel(samples, n_jobs=5):\n    results = Parallel(n_jobs=n_jobs)(delayed(roots_test)(sample) for sample in samples)\n    oscillatory_events, in_unit_circle_events = zip(*results)\n    return np.array(oscillatory_events), np.array(in_unit_circle_events)\n\ndef print_probabilities(A, B, start_date, end_date, dependent_var_name):\n    # Calculate the mean of A and B\n    mean_A = A.mean()\n    mean_B = B.mean()\n\n    # Print the sample period and dependent variable name\n    print(f\"{'Dependent Variable:':&lt;20} {dependent_var_name}\")\n    print(f\"{'Sample Period:':&lt;20} {start_date} to {end_date}\\n\")\n\n\n    print(f\"Pr(Y has oscillatory behavior) = {mean_A:.4f}\")\n    print(f\"Pr(Y has explosive behavior)   = {mean_B:.4f}\")\n</code></pre> <pre><code>A, B = roots_test_parallel(mod.gibbs['betas'], n_jobs=5)\n</code></pre> <pre><code>print_probabilities(A, B, start, end, 'log real GDP (US)')\n</code></pre> <pre><code>Dependent Variable:  log real GDP (US)\nSample Period:       1947-01-01 to 2025-01-01\n\nPr(Y has oscillatory behavior) = 0.0649\nPr(Y has explosive behavior)   = 0.0132\n</code></pre>"},{"location":"courses/bmetrics/TVP-AR/","title":"Time Varying Parameter AR Model","text":"<p>The following model was treated in a course taught by Dimitris Korobilis in a summer school taught at the Barcelona Graduate School of Economics in 2017. It is a simplified version of Primiceri (2005), who uses a time varying parameter (TVP) model to investigate historical changes in the way monetary policy has been transmitted in the US. The data set we will be using has nothing to do with this application, and consists of the annual percentage change in UK industrial production from 1701-1992. In order to investigate whether the dynamic structure of this time series model is changing over time, we use an AR(p) model with time-varying coefficients:</p>  y_t = \\alpha_{0t} + \\alpha_{1t}y_{t-1} + \\dots + \\alpha_{pt}y_{t-p} + \\varepsilon_t,  <p>where for i = 0, \\dots, p</p>  \\alpha_{it+1} = \\alpha_{it} + u_{it}.  <p>We furthermore assume that \\varepsilon_t \\sim_{iid} N(0, h^{-1}) and u_{it} \\sim_{iid} N(0, \\lambda_i h^{-1}) where \\varepsilon_t, u_{is}, and u_{jr} are independent of one another for all s, t, r, i, and j. We use a slightly informative prior for the parameters h and \\lambda_i for i = 0, \\dots, p. For h, use a Gamma prior with \\underline\\nu = 1 and \\underline s^{-2} = 1. For \\lambda_i^{-1}, use Gamma priors with \\underline\\nu_i = 1 and \\underline\\lambda_i = 1. With this prior, the conditional posteriors have the form:</p>  p(\\lambda_i^{-1} | y, \\alpha_1, \\dots, \\alpha_T) = f_G\\left(\\lambda_i^{-1} | \\overline{\\lambda}_i^{-1}, \\overline\\nu_i\\right),  <p>for i = 0, \\dots, p, where</p>  \\overline\\nu_i = T + \\underline\\nu_i  <p>and</p>  \\overline{\\lambda}_i =  \\frac{h\\sum_{t=0}^{T-1} (\\alpha_{i, t+1} - \\alpha_{it})(\\alpha_{i, t+1} - \\alpha_{it})' + \\underline\\nu_i \\underline\\lambda_i}{\\overline \\nu_i}.  <p>We will write code which implements the Gibbs sampling algorithm for the model.</p> <p>References: 1. De Jong, Shephard (1995) - The Simulation Smoother for Time Series Models</p> <ol> <li> <p>Carter, Kohn (1994) - On Gibbs Sampling for State Space Models</p> </li> <li> <p>Primiceri (2005) - Time Varying Structural Vector Autoregressions and Monetary Policy</p> </li> </ol> <pre><code>## import data\nimport pandas as pd\nimport numpy as np\nfrom numba import jit, njit, prange\nimport matplotlib.pyplot as plt\n\n\n## load data from txt file\ny_raw = np.loadtxt('./data/uk_ind_prod_growth.txt')*100\nyears_raw = [1701 + i for i in range(len(y_raw))]\ndf = pd.DataFrame(y_raw, columns=['growth'], index=years_raw)\ndf.plot(title='UK Industrial Production Growth', color='blue', linewidth=1)\n</code></pre> <pre><code>&lt;Axes: title={'center': 'UK Industrial Production Growth'}&gt;\n</code></pre> <p></p>"},{"location":"courses/bmetrics/TVP-AR/#state-space-representation","title":"State-Space Representation","text":"<p>The Time-Varying Parameter (TVP) model can be expressed in state-space form, which consists of an observation equation and a state equation.</p> <ol> <li> <p>Observation Equation</p> <p>The observation equation relates the observed y_t to the state (parameters) \\boldsymbol{\\alpha}_t: $$ y_t = \\mathbf{X}_t\u2019 \\boldsymbol{\\alpha}_t + \\varepsilon_t, $$ where:</p> <ul> <li>\\mathbf{X}_t = [1, y_{t-1}, y_{t-2}, \\dots, y_{t-p}]' is a (p+1) \\times 1 vector of predictors (including the intercept as the first entry),</li> <li>\\boldsymbol{\\alpha}_t = [\\alpha_{0,t}, \\alpha_{1,t}, \\dots, \\alpha_{p,t}]' is a (p+1) \\times 1 vector of time-varying parameters,</li> <li>\\varepsilon_t \\sim N(0, h^{-1}) is the observation noise.</li> </ul> <p>This can be written compactly as: $$ y_t = \\mathbf{X}_t\u2019 \\boldsymbol{\\alpha}_t + \\varepsilon_t, \\quad \\varepsilon_t \\sim N(0, h^{-1}). $$</p> </li> <li> <p>State Equation</p> <p>The state equation describes the evolution of the time-varying parameters \\boldsymbol{\\alpha}_t over time: $$ \\boldsymbol{\\alpha}_{t+1} = \\boldsymbol{\\alpha}_t + \\mathbf{u}_t, $$ where: - \\mathbf{u}_t \\sim N(\\mathbf{0}, \\mathbf{Q}), - \\mathbf{Q} = \\text{diag}([\\lambda_0 h^{-1}, \\lambda_1 h^{-1}, \\dots, \\lambda_p h^{-1}]) is a diagonal covariance matrix representing the process noise for each parameter.</p> </li> </ol> <p>This can be written compactly as: $$ \\boldsymbol{\\alpha}_{t+1} \\sim N(\\boldsymbol{\\alpha}_t, \\mathbf{Q}). $$</p>"},{"location":"courses/bmetrics/TVP-AR/#kalman-filter-and-smoother","title":"Kalman Filter and Smoother","text":"<p>The state-space representation allows you to apply the Kalman filter for forward filtering (estimating \\boldsymbol{\\alpha}_t given y_{1:t} = \\{y_1, ..., y_t\\}) and the Kalman smoother for backward smoothing (estimating \\boldsymbol{\\alpha}_t given y_{1:T}). Our first objective is to set up the Kalman filter to obtain state means (given the observations and the distribution of u and \\varepsilon). We also call these means filtered (state) estimates. The Kalman filter consists of the following equations (see Primiceri, 2005):</p> <ol> <li> <p>Initialization Start with an initial guess for the state vector \\boldsymbol{\\alpha}_0 and its covariance \\mathbf{P}_0: \\boldsymbol{\\alpha}_0 \\quad \\text{and} \\quad \\mathbf{P}_0 = \\text{Cov}(\\boldsymbol{\\alpha}_0)</p> </li> <li> <p>Prediction Step Predict the state and its uncertainty at time t: \\hat{\\boldsymbol{\\alpha}}_{t|t-1} = \\hat{\\boldsymbol{\\alpha}}_{t-1|t-1} and \\mathbf{P}_{t|t-1} = \\mathbf{P}_{t-1|t-1} + \\mathbf{Q}. The prediction assumes the state evolves with added process noise from \\mathbf{Q}.</p> </li> <li> <p>Measurement Update (Correction Step) Use the new observation y_t to correct the state estimate.</p> <ul> <li> <p>Compute the prediction error (innovation): v_t = y_t - \\mathbf{X}_t' \\hat{\\boldsymbol{\\alpha}}_{t|t-1}</p> </li> <li> <p>Compute the innovation covariance: S_t = \\mathbf{X}_t' \\mathbf{P}_{t|t-1} \\mathbf{X}_t + h^{-1}</p> </li> <li> <p>Compute the Kalman gain: \\mathbf{K}_t = \\mathbf{P}_{t|t-1} \\mathbf{X}_t \\cdot S_t^{-1}</p> </li> <li> <p>Update the state estimate: \\hat{\\boldsymbol{\\alpha}}_{t|t} = \\hat{\\boldsymbol{\\alpha}}_{t|t-1} + \\mathbf{K}_t v_t</p> </li> <li> <p>Update the covariance estimate: \\mathbf{P}_{t|t} = \\mathbf{P}_{t|t-1} - \\mathbf{K}_t \\mathbf{X}_t' \\mathbf{P}_{t|t-1}</p> </li> </ul> </li> <li> <p>Iterate Repeat the prediction and correction steps for t = 1, 2, \\dots.</p> </li> </ol> <pre><code># First, we need to generate the lagged variables\n# for the state space form of this model\np = 1\nX = np.ones((len(y_raw), p+1))\ny_lag = y_raw.copy()\nfor j in range(1,p+1):\n    y_lag = np.concatenate([[np.nan], y_lag[:-1]])\n    X[:, j] = y_lag\nX = X[p:, :]\ny = y_raw[p:]\nyears = years_raw[p:]\n</code></pre> <p>Now, implement the Kalman filter. I call the matrices similar to the naming conventions in Primiceri (2005):</p> <pre><code># set up the kalman filter for a general state space model\n# but encapsulate performance routines for the TVP-AR(p) model\n# at hand.\n@njit\ndef kalman_filter(y, X, Q, R, F=None, malpha_init=None, Palpha_init=None):\n    \"\"\" \n    Kalman filter corresponding to the following state space model:\n\n        y_t = X_t' \u03b1_t + \u03b5_t\n        \u03b1_t = F \u03b1_{t-1}  + u_t\n\n        \u03b5_t ~ N(0, R)\n        u_t ~ N(0, Q)\n    \"\"\"\n\n    p   = X.shape[1] - 1 # number of explanatory variables\n    T   = len(y)\n    dim = p + 1\n\n    # Preallocate\n    malphas      = np.zeros((T+1, dim))\n    malphas_pred = np.zeros((T+1, dim))        # prediction current mean given previous data\n    Palphas      = np.zeros((T+1, dim, dim))\n    Palphas_pred = np.zeros((T+1, dim, dim))   # prediction current variance given previous data\n    Ks           = np.zeros(T)                 # Kalman gains\n    y_preds      = np.zeros_like(y)      # predictions; y_preds[t] = E[y_t | y_{1:t-1}]\n    y_nowcasts   = np.zeros_like(y)      # nowcast: y_nowcasts[t] = E[x_t' \u03b1_t | y_{1:t}]\n\n\n    # Initialize\n    ## defaults for unconditional mean, variance, precision, lambdas\n    if malpha_init is None:\n        malpha_init = np.zeros(dim)     # zero initial mean\n    if Palpha_init is None:\n        Palpha_init = np.eye(dim) * 1E9 # large initial variance\n    if F is None:\n        F = np.eye(dim)                 # transition matrix\n        idtrnsm = True\n    else:\n        idtrnsm = False\n\n    # construct initial values for Kalman matrices\n    Palphas[0]  = Palpha_init           # current variance given current data\n    malphas[0]  = malpha_init           # filtered mean given current data \n\n    for t in range(T):\n\n        # prediction\n        if idtrnsm:\n            malphas_pred[t] = malphas[t]                # malphas_pred[t] = E[\u03b1_t | y_{1:t-1}]\n            Palphas_pred[t] = Palphas[t] + Q            # Palphas_pred[t] = Var[\u03b1_t | y_{1:t-1}]\n        else:\n            malphas_pred[t] = F @ malphas[t]                # malphas_pred[t] = E[\u03b1_t | y_{1:t-1}]\n            Palphas_pred[t] = F @ Palphas[t] @ F.T + Q      # Palphas_pred[t] = Var[\u03b1_t | y_{1:t-1}]\n        y_t             = y[t]\n        x_t             = X[t][np.newaxis, :]\n        y_pred          = x_t @ malphas_pred[t]\n\n        # update\n        K           = Palphas_pred[t] @ x_t.T / (x_t @ Palphas_pred[t] @ x_t.T + R) # Kalman gain\n        malpha      = malphas_pred[t] + K @ (y_t - y_pred)                          # update mean\n        Palpha      = Palphas_pred[t] - K.reshape(-1, 1) @ x_t @ Palphas_pred[t]    # update variance\n        y_nowcast   = x_t @ malpha                                                  # nowcast\n\n        # store results\n        y_preds[t]      = y_pred[0]\n        y_nowcasts[t]   = y_nowcast[0]\n        malphas[t+1]    = malpha\n        Palphas[t+1]    = Palpha\n        Ks[t]           = K[0,0]\n\n    # final prediction\n    malphas_pred[-1] = malphas[-1]\n    Palphas_pred[-1] = Palphas[-1] + Q\n\n    # remove the initial value\n    malphas = malphas[1:]\n    Palphas = Palphas[1:]\n\n    return y_preds, y_nowcasts, malphas, Palphas, malphas_pred, Palphas_pred, Ks\n</code></pre> <p>The Kalman smoother is an extension of the Kalman filter that provides smoothed estimates of the states \\boldsymbol{\\alpha}_t by using all available data (past, present, and future observations). Unlike the filter, which only estimates states sequentially up to the current time t, the smoother improves accuracy by revisiting past state estimates during a backward pass.</p> <p>Key Concepts:</p> <ul> <li>Kalman Filter: Forward pass (time 1 \\to T), estimating \\boldsymbol{\\alpha}_t based on data up to t.</li> <li>Kalman Smoother: Backward pass (time T \\to 1), refining \\boldsymbol{\\alpha}_t using future observations.</li> </ul> <p>Kalman Smoother Steps:</p> <ol> <li> <p>Run the Kalman Filter forward in time (from t = 1 to t = T) to get the filtered estimates \\hat{\\boldsymbol{\\alpha}}_{t|t} and covariance \\mathbf{P}_{t|t}.</p> </li> <li> <p>Backward Pass (Smoothing Step): For t = T-1, T-2, \\dots, 1, compute the smoothed state estimate using information from future times.</p> </li> </ol> <p>Smoothing Equations:</p> <ol> <li> <p>Smoothing Gain: \\mathbf{G}_t = \\mathbf{P}_{t|t} \\mathbf{P}_{t+1|t}^{-1}. This gain tells us how much of the future state \\hat{\\boldsymbol{\\alpha}}_{t+1|T} should influence the current state.</p> </li> <li> <p>Smoothed State Estimate: \\hat{\\boldsymbol{\\alpha}}_{t|T} = \\hat{\\boldsymbol{\\alpha}}_{t|t} + \\mathbf{G}_t \\big( \\hat{\\boldsymbol{\\alpha}}_{t+1|T} - \\hat{\\boldsymbol{\\alpha}}_{t+1|t} \\big). This equation adjusts the filtered estimate \\hat{\\boldsymbol{\\alpha}}_{t|t} using the future information from \\hat{\\boldsymbol{\\alpha}}_{t+1|T}.</p> </li> <li> <p>Smoothed Covariance: \\mathbf{P}_{t|T} = \\mathbf{P}_{t|t} + \\mathbf{G}_t \\big( \\mathbf{P}_{t+1|T} - \\mathbf{P}_{t+1|t} \\big) \\mathbf{G}_t'</p> </li> </ol> <p>By combining forward and backward passes, the Kalman smoother effectively reduces noise and enhances estimation accuracy, making it ideal for offline applications like retrospective analysis.</p> <pre><code>@njit\ndef kalman_smoother(y, malphas, Palphas, malphas_pred, Palphas_pred, X):\n    p   = X.shape[1] - 1\n    dim = p+1\n    T   = len(y)\n\n    # preallocate\n    smalphas        = np.zeros((T, dim)) # smoothed mean\n    sPalphas        = np.zeros((T, dim, dim)) # smoothed variance\n    y_smootheds     = np.zeros_like(y)  # smoothed estimate\n\n    # initialize\n    smalphas[-1]    = malphas[-1]\n    sPalphas[-1]    = Palphas[-1]\n\n    for t in np.arange(T-2, -1, -1): # Note that len(y)-2 = T-1; can't initialize from T\n\n        J           = Palphas[t] @ np.linalg.inv(Palphas_pred[t])               # smoother gain\n        smalpha     = malphas[t] + J @ (smalphas[t+1] - malphas_pred[t+1])      # smoothed mean\n        sPalpha     = Palphas[t] + J @ (sPalphas[t+1] - Palphas_pred[t]) @ J.T  # smoothed variance\n        y_smoothed  = X[t] @ smalpha                                            # smoothed estimate\n\n        # store results\n        smalphas[t]     = smalpha\n        sPalphas[t]     = sPalpha\n        y_smootheds[t]  = y_smoothed\n\n    return y_smootheds, smalphas, sPalphas\n</code></pre> <p>We are ready to calculate and plot the Kalman filter and smoother estimates. We run the Kalman filter with large, diagonal \\boldsymbol R, assuming that a lot of the variation in y is measurement error. Additionally, we assume small \\boldsymbol Q, which implies that the state only changes slowly.</p> <pre><code>def plot_kalman(years, y, y_preds=None, y_nowcasts=None, y_smootheds=None):\n    plt.figure(figsize=(14, 4))\n    plt.title('UK Industrial Production Growth')\n    plt.plot(years, y, label='observed', linewidth=1, alpha=0.4)\n    if y_nowcasts is not None:\n        plt.plot(years, y_nowcasts, label='filtered (nowcast)', linestyle='--', linewidth=1, alpha=0.8)\n    if y_preds is not None:\n        plt.plot(years, y_preds, label='prediction', linestyle='-.', linewidth=1, color='black', alpha=0.7)\n    if y_smootheds is not None:\n        plt.plot(years, y_smootheds, label='smoother', linestyle='-.', linewidth=1)\n    plt.legend()\n    plt.show()\n</code></pre> <pre><code>%%capture\ny_preds, y_nowcasts, malphas, Palphas, malphas_pred, Palphas_pred, Ks = kalman_filter(y, \n                                                X, \n                                                Q=np.eye(p+1)/10, # innovations\n                                                R=np.eye(1)*30,  # measurement error\n                                                Palpha_init=np.eye(p+1) * 1E-9)\ny_smootheds, smalphas, sPalphas = kalman_smoother(y, malphas, Palphas, malphas_pred, Palphas_pred, X)\n</code></pre> <pre><code>plot_kalman(years, y, y_nowcasts=y_nowcasts, y_smootheds=y_smootheds)\nplt.show()\n</code></pre> <p></p>"},{"location":"courses/bmetrics/TVP-AR/#gibbs-sampler","title":"Gibbs Sampler","text":"<p>Fantastic. The first step to implementing the full Gibbs sampler is completed. The Kalman filter/smoother is very helpful to generate samples of \\boldsymbol \\alpha_t | \\{\\text{others}\\}. The exact way how to do this was developed in Carter and Kohn (1994) (CK) and De Jong and Shephard (1995). The CK method is </p> <p>The Carter and Kohn method is a technique for drawing samples of the latent states \\boldsymbol{\\alpha}_t from their posterior distribution in a state-space model. This method is commonly used in Bayesian inference, such as in the Gibbs sampling framework, to sample from the joint posterior of the states and other model parameters.</p> <p>We aim to draw samples of \\boldsymbol{\\alpha}_{1:T} from their posterior distribution: p(\\boldsymbol{\\alpha}_{1:T} | y_{1:T}, \\mathbf{X}_{1:T})</p>"},{"location":"courses/bmetrics/TVP-AR/#steps-of-the-carter-and-kohn-method","title":"Steps of the Carter and Kohn Method:","text":"<ol> <li> <p>Forward Pass (Kalman Filtering):</p> <ul> <li>Run the Kalman filter from t = 1 to t = T to obtain:</li> <li>The filtered mean \\hat{\\boldsymbol{\\alpha}}_{t|t}</li> <li>The filtered covariance \\mathbf{P}_{t|t}</li> </ul> </li> <li> <p>Backward Pass (State Sampling):</p> </li> </ol> <p>Draw the states \\boldsymbol{\\alpha}_T, \\boldsymbol{\\alpha}_{T-1}, \\dots, \\boldsymbol{\\alpha}_1 recursively starting from t = T and moving backward:</p> <p>a. Sample \\boldsymbol{\\alpha}_T: Draw \\boldsymbol{\\alpha}_T from:</p> \\boldsymbol{\\alpha}_T \\sim N(\\hat{\\boldsymbol{\\alpha}}_{T|T}, \\mathbf{P}_{T|T}) <p>b. Sample \\boldsymbol{\\alpha}_{t} for t = T-1, T-2, \\dots, 1: For each time step t, sample \\boldsymbol{\\alpha}_t from</p>  \\boldsymbol{\\alpha}_t | \\boldsymbol{\\alpha}_{t+1}, y_{1:T} \\sim N(\\hat{\\boldsymbol{\\alpha}}_{t|T}, \\mathbf{P}_{t|T})  <p>The smoothed mean and covariance are given by:</p> <ul> <li> <p>Smoothed Mean: \\hat{\\boldsymbol{\\alpha}}_{t|T} = \\hat{\\boldsymbol{\\alpha}}_{t|t} + \\mathbf{G}_t (\\boldsymbol{\\alpha}_{t+1} - \\hat{\\boldsymbol{\\alpha}}_{t+1|t})</p> </li> <li> <p>Smoothing Gain: \\mathbf{G}_t = \\mathbf{P}_{t|t} \\mathbf{P}_{t+1|t}^{-1}</p> </li> <li> <p>Smoothed Covariance: \\mathbf{P}_{t|T} = \\mathbf{P}_{t|t} + \\mathbf{G}_t (\\mathbf{P}_{t+1|T} - \\mathbf{P}_{t+1|t}) \\mathbf{G}_t'</p> </li> <li> <p>Forecast Covariance: \\mathbf{P}_{t+1|t} = \\mathbf{P}_{t|t} + \\boldsymbol Q</p> </li> </ul> <p>The function <code>kalman_sample_nb</code> below implements the CK method. I also invoke a routine <code>mvn_sample</code> to sample from a multivariate normal distribution using <code>numba</code>.</p> <pre><code>@njit\ndef mvn_sample(mean, cov):\n    \"\"\"\n    Draws a single sample from a multivariate normal distribution:\n        N(mean, cov)\n\n    Parameters\n    ----------\n    mean : 1D np.ndarray\n        The mean vector of length d.\n    cov  : 2D np.ndarray\n        The (d x d) covariance matrix.\n\n    Returns\n    -------\n    sample : 1D np.ndarray\n        A single draw from the specified MVN distribution.\n    \"\"\"\n    # Force the covariance matrix to be symmetric to avoid numerical issues\n    cov_sym = 0.5 * (cov + cov.T)\n    # Cholesky factor (lower triangular)\n    L = np.linalg.cholesky(cov_sym)\n    # Draw standard normals\n    z = np.random.randn(len(mean))\n    # Sample = mean + L * z\n    return mean + L @ z\n\n@njit\ndef kalman_sample_nb(filtered_states, filtered_variances, Q):\n    \"\"\"\n    Draws from the Kalman smoother backward recursion a la Carter and Kohn (1994).\n    \"\"\"\n    fm, fP = filtered_states.copy(), filtered_variances.copy()\n    T = len(fm)\n    \u03b1_samples   = np.empty((T, len(fm[0])))\n    \u03b1_samples[T-1] = mvn_sample(fm[T-1], fP[T-1]) # sample from the last state\n    for t in range(T-2, -1, -1):\n        V_tp1_t_inv = np.linalg.inv(fP[t] + Q) # Q is constant across time, varies across state variables\n        mean = fm[t] +  fP[t] @ V_tp1_t_inv @ (\u03b1_samples[t+1] - fm[t])  \n        var = fP[t] - fP[t] @ V_tp1_t_inv @ fP[t] \n        \u03b1_samples[t] = mvn_sample(mean, var)\n    return \u03b1_samples\n</code></pre> <p>Perfect! The rest is standard and can be implemented straightforwardly. The samplers for h and \\lambda are defined below. Note that <code>numpy</code> uses the shape-scale parametrization of the Gamma distribution. I prefer the degrees-of-freedom-mean parametrization, hence I define <code>gamma_from_mean_df</code> additionally.</p> <pre><code>def gamma_from_mean_df(means, dfs):\n    means = np.asarray(means, dtype=np.float64)\n    dfs   = np.asarray(dfs, dtype=np.float64)\n    scale = 2*means / dfs   # beta or theta\n    shape = dfs/2           # alpha or k\n    return np.random.gamma(shape, scale)\n\ndef update_lam(\u03b1, h, lam0, nulam0):\n    T, dim  = \u03b1.shape\n    u       = \u03b1[1:,:] - \u03b1[:-1,:]\n    nulam1  = nulam0 + T\n    lam1    = np.zeros_like(lam0)\n    for j in np.arange(dim):\n        lam1[j] = (nulam0[j] * lam0[j] + (u[:,j]**2).sum()*h) / nulam1[j]\n    lam_new = gamma_from_mean_df(1/lam1, nulam1)\n    lam_new = 1/lam_new\n    lam_new[lam_new &gt; 1E6] = 1E6\n    return lam_new\n\n@njit\ndef get_ssr(y, X, \u03b1): \n    y_hat = (X * \u03b1).sum(axis=1)\n    return ((y - y_hat).T @ (y - y_hat))\n\ndef update_h(\u03b1, y, ssq0_inv, nu0):\n    T, _    = \u03b1.shape\n    ssq0    = ssq0_inv\n    nu1     = nu0 + T\n    ssr     = get_ssr(y, X, \u03b1)\n    mu      = 1 / ((ssr + ssq0 * nu0) / nu1)\n    h_new   = gamma_from_mean_df(mu, nu1)\n    return h_new\n</code></pre> <p>Finally, we can put the samplers from conditional distributions together to create the Gibbs sampler. Since we use fast operations and <code>numba</code>s <code>@njit</code> in many places, the Gibbs sampler is conveniently fast!</p> <pre><code>from tqdm import trange\nnu0 = 1\nssq0_inv = 1\nlam0 = np.ones(p+1)\nnulam0 = np.ones(p+1)\n\nburn_in = 1_000\nn_draws = 10_000\nh_init = 1\nT = len(y)\n\n# preallocate\nh_samples = np.zeros(n_draws)\nlam_samples = np.zeros((n_draws, p+1))\nalpha_samples = np.zeros((n_draws, len(y), p+1))\n\n# initialize\nh_sample = 1\nlam_sample = np.ones(p+1)\nalpha_sample = np.zeros((T, p+1))\n\nfor i in trange(-burn_in, n_draws, desc=\"Sampling\", leave=True):\n\n    # run the Kalman filter and sample alphas\n    (y_preds, y_nowcasts, malphas, Palphas, \n     malphas_pred, Palphas_pred, Ks) = kalman_filter(y, \n                                                    X, \n                                                    Q=1/h_sample*np.diag(lam_sample), \n                                                    R=np.eye(1)*1/h_sample,\n                                                    Palpha_init=np.eye(p+1))\n    alpha_sample                     = kalman_sample_nb(malphas, \n                                                        Palphas, \n                                                        Q=np.diag(1/h_sample * lam_sample))\n\n    # update lambda\n    lam_sample  = update_lam(alpha_sample, h_sample, lam0, nulam0)\n\n    # update h\n    h_sample    = update_h(alpha_sample, y, ssq0_inv, nu0)\n\n    if i &gt;= 0:\n        h_samples[i]     = h_sample\n        lam_samples[i]   = lam_sample\n        alpha_samples[i] = alpha_sample\n</code></pre> <pre><code>Sampling: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11000/11000 [00:11&lt;00:00, 943.19it/s]\n</code></pre>"},{"location":"courses/bmetrics/TVP-AR/#posterior-distributions","title":"Posterior Distributions","text":"<p>Perfect. Now we can look at the posterior distributions of all parameters!</p> <pre><code>n_plots = 2*(p+1)+1\nfig, ax = plt.subplots(np.ceil(n_plots/3).astype(int), 3, figsize=(10, 5))\nif ax.ndim == 1:\n    ax = ax.reshape(1, -1)\nfor a in range(p+1):\n    ax[a//3, a%3].hist(alpha_samples[:, :, a].flatten(), bins=75, density=True, color=\"blue\")\n    ax[a//3, a%3].set_title(f'$\\\\alpha_{a}$')\na+=1\nax[a//3, a%3].hist(h_samples, bins=75, density=True, color='green')\nax[a//3, a%3].set_title('$h$')\nfor i in np.arange(a+1, n_plots):\n    j = i-(a+1)\n    ax[i//3, i%3].hist(lam_samples[:,j], bins=75, density=True, color='red')\n    ax[i//3, i%3].set_title(f'$\\\\lambda_{j}$')\nfig.suptitle(\"Posterior Distributions\")\nfig.tight_layout()\n</code></pre> <p></p> <p>Additionally, we can plot the state variables over time.</p> <pre><code># change plot size\nfig, ax = plt.subplots(2, 1, figsize=(10, 5))\nax[0].plot(years, y, linewidth=1, color='green', label='data')\nm = len(smalphas[:, 0])\nax[0].plot(years[-m:], (alpha_samples.mean(axis=0) * X).sum(axis=1), color='blue', linewidth=1, label=r'posterior mean $E[X_t^{\\prime} \\alpha_t | y_{1:T}]$')\ncolors = ['red', 'blue', 'purple', 'black']\nfor k in range(smalphas.shape[1]):\n    ax[1].plot(years[-m:], np.quantile(alpha_samples[:, :, k], [0.25], axis=0).flatten(), linewidth=1, color=colors[k], linestyle='--', alpha=0.5)\n    ax[1].plot(years[-m:], np.quantile(alpha_samples[:, :, k], [0.5], axis=0).flatten(), linewidth=1, label=f'median \u03b1_{k}', color=colors[k])\n    ax[1].plot(years[-m:], np.quantile(alpha_samples[:, :, k], [0.75], axis=0).flatten(), linewidth=1, color=colors[k], linestyle='--', alpha=0.5)\nax[0].legend()\nax[1].legend()\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <p>Finally, we can also write a function to samples data \\tilde y from the model:</p> <pre><code>@njit\ndef draw_e(dim, h_samples):\n    e = np.zeros(dim)\n    for s in range(e.shape[0]):\n        for t in range(e.shape[1]):\n            e[s, t] = np.random.normal(0, 1/h_samples[s]**0.5)\n    return e\n\n@njit\ndef simulate_AR(alpha_samples, e):\n    p = alpha_samples.shape[2] - 1\n    sims = np.zeros((alpha_samples.shape[0], alpha_samples.shape[1]))\n    for s in range(e.shape[0]):\n        y = np.zeros(e.shape[1])\n        for t in range(p, e.shape[1]):\n            y[t] = alpha_samples[s,t,0] + np.vdot(alpha_samples[s,t,1:], np.flip(y[t-p:t])) + e[s, t]\n        sims[s, :] = y\n    return sims\n</code></pre> <pre><code>%%capture\ne = draw_e(alpha_samples.shape[:2], h_samples)\nsim = simulate_AR(alpha_samples, e)\n</code></pre> <pre><code>sim_i = 30\nplt.plot(years, y, linewidth=1, color='green', label='data', alpha=.4)\nplt.plot(years, sim[sim_i], linewidth=1, color='blue', label='sample')\nplt.title('Simulated UK Industrial Production Growth')\nplt.legend()\nplt.show()\n\nprint(\"Compare time s.dev. of some simulated series with that of the data:\\n\")\nprint(\"    simulated: \", sim[sim_i].std())\nprint(\"    data:      \",y.std())\n</code></pre> <p></p> <pre><code>Compare time s.dev. of some simulated series with that of the data:\n\n    simulated:  6.9340546525578235\n    data:       5.00149561679944\n</code></pre> <p>It can be plausible that the posterior predictive or simulated y series is significantly more volatile than the observed data, even by a factor of about three\u2014especially in a time\u2010varying parameter setting with:</p> <ol> <li> <p>Coefficient Uncertainty    When you use MCMC draws of the latent states (or time\u2010varying parameters) and error variance, you are sampling all the ways your model can generate the observed data. This broader \u201cenvelope\u201d can easily permit larger swings than a single historical realization.</p> </li> <li> <p>Priors or Limited Sample Size    If you have a relatively short sample or quite diffuse priors, the random walk variance in the parameters (\\lambda) might be estimated to allow bigger drifts in the AR coefficients, plus the error variance (1/h) might also be relatively large.  </p> </li> <li> <p>Model Misspecification    If the model does not capture some structural features (e.g. breaks in mean, heteroskedasticity not accounted for), the parameter uncertainty might be inflated, again leading to larger predictive variance.</p> </li> </ol> <p>The volatility inflation relative to the single observed time path is normal in a fully Bayesian approach, as it reflects both parameter and observational uncertainty. However, we see extreme outliers in the path of new samples of y. Their may be evidence that the time series is not too well described by the chosen AR-model.  </p>"},{"location":"courses/bmetrics/UCSV/","title":"The Unobserved Component Stochastic Volatility Model","text":""},{"location":"courses/bmetrics/UCSV/#theory","title":"Theory","text":""},{"location":"courses/bmetrics/UCSV/#model-purpose-and-overview","title":"Model Purpose and Overview","text":"<p>Stock and Watson (2007) propose an unobserved components model with stochastic volatility (UCSV) for inflation. The model expresses inflation \\pi_t as the sum of a time\u2010varying trend plus a transitory component, each with time\u2010varying variance. Specifically:</p>      \\pi_t = \\mu_t + \\epsilon_t,      \\quad \\epsilon_t \\sim N\\bigl(0,\\,\\sigma_{\\epsilon, t}^2 \\bigr),\\\\     \\quad \\mu_t = \\mu_{t-1} + \\eta_t,     \\quad \\eta_t \\sim N\\bigl(0,\\,\\sigma_{\\eta, t}^2 \\bigr).  <p>Here, h_t is the volatility of the short\u2010run fluctuations and w_t is the volatility of the trend innovations; both h_t and w_t evolve over time according to their own stochastic processes.</p> <p>Key Findings by Stock and Watson</p> <ol> <li> <p>Changing Inflation Volatility: They show that both the permanent and transitory shocks to inflation exhibit significant variance changes, reflecting important shifts in the volatility of inflation over different historical periods.</p> </li> <li> <p>Improved Model Fit: Allowing time\u2010varying variance for both the trend and transitory shocks helps explain episodes of high and low inflation volatility. This leads to a better empirical fit compared to simpler models with constant volatility.</p> </li> <li> <p>Implications for Forecasting: Time variation in shock variances affects the predictability of inflation. In some periods, the trend may be more stable (lower variance), while in others the transitory component may drive larger short\u2010term swings. These shifts in relative volatility can make inflation more or less forecastable at different times.</p> </li> </ol> <p>Overall, the UCSV approach highlights how inflation can be viewed through the lens of trend + noise, each evolving with its own stochastic volatility, thus capturing both structural shifts and periods of stability in inflation dynamics.</p> <p>Stochastic Processes for the Variances</p> <p>In the Stock and Watson (2007) setup, the two error variances h_t and w_t evolve stochastically over time. Their approach is to assume each variance follows a random walk in log scale, ensuring positivity:</p>  \\ln \\sigma_{\\eta, t}^2 = \\ln \\sigma_{\\eta, t}^2 + \\nu_{\\eta,t}, \\quad \\nu_{\\eta,t} \\sim N\\bigl(0,\\gamma_\\eta^2\\bigr),   \\ln \\sigma_{\\epsilon, t}^2 = \\ln \\sigma_{\\epsilon, t}^2 + \\nu_{\\epsilon,t}, \\quad \\nu_{\\epsilon,t} \\sim N\\bigl(0,\\gamma_\\epsilon^2\\bigr),  <p>Under this specification, the level of each variance changes gradually, capturing shifts in the volatility of both the permanent shocks \\eta_t (with variance h_t) and the transitory shocks \\varepsilon_t (with variance w_t).</p>"},{"location":"courses/bmetrics/UCSV/#the-unobserved-component-stochastic-volatility-model_1","title":"The Unobserved Component Stochastic Volatility Model","text":""},{"location":"courses/bmetrics/UCSV/#theory_1","title":"Theory","text":""},{"location":"courses/bmetrics/UCSV/#model-purpose-and-overview_1","title":"Model Purpose and Overview","text":"<p>Stock and Watson (2007) propose an unobserved components model with stochastic volatility (UCSV) for inflation. The model expresses inflation \\pi_t as the sum of a time\u2010varying trend plus a transitory component, each with time\u2010varying variance. Specifically:</p>      \\pi_t = \\mu_t + \\epsilon_t,      \\quad \\epsilon_t \\sim N\\bigl(0,\\,\\sigma_{\\epsilon, t}^2 \\bigr),\\\\     \\quad \\mu_t = \\mu_{t-1} + \\eta_t,     \\quad \\eta_t \\sim N\\bigl(0,\\,\\sigma_{\\eta, t}^2 \\bigr).  <p>Here, h_t is the volatility of the short\u2010run fluctuations and w_t is the volatility of the trend innovations; both h_t and w_t evolve over time according to their own stochastic processes.</p> <p>Key Findings by Stock and Watson</p> <ol> <li> <p>Changing Inflation Volatility: They show that both the permanent and transitory shocks to inflation exhibit significant variance changes, reflecting important shifts in the volatility of inflation over different historical periods.</p> </li> <li> <p>Improved Model Fit: Allowing time\u2010varying variance for both the trend and transitory shocks helps explain episodes of high and low inflation volatility. This leads to a better empirical fit compared to simpler models with constant volatility.</p> </li> <li> <p>Implications for Forecasting: Time variation in shock variances affects the predictability of inflation. In some periods, the trend may be more stable (lower variance), while in others the transitory component may drive larger short\u2010term swings. These shifts in relative volatility can make inflation more or less forecastable at different times.</p> </li> </ol> <p>Overall, the UCSV approach highlights how inflation can be viewed through the lens of trend + noise, each evolving with its own stochastic volatility, thus capturing both structural shifts and periods of stability in inflation dynamics.</p> <p>Stochastic Processes for the Variances</p> <p>In the Stock and Watson (2007) setup, the two error variances h_t and w_t evolve stochastically over time. Their approach is to assume each variance follows a random walk in log scale, ensuring positivity:</p>  \\ln \\sigma_{\\eta, t}^2 = \\ln \\sigma_{\\eta, t}^2 + \\nu_{\\eta,t}, \\quad \\nu_{\\eta,t} \\sim N\\bigl(0,\\gamma_\\eta^2\\bigr),   \\ln \\sigma_{\\epsilon, t}^2 = \\ln \\sigma_{\\epsilon, t}^2 + \\nu_{\\epsilon,t}, \\quad \\nu_{\\epsilon,t} \\sim N\\bigl(0,\\gamma_\\epsilon^2\\bigr),  <p>Under this specification, the level of each variance changes gradually, capturing shifts in the volatility of both the permanent shocks \\eta_t (with variance h_t) and the transitory shocks \\varepsilon_t (with variance w_t).</p>"},{"location":"courses/bmetrics/UCSV/#stock-and-watsons-approach-to-updating-h_th_t-and-w_tw_t","title":"Stock and Watson\u2019s Approach to Updating h_t and w_t","text":"<p>In the original Stock and Watson (2007) implementation, the variances of the log-vol processes are typically fixed or calibrated rather than fully estimated via a Bayesian updating. This means they set \\gamma_eta^2 and \\gamma_\\epsilon^2 to fixed values, often chosen based on a small training sample or other prior considerations.</p> <p>Under this scheme, the unknown paths \\{\\sigma_{\\eta, t}^2\\} and \\{\\sigma_{\\epsilon, t}^2\\} are each updated using a separate state-space routine (akin to a Kalman filter/smoother), but the \u201cmeasurement error\u201d involved in these auxiliary models is non-normal. Hence, for the UC-SV model, one effectively solves three state-space models when setting up the Gibbs sampler:</p> <ol> <li> <p>Main Model:  Handle this using the standard Carter and Kohn (1994) method of resampling from normal state space models, conditioning on the current values of \\{\\sigma_{\\eta, t}^2\\} and \\{\\sigma_{\\epsilon, t}^2\\} in the Gibbs sampler sweep.    $$      \\pi_t = \\tau_t + \\epsilon_t,       \\quad \\epsilon_t \\sim N\\bigl(0,\\,\\sigma_{\\epsilon, t}^2 \\bigr),\\      \\quad \\tau_t = \\tau_{t-1} + \\eta_t,      \\quad \\eta_t \\sim N\\bigl(0,\\,\\sigma_{\\eta, t}^2 \\bigr).    $$</p> </li> <li> <p>Volatility of Transitory Shocks: Next, subtract \\tau_t from the measurement equation and square it. The RHS is now \\eta_t^2 \\sim \\sigma_{\\eta, t}^2 N(0, 1)^2 distributed. Taking logs, we arrive at \\ln \\sigma_{\\eta, t}^2 + \\ln \\chi^2 on the RHS. Let u_{\\eta, t} \\sim_{iid} \\ln \\chi^2, we have the following state-space model:    $$    \\begin{align}       y^\\star_t := \\ln((\\pi_t - \\tau_t)^2) &amp;= \\ln \\sigma_{\\eta,t}^2 + u_{\\eta, t} \\       \\ln \\sigma_{\\eta, t}^2  &amp;= \\ln \\sigma_{\\eta, t-1}^2 + \\nu_{\\eta, t}    \\end{align}    $$    Because the measurement error is not normally distributed, we cannot use the Kalman Filter directly on this state-space model. If we could, we would be able to apply the Carter &amp; Kohn (1994) method to sample from linear state space models (see previous notebook for an introduction to Carter and Kohn). However, there we use a trick by Shephard and Kim (1998). The distribution of u_{\\eta, t} can be well approximated by a mixture distribution of normals:     $$       u_{\\eta, t} \\sim \\sum_{1\\leq i\\leq 7} \\phi_i N(m_i, \\varsigma_i)    $$    where the \\phi_i are indicators which randomly select a normal variate N(m_i, \\varsigma_i). Each \\phi_i is 1 with probability \\omega_i, and the constraint \\sum_i \\phi_i = 1 applies. The vectors \\omega, m and \\varsigma are fixed and chosen such that \\phi_i N(m_i, \\varsigma_i) approximates the \\ln \\chi^2 distribution well. The insight here is that conditionally on \\phi, the noise u_{\\eta, t}| \\phi is normally distributed. Therefore, in a Gibbs sampling routine, we can first draw \\phi | \\text{others} \\sim \\phi | y^\\star, and in a second step apply the Carter and Kohn sampling scheme. The draw of \\phi_t | \\text{others} \\sim \\phi | y^\\star_t is easily achieved, with (f_N is a normal density)</p> </li> </ol> \\Pr(\\text{component $i$ is drawn at time $t$}) \\propto \\omega_i f_N(y^\\star_t | \\ln \\sigma_{\\eta,t}^2 + m_i - 1.2704, \\varsigma_i^2). <ol> <li>Volatility of Permanent Shocks: The idea for the process of the other volatility is the same. We write the model in state-space form with non-normal measurement error. Then we approximate the measurement error with a normal mixture, making the state space conditionally normal. To the conditionally normal state space model, we apply a forward pass of the Kalman filter and a backward pass of the Kalman smoother combined, during which we draw samples (CK method). The state space is:     $$    \\begin{align}       y^\\star_t := \\ln((\\tau_t - \\tau_{t-1})^2) &amp;= \\ln \\sigma_{\\epsilon,t}^2 + u_{\\epsilon, t} \\       \\ln \\sigma_{\\epsilon, t}^2  &amp;= \\ln \\sigma_{\\epsilon, t-1}^2 + \\nu_{\\epsilon, t}    \\end{align}    $$    By constructing a similar state-space as for \\ln(\\eta_t^2), Stock and Watson again use a mixture approximation for the log-chi-squared distribution to sample \\ln h_t.</li> </ol> <p>Consequently, while each volatility path is updated in a \u201cKalman-like\u201d fashion, the non-Gaussian nature of \\ln(\\varepsilon_t^2) and \\ln(\\eta_t^2) means additional mixture-indicator steps are required, but the innovation variances \\sigma_h^2 and \\sigma_w^2 for those log-vol processes remain fixed throughout the estimation. </p>"},{"location":"courses/bmetrics/UCSV/#implementation","title":"Implementation","text":""},{"location":"courses/bmetrics/UCSV/#normal-mixture-approximation","title":"Normal Mixture Approximation","text":"<p>We begin the coding part of this notebook by confirming that the normal mixture approximates the distribution of \\ln \\chi^2 well. Let\u2019s make this an exercise. The mixture weights and parameters are:</p>  \\begin{align*}     m &amp;= [-10.12999, -3.97281, -8.56686, 2.77786, 0.61942, 1.79518, -1.08819] \\\\     \\varsigma^2 &amp;= [5.79596, 2.61369, 5.17950, 0.16735, 0.64009, 0.34023, 1.26261] \\\\     \\omega &amp;= [0.00730, 0.10556, 0.00002, 0.04395, 0.34001, 0.24566, 0.25750] \\end{align*}  <p>Task [Mixture Approximation of \\log \\chi^2]: Write a function, which will generate draws of the mixture indicators given a weights vector (here, such vector is \\omega). Second, write a function to draw from the mixture component specified by the indicator given as input. Third, compare the samples from the mixture distribution to samples of a \\log \\chi^2 variable. Plot the sampling distributions and make sure they are close.</p> <pre><code>import numpy as np\nfrom numba import njit\nimport matplotlib.pyplot as plt\nfrom tqdm import trange\nimport pandas as pd\n\n# we need a function to draw the indicators for a mixture of normals\ndef draw_from_mixture(components):\n    \"\"\"\n    Draws samples from the normal distributions corresponding to the specified mixture components.\n\n    Parameters:\n    components (array-like): Array of mixture component indices (1 to 7).\n\n    Returns:\n    np.ndarray: An array of samples drawn from the corresponding normal distributions.\n    \"\"\"\n    # Updated mixture component parameters (mi, sigma_c^2 from Table 4)\n    mixture_parameters = np.array([\n        (-10.12999, 5.79596),  # Component 1\n        (-3.97281, 2.61369),  # Component 2\n        (-8.56686, 5.17950),  # Component 3\n        (2.77786, 0.16735),   # Component 4\n        (0.61942, 0.64009),   # Component 5\n        (1.79518, 0.34023),   # Component 6\n        (-1.08819, 1.26261)   # Component 7\n    ])\n\n    # Ensure components are valid\n    if not np.all((1 &lt;= components) &amp; (components &lt;= len(mixture_parameters))):\n        raise ValueError(\"All component indices must be between 1 and 7.\")\n\n    # Get the parameters for the specified components\n    mu_c = mixture_parameters[components - 1, 0]  # Means\n    sigma2_c = mixture_parameters[components - 1, 1]  # Variances\n    sigma_c = np.sqrt(sigma2_c)  # Standard deviations\n\n    # Draw samples from the corresponding normal distributions\n    return np.random.normal(mu_c, sigma_c) - 1.2704\n\n# I write this function rather than using using pre-built functions\n# to ensure that the function is compatible with numba\n@njit\ndef discrete_sample(p):\n    \"\"\"\n    Returns one index sampled according to probability vector p.\n    p should sum to 1.\n    \"\"\"\n    u = np.random.rand()\n    cdf = 0.0\n    for i in range(len(p)):\n        cdf += p[i]\n        if u &lt; cdf:\n            return i\n    return len(p) - 1  # Fallback in case of floating-point rounding\n\ndef draw_mixture_index(size=1):\n    \"\"\"\n    Draws a sample of mixture indexes.\n\n    Parameters:\n    size (int): Number of samples to draw.\n\n    Returns:\n    np.ndarray: An array of samples from the mixture index.\n    \"\"\"\n    # Mixture probabilities (pi from Table 4)\n    mixture_probabilities = np.array([0.00730, 0.10556, 0.00002, 0.04395, 0.34001, 0.24566, 0.25750])\n\n    # Draw samples from the mixture index\n    return np.array([discrete_sample(mixture_probabilities) + 1 for _ in range(size)])\n\n# Example usage\nn = 1_000_000\nc = draw_mixture_index(size=n)  # Draw a component index\nmixture_samples = draw_from_mixture(c)  # Draw from the corresponding normal distribution\ntrue_samples = np.log(np.abs(np.random.normal(0, 1, n)))*2\n\n# Plot the true and mixture samples\nplt.figure(figsize=(7, 4))\nplt.hist(true_samples[true_samples &gt; -15], bins=100, alpha=0.5, label=\"True Samples\", color='blue', density=True, histtype='step', linewidth=1.5)\nplt.hist(mixture_samples[mixture_samples &gt; -15], bins=100, alpha=0.75, label=\"Mixture Samples\", color='red', density=True, histtype='step', linewidth=1.5)\nplt.legend()\nplt.show()\nplt.close()\n</code></pre> <p></p>"},{"location":"courses/bmetrics/UCSV/#the-data","title":"The Data","text":"<p>The data we will be working with can be found on Dimitris Korobilis\u2019 website, where you can also find his full replication of the UC-SV model with some extra bells and whistles. I suggest popping by if you want to learn some more of the advanced Bayesian stuff.</p> <p>For now, place the files <code>infl_data.dat</code> and <code>yearlabb.dat</code> somewhere where you can access them.</p> <pre><code># import data from /data/stock_watson_infl/infl_data.dat\ndata = np.loadtxt('./data/stock_watson_inflation/infl_data.dat')\nyears_data = np.loadtxt('./data/stock_watson_inflation/yearlab.dat', usecols=0)\ncolnames = ['CPI', 'GPI', 'GDP_defl']\ndata_col = 0\n\n# make stuff inflation rates (annualized)\nyears = years_data[4:]\ny = (data[4:,data_col] - data[:-4,data_col])/data[:-4,data_col] # inflation time series\n\n# years = np.arange(2007 - len(y)/4, 2007, 1/4)\n# y = y[years &gt;= 1953]\n# years = years[years &gt;= 1953]\n# plt.plot(years, y)\n\n# plot the data\nfig, axs = plt.subplots(1, 2, figsize=(10, 4))\naxs[0].plot(years_data, data, label=colnames)\naxs[1].plot(years, y, label='CPI headline inflation (YoY)')\naxs[0].legend()\naxs[1].legend()\nplt.show()\nplt.close()\n</code></pre> <p></p>"},{"location":"courses/bmetrics/UCSV/#the-model","title":"The Model","text":"<p>Next step is to write down a proper Gibbs sampler for the UC-SV model. And of course, that is easier said than done. We accomplish it in a sequence of steps, described in the following pseudo code.</p> <pre><code>INPUT: \n  {\u03c0_t}_{t=1..T}, observed inflation data\n  hyperparameters {\u03b3_\u03b7^2, \u03b3_\u03b5^2}, or initial guesses if these are fixed\n  number of MCMC iterations (N + burn_in)\n\nINITIALIZE:\n  1. For t=1..T:\n       \u2022 Set \u03bc_t^(0) = some initial guess (e.g., 0 or an OLS-based trend)\n       \u2022 Set ln(\u03c3_{\u03b7,t}^2)^(0) = constant (e.g., log of small value)\n       \u2022 Set ln(\u03c3_{\u03b5,t}^2)^(0) = constant\n  2. Possibly initialize mixture indicators if using log-chi^2 approximation\n\nFOR iteration i = 1 TO (N + burn_in):\n\n  (A) Sample the entire path {\u03bc_t} given {\u03c3_{\u03b7,t}^2, \u03c3_{\u03b5,t}^2}:\n      1. Use a forward\u2010filter / backward\u2010sample routine (Carter\u2010Kohn style):\n         - State equation: \u03bc_t = \u03bc_{t-1} + \u03b7_t, Var(\u03b7_t)=\u03c3_{\u03b7,t}^2\n         - Measurement: \u03c0_t = \u03bc_t + \u03b5_t, Var(\u03b5_t)=\u03c3_{\u03b5,t}^2\n         - Because \u03c3_{\u03b7,t}^2, \u03c3_{\u03b5,t}^2 are known in this step (from prev iteration),\n           treat them as time\u2010varying \u201cQ_t\u201d and \u201cR_t\u201d in the Kalman filter.\n      2. The result is a new draw: {\u03bc_t}^(i).\n\n  (B) Sample log\u2010vol {ln(\u03c3_{\u03b5,t}^2)} using the residuals u_t:\n      1. Compute u_t = \u03c0_t - \u03bc_t, for t=1..T.\n      2. Let y_t = ln(u_t^2 + offset).\n      3. Similarly to step (B):\n         - Draw mixture indicators for y_t given current ln(\u03c3_{\u03b5,t}^2).\n         - Treat ln(\u03c3_{\u03b5,t}^2) as a random walk:\n             ln(\u03c3_{\u03b5,t}^2) = ln(\u03c3_{\u03b5,t-1}^2) + \u03bd_{\u03b5,t}, Var(\u03bd_{\u03b5,t})=\u03b3_\u03b5^2.\n         - Forward\u2010filter/backward\u2010sample to obtain {ln(\u03c3_{\u03b5,t}^2)}^(i).\n      4. Convert back to {\u03c3_{\u03b5,t}^2}^(i).\n\n  (C) Sample log\u2010vol {ln(\u03c3_{\u03b7,t}^2)} using the increments of \u03bc_t:\n      1. Compute \u03b7_t = \u03bc_t - \u03bc_{t-1}, for t=2..T.\n      2. Let v_t = ln(\u03b7_t^2 + offset), to avoid ln(0).\n      3. Use a mixture\u2010of\u2010normals approximation or a log(\u03c7^2) approach:\n         - For each t=2..T, draw a mixture indicator based on v_t and current ln(\u03c3_{\u03b7,t}^2).\n         - Construct a state\u2010space for ln(\u03c3_{\u03b7,t}^2), which evolves as:\n             ln(\u03c3_{\u03b7,t}^2) = ln(\u03c3_{\u03b7,t-1}^2) + \u03bd_{\u03b7,t}, Var(\u03bd_{\u03b7,t})=\u03b3_\u03b7^2.\n         - Apply a forward\u2010filter/backward\u2010sample step with \"observations\" = v_t - (mixture means).\n      4. The output is a new path {ln(\u03c3_{\u03b7,t}^2)}^(i), thus {\u03c3_{\u03b7,t}^2}^(i).\n\n  (D) [OPTIONAL] If \u03b3_\u03b7^2 or \u03b3_\u03b5^2 are to be updated (we don't do this here):\n      - gather the sum of squared increments in ln(\u03c3_{\u03b7,t}^2) or ln(\u03c3_{\u03b5,t}^2).\n      - draw from an appropriate Inverse\u2010Gamma posterior or similar.\n      Otherwise, if \u03b3_\u03b7^2, \u03b3_\u03b5^2 are fixed, skip this.\n\n  (E) If i &gt; burn_in:\n      Store {\u03bc_t}^(i), {\u03c3_{\u03b7,t}^2}^(i), {\u03c3_{\u03b5,t}^2}^(i)\n\nEND FOR\n\nOUTPUT:\n  Posterior draws for the trend {\u03bc_t}, \n  the permanent shock volatility {\u03c3_{\u03b7,t}^2}, \n  and the transitory shock volatility {\u03c3_{\u03b5,t}^2}.\n</code></pre> <p>We begin by defining functions for drawing the mixture indexes conditional on the data and the current sweep of the Gibbs sampler. </p> <pre><code>@njit\ndef random_choice_nb(p):\n    \"\"\"\n    Returns 'size' samples (as an array of indices) from the distributions in p.\n    rows of p should sum to 1.\n    \"\"\"\n    size = p.shape[0]\n    out = np.empty(size, dtype=np.int64)\n    for s in range(size):\n        out[s] = discrete_sample(p[s])\n    return out\n\n@njit\ndef draw_mixture_index_cond(obss, lvls):\n\n    # preallocate\n    mixture_weights = np.zeros((len(obss), 7))\n\n    mixture_qs = np.array([0.00730, 0.10556, 0.00002, 0.04395, 0.34001, 0.24566, 0.25750])\n\n    mixture_parameters = np.array([\n            (-10.12999, 5.79596), # Component 1\n            (-3.97281, 2.61369),  # Component 2\n            (-8.56686, 5.17950),  # Component 3\n            (2.77786, 0.16735),   # Component 4\n            (0.61942, 0.64009),   # Component 5\n            (1.79518, 0.34023),   # Component 6\n            (-1.08819, 1.26261)   # Component 7\n        ])\n\n    for i, (obs, lvl) in enumerate(zip(obss, lvls)):\n        # Compute the mixture weights based on the updated parameters\n        mixture_weights[i] = mixture_qs * np.exp(-0.5 * (obs - mixture_parameters[:, 0] + 1.2704 - lvl)**2 / mixture_parameters[:, 1]) / mixture_parameters[:, 1]**0.5\n        mixture_weights[i] /= np.sum(mixture_weights[i])\n\n    # Draw `size` indices based on the weights    \n    indices = random_choice_nb(mixture_weights)\n\n    # Return indices in 1-based format (components are 1 through 7)\n    return indices + 1, mixture_weights\n\n_, _ = draw_mixture_index_cond(np.array([0., 0.2]), np.array([0., 0.1]))\n_ = random_choice_nb(np.array([0.00730, 0.10556, 0.00002, 0.04395, 0.34001, 0.24566, 0.25750])[np.newaxis, :])\n\n# check that the functions runs fast\n%time _   = random_choice_nb(np.array([0.00730, 0.10556, 0.00002, 0.04395, 0.34001, 0.24566, 0.25750])[np.newaxis, :])\n%time _,_ = draw_mixture_index_cond(np.array([0., 0.2]), np.array([0., 0.1]))\n</code></pre> <pre><code>CPU times: user 5 \u03bcs, sys: 0 ns, total: 5 \u03bcs\nWall time: 6.91 \u03bcs\nCPU times: user 19 \u03bcs, sys: 0 ns, total: 19 \u03bcs\nWall time: 19.8 \u03bcs\n</code></pre> <p>With working functions to draw from the mixture distribution, we turn to the Carter-Kohn sampler. The function <code>sample_univ_lss</code> specifically implements Carter and Kohn for a linear state space with time varying variances and univariate observation and state equations. It often makes sense to rewrite your state-space model from scratch from a computational perspective. While matrix algebra can express the Kalman filter and resampling procedure neatly, writing functions which deal with general linear state space models often run orders of magnitudes slower. This is due to lower compatibility with <code>numba</code> and frequently encountered matrix inverses, which hugely simplify if we are dealing with scalars or with diagonal matrices.</p> <pre><code>@njit\ndef sample_univ_lss(\n    y,\n    a=None,\n    F=None,\n    Q=None,\n    c=None,\n    H=None,\n    R=None,\n    x0_mean=0.0,\n    x0_var=1.0\n):\n    \"\"\"\n    Samples the latent states {x_t} from a univariate, time-varying linear\n    Gaussian state-space model:\n\n      State equation:       x_{t+1} = a[t+1] + F[t+1]*x_t + \u03b5_{t+1},      Var(\u03b5_{t+1}) = Q[t+1]\n      Measurement equation: y_t = c[t] + H[t]*x_t + \u03c9_t,                 Var(\u03c9_t) = R[t]\n\n    Indexing convention:\n      - t ranges from 0 to T-1.\n      - y[t] is observed at time t.\n      - x0_mean, x0_var are the prior mean and variance for x_0.\n      - Arrays (a, F, Q, c, H, R) each have length T (univariate).\n      - By default, a[t] = 0, c[t] = 0, F[t] = 1, H[t] = 1 (if passed as None).\n      - Q and R must be explicitly specified (no default).\n\n    Methodology follows Carter and Kohn (1994). See also Primiceri (2004).\n\n    Parameters\n    ----------\n    y : np.ndarray of shape (T,)\n        Observations y[0..T-1].\n    a : np.ndarray of shape (T,), optional\n        Time-varying intercept for x_{t+1}. If None, a[t]=0 for all t.\n    F : np.ndarray of shape (T,), optional\n        Time-varying coefficient for x_{t+1} = a[t+1] + F[t+1]*x_t + ...\n        If None, F[t]=1 for all t.\n    Q : np.ndarray of shape (T,)\n        Time-varying variance of the state noise for x_{t+1}.\n    c : np.ndarray of shape (T,), optional\n        Time-varying intercept in y_t = c[t] + H[t]*x_t + ...\n        If None, c[t]=0 for all t.\n    H : np.ndarray of shape (T,), optional\n        Time-varying coefficient in y_t = c[t] + H[t]*x_t + ...\n        If None, H[t]=1 for all t.\n    R : np.ndarray of shape (T,)\n        Time-varying variance of the measurement noise.\n    x0_mean : float, optional\n        Prior mean for x_0. Default is 0.0.\n    x0_var : float, optional\n        Prior variance for x_0. Default is 10.0.\n\n    Returns\n    -------\n    x_draw : np.ndarray of shape (T,)\n        A single draw for the latent states x_0, ..., x_{T-1}.\n    \"\"\"\n    T = len(y)\n\n    # Provide defaults if any are None\n    if a is None:\n        a = np.zeros(T)\n    if F is None:\n        F = np.ones(T)\n    if c is None:\n        c = np.zeros(T)\n    if H is None:\n        H = np.ones(T)\n    if Q is None:\n        Q = np.ones(T)\n    if R is None:\n        R = np.ones(T)\n\n    # Filtered means and variances\n    alpha_filt = np.zeros(T)\n    P_filt = np.zeros(T)\n\n    # -------------------------------\n    # Forward filter\n    # -------------------------------\n    # Initialization from prior for x_0\n    alpha_pred = x0_mean\n    P_pred = x0_var\n\n    for t in range(T):\n        # Measurement update: y[t] = c[t] + H[t]*x[t] + noise, Var(noise)=R[t]\n        yhat = c[t] + H[t]*alpha_pred\n        res = y[t] - yhat\n        S_t = H[t]**2 * P_pred + R[t]\n        K_t = (P_pred * H[t]) / S_t\n\n        alpha_filt[t] = alpha_pred + K_t*res\n        P_filt[t] = (1 - K_t*H[t]) * P_pred\n\n        # Time update for x_{t+1}, if t &lt; T-1\n        if t &lt; T-1:\n            alpha_pred = a[t+1] + F[t+1]*alpha_filt[t]\n            P_pred = (F[t+1]**2)*P_filt[t] + Q[t+1]\n\n    # -------------------------------\n    # Backward sampler\n    # -------------------------------\n    x_draw = np.zeros(T)\n\n    # Sample x_{T-1} from N(alpha_filt[T-1], P_filt[T-1])\n    x_draw[T-1] = np.random.normal(alpha_filt[T-1], np.sqrt(P_filt[T-1]))\n\n    # For t = T-2 down to 0, sample x_t | x_{t+1}, data\n    for t in range(T-2, -1, -1):\n        F_val = F[t+1]\n        A_val = a[t+1]\n        denom = F_val**2 * P_filt[t] + Q[t+1]\n\n        if denom &lt; 1e-14:\n            post_mean = alpha_filt[t]\n            post_var  = P_filt[t]\n        else:\n            x_tplus1_pred = A_val + F_val*alpha_filt[t]\n            K_smooth = (P_filt[t]*F_val) / denom\n            post_mean = alpha_filt[t] + K_smooth*(x_draw[t+1] - x_tplus1_pred)\n            post_var  = P_filt[t] - K_smooth*(F_val*P_filt[t])\n\n        x_draw[t] = np.random.normal(post_mean, np.sqrt(post_var))\n\n    return x_draw\n\ns2_eta = np.ones_like(y)\ns2_eps = np.ones_like(y)\nsample_univ_lss(y, \n                Q = s2_eps,\n                R = s2_eta)\n\n%time _ = sample_univ_lss(y, Q = s2_eps, R = s2_eta)\n</code></pre> <pre><code>CPU times: user 130 \u03bcs, sys: 0 ns, total: 130 \u03bcs\nWall time: 133 \u03bcs\n</code></pre> <p>We are now ready to complete the Gibbs sampler. The following implementation runs efficiently. Frquent use of <code>numba</code> and tailor made code allow us to draw 10,000 samples in under 3 seconds.</p> <pre><code>## sampling parameters\nn_draws = 20_000\nburn_in = 5_000\n\n## mixture parameters\nmixture_parameters = np.array([\n        (-10.12999, 5.79596), # Component 1\n        (-3.97281, 2.61369),  # Component 2\n        (-8.56686, 5.17950),  # Component 3\n        (2.77786, 0.16735),   # Component 4\n        (0.61942, 0.64009),   # Component 5\n        (1.79518, 0.34023),   # Component 6\n        (-1.08819, 1.26261)   # Component 7\n    ])\n\n## variables that change in each sweep\ns2_eta     = np.ones(len(y)) # process innovation variances\nlog_s2_eta = np.log(s2_eta)\ns2_eps     = np.ones(len(y)) # measurement noise variances\nlog_s2_eps = np.log(s2_eps)\n\n## SS subsystems for process innovation/measurement noise\ns2_v_eta = .02 # variance of state innovation in sub-SS-model (proc innovation)\ns2_v_eps = .02 # variance of observation noise in sub-SS-model (meas noise)\nc = 1E-5   # stabilizing constant for log transformation\n\n## preallocate\nT = len(y)\ns2_eta_samples = np.zeros((n_draws, T))\ns2_eps_samples = np.zeros((n_draws, T))\nalpha_samples  = np.zeros((n_draws, T))\n\nfor i in trange(-burn_in, n_draws, desc=\"Sampling\", leave=True):\n    ### ALPHA\n    # Estimate the inflation trend and noise component using KF\n    # and sample the latent states using CK sampler\n    alpha = sample_univ_lss(y, Q = s2_eta, R = s2_eps)\n\n    ### ETA\n    ## sample mixture components for measurement innov variance\n    y_star            = np.log((y - alpha)**2+c)                                      # dep var in transformed state space submodel\n    sample_indices, _ = draw_mixture_index_cond(y_star, log_s2_eta)                   # draw mixture indices\n    params            = mixture_parameters[sample_indices-1] - np.array([1.2704, 0.]) # obtain the mixture parameters\n    ## sample levels of observation noise variances\n    log_s2_eta        = sample_univ_lss(y_star,                                        \n                             Q=np.repeat(s2_v_eta, T) ,                               # state equation var\n                             R=params[:,1],                                           # measurement equation var\n                             c=params[:,0],                                           # measurement equation mean \n                             x0_var = 1E9,\n                             x0_mean = 1E-4\n                             )                \n    s2_eta            = np.exp(log_s2_eta)\n\n    ### EPSILON\n    ## sample mixture components for process noise variance\n    y_star            = np.log((alpha[1:] - alpha[:-1])**2+c)\n    sample_indices, _ = draw_mixture_index_cond(y_star, log_s2_eps)\n    params            = mixture_parameters[sample_indices-1] - np.array([1.2704, 0.])\n    ## sample states log(s2_eps_t) for t = 2, ..., T\n    log_s2_eps        = sample_univ_lss(y_star,                                        \n                            Q=np.repeat(s2_v_eps, T-1) ,                             # state equation var\n                            R=params[:,1],                                           # measurement equation var\n                            c=params[:,0],                                           # measurement equation mean \n                            x0_var = 1E9,\n                            x0_mean = 1E-4\n                            )\n    log_s2_eps_0      = log_s2_eps[0] - np.random.normal(scale=np.sqrt(s2_v_eps))    # sample s2_eps_0     \n    log_s2_eps        = np.concatenate(([log_s2_eps_0], log_s2_eps))                 # concatenate with s2_eps_0\n    s2_eps            = np.exp(log_s2_eps)\n\n    if i &gt;= 0:\n        s2_eta_samples[i] = s2_eta\n        s2_eps_samples[i] = s2_eps\n        alpha_samples[i]  = alpha\n</code></pre> <pre><code>Sampling: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 25000/25000 [00:04&lt;00:00, 5091.21it/s]\n</code></pre>"},{"location":"courses/bmetrics/UCSV/#visual-analysis","title":"Visual Analysis","text":"<p>Without going in too much detail, we can plot the </p> <pre><code>def plot_ts_quantiles(ax, years, dat, quantiles, title, x_select=None):\n    if x_select is not None:\n        data = dat.copy()[:, x_select]\n        x = years[x_select]\n    else:\n        data = dat.copy()\n        x = years.copy()\n    from matplotlib.ticker import FormatStrFormatter\n    quantiles = pd.DataFrame(data).quantile(quantiles, axis=0).T.to_numpy()\n    ax.plot(x, quantiles[:, 1], label='median', color='black', lw=.8)\n    ax.fill_between(x, quantiles[:, 0], quantiles[:, 2], alpha=0.5, label='80%-interval', color='lightgrey', ec=\"black\", linewidth=.8, linestyle='--')\n    ax.set_xticks(x[::20])\n    ax.set_xticklabels(x[::20], fontsize=8)\n    ax.set_xlabel('Year', fontsize=10)\n    ax.set_yticks(ax.get_yticks())\n    ax.set_yticklabels(ax.get_yticks(), fontsize=8)\n    ax.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))  # round to 2 decimals\n    ax.xaxis.set_major_formatter(FormatStrFormatter('%.0f'))  # round to 0 decimals\n    ax.legend()\n    ax.set_title(title)\n    return None\n\nfig, axs = plt.subplots(nrows=3, ncols=1, figsize=(6, 10), sharex=False)\nplot_ts_quantiles(axs[0], years, alpha_samples, [0.1, 0.5, 0.9], 'Inflation Level', x_select=(years &gt; 1954))\nplot_ts_quantiles(axs[1], years, np.sqrt(s2_eps_samples), [0.1, 0.5, 0.9], 'State Innovation SD', x_select=(years &gt; 1954))\nplot_ts_quantiles(axs[2], years, np.sqrt(s2_eta_samples), [0.1, 0.5, 0.9], 'Measurement Noise SD', x_select=(years &gt; 1954))\naxs[1].set_xlabel('Year', fontsize=10)\nfig.tight_layout()\n</code></pre> <p></p>"},{"location":"courses/sem/","title":"Solving Economic Models","text":"<p>This course is targeted at PhD students and practitioners, who would like to improve their coding skills in macroeconomics. The notebooks teach core scientific computing libraries (<code>numpy</code>, <code>numba</code>, <code>scipy</code>) and functional and object-oriented programming style by example. Examples are economic applications. As the course progresses, notebooks become increasingly focused on applying the coding concepts to state-of-the-art methods in computational economics. </p> <p>The github page associated with the course can be found here: </p> <p> </p>"},{"location":"courses/sem/1-numpy/","title":"Numpy Basics","text":"<p>To get started, install <code>numpy</code> using <code>pip</code> or <code>conda</code> package managers, or make sure that you have a recent version of numpy in your active Python environment.</p> <pre><code># as usual, import the module\nimport numpy as np # np is the standard name of numpy\n</code></pre>"},{"location":"courses/sem/1-numpy/#1-arrays","title":"1. Arrays","text":"<p>The fundamental object in numpy are numpy arrays, <code>np.array</code>s. They are iterable objects which behave much like lists. They can have many dimensions. Create an array as follows. </p> <pre><code>a = np.array([1, 2, 3]) # create a numpy array from a list\nA = np.array([[1, 2, 3], [4, 5, 6]]) # create a 2-d array from a list with two lists\nprint(\"a = \", a, '\\n', \"A = \", A, sep=\"\") # extra bit of python: sep argument in print function defines the separating string\n</code></pre> <pre><code>a = [1 2 3]\nA = [[1 2 3]\n [4 5 6]]\n</code></pre> <p>You cannot create numpy arrays from any kind of list. If your list contains integers and floats, integers will be \u2018up-cast\u2019 to the float datatype. If your list contains string, all else will be up-cast to string. What if it contains another datatype, like a list? Brace for an error.</p> <pre><code>print(\"an up-cast array to float: \", np.array([1.2, 1, 3]))\nprint(\"an up-cast array to str: \", np.array(['1.2', 1, 3]))\n\n#print(\"something illegal: \", np.array([1, 2, 3, [1, 2]]) ) # this will throw an error\n</code></pre> <pre><code>an up-cast array to float:  [1.2 1.  3. ]\nan up-cast array to str:  ['1.2' '1' '3']\n</code></pre> <p>Exercise: Use the \u2018dtype\u2019 argument to save the list <code>[1.9, 1, 3]</code> as a numpy array consisting of str/float/int/bool. What do you notice in the <code>int</code>-case? In the <code>bool</code>-case?</p> <pre><code>print(\"Begin with list: \", [1.9, 1, 3])\nprint(\"forced data-type to str: \", np.array([1.9, 1, 3], dtype=int))\nprint(\"forced data-type to int: \", np.array([1.9, 1, 3], dtype=str))\nprint(\"forced data-type to int: \", np.array([1.9, 1, 3], dtype=bool))\n</code></pre> <pre><code>Begin with list:  [1.9, 1, 3]\nforced data-type to str:  [1 1 3]\nforced data-type to int:  ['1.9' '1' '3']\nforced data-type to int:  [ True  True  True]\n</code></pre> <p>For Reference: Data Types</p> Data type Description <code>bool_</code> Boolean (True or False) stored as a byte <code>int_</code> Default integer type (same as C <code>long</code>; normally either <code>int64</code> or <code>int32</code>) <code>intc</code> Identical to C <code>int</code> (normally <code>int32</code> or <code>int64</code>) <code>intp</code> Integer used for indexing (same as C <code>ssize_t</code>; normally either <code>int32</code> or <code>int64</code>) <code>int8</code> Byte (-128 to 127) <code>int16</code> Integer (-32768 to 32767) <code>int32</code> Integer (-2147483648 to 2147483647) <code>int64</code> Integer (-9223372036854775808 to 9223372036854775807) <code>uint8</code> Unsigned integer (0 to 255) <code>uint16</code> Unsigned integer (0 to 65535) <code>uint32</code> Unsigned integer (0 to 4294967295) <code>uint64</code> Unsigned integer (0 to 18446744073709551615) <code>float_</code> Shorthand for <code>float64</code>. <code>float16</code> Half precision float: sign bit, 5 bits exponent, 10 bits mantissa <code>float32</code> Single precision float: sign bit, 8 bits exponent, 23 bits mantissa <code>float64</code> Double precision float: sign bit, 11 bits exponent, 52 bits mantissa <code>complex_</code> Shorthand for <code>complex128</code>. <code>complex64</code> Complex number, represented by two 32-bit floats <code>complex128</code> Complex number, represented by two 64-bit floats <p>Source: Jake VanderPlas (2016), Python Data Science Handbook Essential Tools for Working with Data, O\u2019Reilly Media.</p> <p>Exercise: Explore the commands <code>np.zeros</code>, <code>np.ones</code>, <code>np.full</code> as follows:</p> <ul> <li>instantiate a <code>(2, 3, 4)</code> array with each of the commands</li> <li>select element <code>[0, 0, 2]</code> for each object and set its value to <code>100</code></li> <li>print each object.</li> </ul> <pre><code>A = np.zeros(shape=(2, 3, 4))\nB = np.ones(shape=(2, 3, 4))\nC = np.full((2, 3, 4), 4) # different syntax for full\n\nfor x in [A, B, C]:\n    x[0,0,2] = 100\n\n# extra bit of python syntax:\n# \"abc\" * 10 produces a string which repeats \"abc\" 10 times.\nprint(A, \"\\n \", \"-\" * 70,  \"\\n\",  B, \"\\n \", \"-\" * 70,  \"\\n\", C) \n</code></pre> <pre><code>[[[  0.   0. 100.   0.]\n  [  0.   0.   0.   0.]\n  [  0.   0.   0.   0.]]\n\n [[  0.   0.   0.   0.]\n  [  0.   0.   0.   0.]\n  [  0.   0.   0.   0.]]] \n  ---------------------------------------------------------------------- \n [[[  1.   1. 100.   1.]\n  [  1.   1.   1.   1.]\n  [  1.   1.   1.   1.]]\n\n [[  1.   1.   1.   1.]\n  [  1.   1.   1.   1.]\n  [  1.   1.   1.   1.]]] \n  ---------------------------------------------------------------------- \n [[[  4   4 100   4]\n  [  4   4   4   4]\n  [  4   4   4   4]]\n\n [[  4   4   4   4]\n  [  4   4   4   4]\n  [  4   4   4   4]]]\n</code></pre> <p>Arrays have methods and attributes associated with them. An attribute is <code>dtype</code>, another attribute is <code>shape</code>. We will cover methods below.</p> <pre><code>print(A.dtype, \"\\n\", A.shape, sep=\"\")\n</code></pre> <pre><code>float64\n(2, 3, 4)\n</code></pre> <p>The command <code>np.empty</code> instantiates an empty array, the command <code>np.empty_like</code> instantiates some array which has the same dimension and data type as a given array. Empty arrays are computationally less wasteful to produce than e.g. <code>np.zeros</code>, if one replaces the elements in some process anyways. The print function called on an empty array produces mostly garbage, don\u2019t worry about this.</p> <p>The following two are equivalent: <code>np.empty(shape = A.shape)</code> and <code>np.empty_like(A)</code></p> <pre><code>print(np.empty(shape = A.shape).dtype)\nprint(np.empty_like(A).shape)\nprint(np.empty((2, 3)))\n</code></pre> <pre><code>float64\n(2, 3, 4)\n[[4.9e-324 9.9e-324 1.5e-323]\n [2.0e-323 2.5e-323 3.0e-323]]\n</code></pre>"},{"location":"courses/sem/1-numpy/#array-indexing","title":"Array Indexing","text":"<p>Indexing arrays is easy and best done by example. We can select elements by regular indexing and Boolean indexing:</p> <pre><code>A = np.matrix([[1, 2, 3], [4, 5, 6]]) # a matrix is basically a (n,m)-array\nprint(A)\n\n# indexing\nA[1,0] = A[1,0]*10 # multiply element [0,1] by 10\nprint(A)\n\n# boolean mask\nA[A &lt; 3.2] = 0 # replace all elements &lt; 3.2 by 0\nprint(A)\n</code></pre> <pre><code>[[1 2 3]\n [4 5 6]]\n[[ 1  2  3]\n [40  5  6]]\n[[ 0  0  0]\n [40  5  6]]\n</code></pre> <p>Note that above we created a <code>np.matrix</code>, which is in many ways similar to a numpy array. However, it has some methods associated with it which are specific for linear algebra. Additionally, some operators are interpreted differently. The asterisk <code>*</code> defines element-wise multiplication for arrays, but always refers to matrix-multiplication for matrices. Furthermore, when making a boolean comparison where only matrices are involved, the returned object will be a boolean matrix and also have matrix operations associated to it.</p> <p>Note that the Boolean comparison is done element-wise on the elements of the matrix (here, <code>A</code>):</p> <pre><code>A &gt; 10\n</code></pre> <pre><code>matrix([[False, False, False],\n        [ True, False, False]])\n</code></pre> <p>Finally, we consider the difference between views and copies:</p> <p>If we want to obtain a true copy of some array <code>A</code>, we need to enclose it in <code>np.copy</code>. Otherwise, we will obtain a view, which if called links back to the original object <code>A</code>.</p> <pre><code>A_copy = np.copy(A) # use the copy function to make A_copy, which DOES NOT change if we change A\n\n# however, this LHS variable will 'point' to the elements of A_copy\n# if we change stuff in A_copy[0,:], then the_first_row_of_A_copy changes\nthe_first_row_of_A_copy = A_copy[0,:] \nprint(the_first_row_of_A_copy)\n\nA_copy[0,:] = np.arange(1, 4, 1) # np.arange(start, end, step) creates a sequence from start to (excluding) end, in 'step'-size\nprint(the_first_row_of_A_copy)\n</code></pre> <pre><code>[0 0 0]\n[1 2 3]\n</code></pre> <p>We can slice arrays in any dimensions using the usual <code>i:j:k</code> syntax: select every <code>k</code>th element from <code>i</code> to <code>j</code>.</p> <p>Exercise:  - Write a function <code>make_shift_mat</code> which takes a number n and outputs the n by n shift matrix </p>  \\begin{align*} S_n =  \\begin{pmatrix} 0 &amp; 1 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\end{pmatrix} \\end{align*}  <ul> <li>Create another function <code>make_nilpotent_mat</code> which takes as argument a list of integers <code>[n_1, n_2, ..., n_m]</code> and outputs the a matrix which has S_{n_1}, ..., S_{n_m} on the diagonal and is 0 in all other entries.</li> <li>Then create a function <code>get_np_index</code> which takes in a nilpotent matrix N and calculates the (least) k, for which N^k = \\mathbf{0} (the zero matrix)</li> </ul> <p>HINT: To calculate a matrix product of two arrays <code>A, B</code> of conforming dimension, use <code>A@B</code>.</p> <p>Solution:</p> <pre><code># a solution with a loop\ndef make_shift_mat(n):\n    A = np.zeros([n,n])\n    for i in range(n-1):\n        A[i,i+1] = 1\n    return A\n\n# an alternative way with slicing\ndef make_shift_mat(n):\n    A = np.zeros((n,n))\n    A[np.arange(n-1), np.arange(1,n)] = 1\n\n    return A\n\nmake_shift_mat(8)\n\ndef make_nilpotent_mat(dim_list): \n    B = np.zeros((sum(dim_list),sum(dim_list)))\n    start = 0\n    for n in dim_list:\n        end = start + n\n        B[start:end, start:end] = make_shift_mat(n)\n        start += n\n    return B\n\n\ndef get_np_index(M, max_iter=10_000):\n    M_copy = M.copy()\n    counter = 0\n    while not np.all(M_copy == 0):\n        counter += 1\n        M_copy = M_copy @ M\n\n        if counter &gt;= max_iter:\n            print(\"NO NILPINDEX FOUND\")\n            return None      \n\n    print(\"NILPINDEX\", counter+2)\n    return counter+2\n\n\ndef get_np_index(M, max_iter=10_000):\n    M_copy = M.copy()\n\n    for i in range(max_iter):\n\n        M_copy = M_copy @ M\n\n        if np.all(M_copy == 0):    \n            print(\"NILPINDEX\", i+2)\n            return i+2\n\n    print(\"NO NILPINDEX FOUND\")\n    return None      \n\n\nM = make_nilpotent_mat([6, 2, 5])\n\nget_np_index(M)\n# check that it works\nM @ M @ M @ M @ M @ M \n</code></pre> <pre><code>NILPINDEX 6\n\n\n\n\n\narray([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n</code></pre>"},{"location":"courses/sem/1-numpy/#functions-to-make-arrays","title":"Functions to Make Arrays","text":"<p>Numpy has a few handy built-in methods to create arrays of different kinds. <code>np.ones</code> and <code>np.zeros</code> are such. Now we look at two more: <code>np.linspace</code> and <code>np.logspace</code>. </p> <pre><code>np.linspace(start=0., stop=100, num=20) # create a grid from 0 to 100 with 20 grid points\nnp.logspace(start=np.log(1), stop=np.log(100), num=20, base = np.e) # create a grid from 0 to 100 with 20 grid points but in logs\n\n# the latter is equivalent to \nlower = np.log(1) # np.log( . ) is the natural logarithm\nupper = np.log(100)\nnp.exp(np.linspace(lower, upper, 20)) # use broadcasting here, see next section\n</code></pre> <pre><code>array([  1.        ,   1.27427499,   1.62377674,   2.06913808,\n         2.6366509 ,   3.35981829,   4.2813324 ,   5.45559478,\n         6.95192796,   8.8586679 ,  11.28837892,  14.38449888,\n        18.32980711,  23.35721469,  29.76351442,  37.92690191,\n        48.32930239,  61.58482111,  78.47599704, 100.        ])\n</code></pre> <p>The function <code>np.arange</code> is very similar to the native <code>range()</code> function:</p> <pre><code>np.arange(start=1, stop=20, step=3)\n</code></pre> <pre><code>array([ 1,  4,  7, 10, 13, 16, 19])\n</code></pre>"},{"location":"courses/sem/1-numpy/#2-computations-and-broadcasting","title":"2. Computations and Broadcasting","text":"<p>One can do pretty much all basic computations on <code>np.array</code>s and these will be applied elementwise. (These computations are also called vectorized functions.) </p> <p>Let\u2019s also consider some functions coming with numpy: <code>np.exp, np.log, np.abs</code>.</p> <pre><code>a = np.arange(1,10,2)\nprint(a)\n\n# multiplication / addition with a scalar\nprint(a * 10)\nprint(a + 10)\n\n# exponential function, log function\nprint(np.exp(a))\nprint(np.log(a))\n\nb = np.array([-1,0,1])\nprint(np.abs(b))\n</code></pre> <pre><code>[1 3 5 7 9]\n[10 30 50 70 90]\n[11 13 15 17 19]\n[2.71828183e+00 2.00855369e+01 1.48413159e+02 1.09663316e+03\n 8.10308393e+03]\n[0.         1.09861229 1.60943791 1.94591015 2.19722458]\n[1 0 1]\n</code></pre> <p>We can add two <code>np.array</code>s together element-wise in the obvious fashion. This is called \u2018broadcasting\u2019. My advice: While useful, try to avoid situations in which non-obvious broadcasting things can happen.</p> <p>Instead of addition, we can perform above computations with multiplication <code>*</code> or exponentiation <code>**</code>, too.</p> <p>An interesting way to leverage broadcasting is to use <code>np.newaxis</code>, which creates an additional yet empty dimension to an array. For example, let <code>a = np.array([1, 2, 3])</code>. Then <code>a[:, np.newaxis]</code> has shape <code>(3, 1)</code> and <code>a[np.newaxis, :]</code> has shape <code>(1, 3)</code>. What does the following broadcasting procedure yield: <code>B = a[np.newaxis, :] + a[:, np.newaxis]</code>?</p> <p>Think it through. If you repeat <code>a[np.newaxis, :]</code> on the second axis you get a <code>(3,3)</code> array. Same if you repeat <code>a[:, np.newaxis]</code> thrice on the first axis. Then, you add the two resulting matrices elementwise. That\u2019s basically an outer product!</p> <pre><code>a = np.array([1, 2, 3])\n\nprint(a**2, \"\\n\")\n\nprint(a[:, np.newaxis].shape, \"\\n\")\n\nprint(a[np.newaxis, :] + a[:, np.newaxis], \"\\n\")\n\nprint(a[np.newaxis, :] ** a[:, np.newaxis])\n</code></pre> <pre><code>[1 4 9]\n\n(3, 1)\n\n[[2 3 4]\n [3 4 5]\n [4 5 6]]\n\n[[ 1  2  3]\n [ 1  4  9]\n [ 1  8 27]]\n</code></pre> <p>Rules of Broadcasting</p> <p>Now we have seen Broadcasting in action, let\u2019s consider the rules that NumPy us using to determine how it operates on two arrays:</p> <ul> <li>Rule 1: If the two arrays differ in their number of dimensions, the shape of the one with fewer dimensions is padded with ones on its leading (left) side.</li> <li>Rule 2: If the shape of the two arrays does not match in any dimension, the array with shape equal to 1 in that dimension is stretched to match the other shape.</li> <li>Rule 3: If in any dimension the sizes disagree and neither is equal to 1, an error is raised.</li> </ul> <p>Consider an operation on <code>matrix</code> and <code>array</code>. The shape of each is:</p> <ul> <li><code>matrix.shape = (2, 3)</code></li> <li><code>array.shape = (3,)</code></li> </ul> <p>Rule 1 tells us that <code>array</code> has fewer dimensions, so we pad it on the left with ones:</p> <ul> <li><code>matrix.shape -&gt; (2, 3)</code></li> <li><code>array.shape -&gt; (1, 3)</code></li> </ul> <p>Rule 2, tells us the first dimension disagrees, so we stretch itnsion to match:</p> <ul> <li><code>matrix.shape -&gt; (2, 3)</code></li> <li><code>array.shape -&gt; (2, 3)</code></li> </ul> <p>Now the shapes match, and we see the output of a ufunc operation will be <code>(2, 3)</code>:</p> <p>(Source PP4RS, 2023)</p> <p>Above, we have seen rule 2 in action. Now look at rule 1:</p> <pre><code># Example of padding\n\na = np.matrix([2, 2, 2])\nb = np.array([1, 2, 3])\n\nprint(a.shape, b.shape) # look at the shape of array and matrix\n\n(a + 0 * b).shape # look at the shape of the broadcasted result\n</code></pre> <pre><code>(1, 3) (3,)\n\n\n\n\n\n(1, 3)\n</code></pre>"},{"location":"courses/sem/1-numpy/#array-methods","title":"Array Methods","text":"<p>We spent a minute on useful methods (=functions) associated with <code>numpy</code> objects. First, we create an array. Then we <code>reshape</code>the array. Then we consider some <code>sum</code>, <code>max</code>, <code>min</code>, <code>mean</code> commands.</p> <pre><code>a = np.arange(1, 100, 3.1234) \n\nprint(a.shape) # well, lets make this a (4, 8) array. \n# the reshape method will first fill up the columns, for row 1, then for row 2, etc until all rows are filled\n# an analogous reshaping occurs when looping through multiple dimensions.\n\na = np.reshape(a, (4, 8))\nprint(a.shape)\n\n# global max\nprint(a.max())\n\n# row max: take max over the first dimension\nprint(a.max(axis=0))\n\n# column min: take min over the second dimension\nprint(a.min(axis=1))\n\n# the mean and sum methods work completely analogously.\n</code></pre> <pre><code>(32,)\n(4, 8)\n97.8254\n[75.9616 79.085  82.2084 85.3318 88.4552 91.5786 94.702  97.8254]\n[ 1.     25.9872 50.9744 75.9616]\n</code></pre> <p>Note: instead of using <code>np.copy(a)</code>, we can always write <code>a.copy()</code> since <code>copy()</code> is a method of the numpy object.</p>"},{"location":"courses/sem/1-numpy/#matrix-computations","title":"Matrix Computations","text":"<p>Of course we can use matrix algebra with <code>numpy</code>.</p> <pre><code># transpose of A\nA.transpose()\n\n# multiply A to A'\nA @ A.transpose()\n\nnp.dot(A, A.transpose()) # alternatively, use np.dot instead of @\n</code></pre> <pre><code>matrix([[   0,    0],\n        [   0, 1661]])\n</code></pre>"},{"location":"courses/sem/1-numpy/#3-the-nprandom-module","title":"3. The <code>np.random</code> Module","text":"<p>The <code>np.random</code> module is a collection of functions able to generate random variables and fill array with those. For instance, <code>np.random.uniform</code> generates samples drawn from the uniform distribution. Can you guess what <code>np.random.randint</code> will give us?</p> <pre><code>u = np.random.uniform(low=0, high=1, size=100)\n\n# random matrix\nu = u.reshape(10,10)\n\n# random matrix with integers\nu_int = np.random.randint(low=0, high=101, size=100).reshape(10,10)\n</code></pre> <p>Exercise:</p> <p>Write the function <code>demean</code> which takes two inputs, a numpy array <code>A</code> and <code>axis</code> defaulting to <code>None</code>. If <code>axis</code> is equal to the default, the function calculate the mean across all elements of <code>A</code> and subtract this mean from each element. If <code>axis = i</code>, then the function calculates the means of <code>A</code> along that axis and only demeans in this direction. For example, it calculates a_{i, j, k, l} - \\bar a_{i, j, \\cdot, l} if <code>axis = 2</code>. (This means the third dimension is used to calculate means.)</p> <pre><code>def demean(A, axis=None):\n    temp = np.asarray(A) # make sure A is a numpy array, keepdims does not work with matrices\n    A_mean = temp.mean(axis=axis, keepdims = True)\n    return A - A_mean # broadcasting rule 2 is our friend here\n\ndemean(A, axis=1) \n</code></pre> <pre><code>matrix([[  0.,   0.,   0.],\n        [ 23., -12., -11.]])\n</code></pre>"},{"location":"courses/sem/1-numpy/#4-other-exercises","title":"4. Other Exercises","text":"<p>Exercise: Discretizing the asset space</p> <p>Consider the situation in which we want to create an asset grid for the households in your favorite macro-model. Households choose assets from [\\underline a, \\infty), need to discretize this grid. Idea: there should be more grid points around \\underline a, because policy function is more nonlinear here. But we also want some points for high a. Solution: double exponential transformation of uniformly spaced grid:</p> a_i = \\underline a + e^{e^{u_i} - 1} - 1, u_i \\in [0, \\bar u] <p>Write a function <code>discretize_assets(amin, amax, n_a)</code> which outputs an asset grid ranging from <code>a_min</code> to <code>a_max</code> with <code>n_a</code> grid points, where a_i is determined by the formula above.</p> <pre><code># SOLUTION:\n\n# write a function which discretizes the asset space\ndef discretize_assets(amin, amax, n_a):\n    # find ubar \n    ubar = np.log(np.log(amax - amin + 1)+1)\n    # make linar grid for the u's\n    grid_u = np.linspace(0,ubar, n_a)\n    # transform back to a\n    grid_a = amin + np.exp(np.exp(grid_u)-1)-1\n    return grid_a\n\ngrid_a = discretize_assets(0, 10_000, 50)\n\n# visualize the grid\nimport matplotlib.pyplot as plt\n# some useful plot defaults\nplt.rcParams.update({'font.size' : 10, 'lines.linewidth' : 1.5, 'figure.figsize' : (4,3)})\n# scatter plot of the grid\nplt.scatter(grid_a, np.repeat(1, len(grid_a)), marker='|')\n</code></pre> <pre><code>&lt;matplotlib.collections.PathCollection at 0x116872290&gt;\n</code></pre> <p></p>"},{"location":"courses/sem/2-numba/","title":"Numba","text":"<p>Numba is a library which can speed up computations, especially loops, enormously. We look at two use cases: just-in-time compilation and parallelization.</p>"},{"location":"courses/sem/2-numba/#1-just-in-time-jit-compilation","title":"1. Just-In-Time (JIT) compilation","text":"<p>JIT means that a function you write in Python is not evaluated in its Python code. Rather, it is translated into very fast machine code the first time you run it (\u2018compilation\u2019 step). Function calls are accelerated after you run it for the first time. This works well for Python functions using only base-Python or numpy code, especially if they contain loops. However, not all functions are JITable. Numba will throw an error upon execution in such cases.</p> <p>We JIT a function by including the decorator <code>@jit</code> in front of the function definition.</p> <p>Whenever we can JIT a loop, the speed of execution will be comparable to high-speed, vectorized calculations.</p> <pre><code>from numba import jit\nimport numpy as np\nimport matplotlib.pyplot as plt \n</code></pre> <p>Example 1:  A function to sum the entries of a matrix.</p> <pre><code>def sum2d_slow(arr):\n    M, N = arr.shape\n    result = 0.0\n    for i in range(M):\n        for j in range(N):\n            result += arr[i, j]\n    return result\n\n@jit(nopython=True)\ndef sum2d(arr):\n    M, N = arr.shape\n    result = 0.0\n    for i in range(M):\n        for j in range(N):\n            result += arr[i, j]\n    return result\n\narr = np.random.random((1000, 1000))\nprint(sum2d(arr))\n</code></pre> <pre><code>500813.47465895314\n</code></pre> <pre><code>%timeit sum2d(arr)\n%timeit sum2d_slow(arr)\n</code></pre> <pre><code>983 \u00b5s \u00b1 65.8 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\n94.4 ms \u00b1 1.8 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n</code></pre> <p>Example 2: A function to calculate the nth entry of the Fibonacci sequence x_n = x_{n-1} + x_{n-2} with x_{1}, x_2 = 1.</p> <pre><code>@jit(nopython=True)\ndef fibonacci(n):\n    if n &lt;= 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        return fibonacci(n-1) + fibonacci(n-2)\n\nprint(fibonacci(10))\n</code></pre> <pre><code>55\n</code></pre> <p>Example 3: A custom function to perform matrix multiplication.</p> <pre><code>@jit(nopython=True)\ndef matmul(A, B):\n    M, K = A.shape\n    K, N = B.shape\n    C = np.empty((M, N))\n    for i in range(M):\n        for j in range(N):\n            for k in range(K):\n                C[i, j] += A[i, k] * B[k, j]\n    return C\n\nA = np.random.random((5, 5))\nB = np.random.random((5, 5))\nprint(matmul(A, B))\n</code></pre> <pre><code>[[2.98968204 1.98847909 1.61801679 2.50340159 2.25484186]\n [1.29159912 1.11695596 1.09491006 1.49815718 0.92471361]\n [2.29008386 1.92642715 1.1360947  1.94572225 1.61010675]\n [1.00080451 0.60136262 0.6481075  0.89050315 0.79019492]\n [1.61881542 1.28320473 0.95341038 1.50718031 1.11756129]]\n</code></pre> <p>Exercise: Time the functions in all examples and compare the runtime to a non-JIT\u2019ed version.</p>"},{"location":"courses/sem/2-numba/#2-parallelization","title":"2. Parallelization","text":"<p>We can make use of out computers\u2019 ability to perform multiple calculations at the same time with <code>numba</code>, too. To parallelize loops, the following two simple steps are needed:</p> <ol> <li>The decorator becomes <code>@jit(nopython=True, parallel=True)</code></li> <li>All loops to be parallelized are called with <code>prange</code> objects, instead of the familiar <code>range</code>.</li> </ol> <p>Parallelization works best in scenarios where tasks can be divided into independent units of work that can be executed concurrently without dependencies. This includes operations on large datasets, such as matrix multiplications, image processing, and simulations like Monte Carlo methods or random walks. It is particularly effective when the workload can be evenly distributed across multiple processors, minimizing the need for synchronization and communication between tasks. By leveraging parallelization, significant performance improvements can be achieved, especially in computationally intensive applications.</p> <p>Here is an example for a parallelized matrix-multiplication:</p> <pre><code>from numba import prange\n\n@jit(nopython=True, parallel=True)\ndef parallel_matmul(A, B):\n    M, K = A.shape\n    K, N = B.shape\n    C = np.zeros((M, N))\n    for i in prange(M):\n        for j in prange(N):\n            for k in range(K):\n                C[i, j] += A[i, k] * B[k, j]\n    return C\n\nA = np.random.random((5, 5))\nB = np.random.random((5, 5))\nprint(parallel_matmul(A, B))\n</code></pre> <pre><code>[[0.42546991 0.1540311  0.16394572 0.60225408 0.73378924]\n [0.69485696 0.80875058 0.72270807 1.59882819 1.8065876 ]\n [0.63858342 0.59801137 0.79892044 1.15579666 1.04488927]\n [0.62294144 1.04404476 1.31799181 1.57375161 1.29141532]\n [0.79744389 0.77428444 1.21240957 1.3350469  0.99760936]]\n</code></pre> <pre><code>%timeit matmul(A, B)\n%timeit parallel_matmul(A, B)\n</code></pre> <pre><code>509 ns \u00b1 5.12 ns per loop (mean \u00b1 std. dev. of 7 runs, 1,000,000 loops each)\n94.9 \u00b5s \u00b1 2.69 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10,000 loops each)\n</code></pre> <p>Exercise: Parallel simulation of a brownian motion. The formula for a Geometric Brownian Motion (GBM) is given by:</p>  dS_t = \\mu S_t \\, dt + \\sigma S_t \\, dW_t  <p>where: - S_t is the stock price at time t - \\mu is the drift coefficient (expected return) - \\sigma is the volatility coefficient (standard deviation of returns) - dW_t is a Wiener process or Brownian motion</p> <p>In its discrete form, the GBM can be expressed as:</p>  S_{t+\\Delta t} = S_t \\exp \\left( \\left( \\mu - \\frac{\\sigma^2}{2} \\right) \\Delta t + \\sigma \\sqrt{\\Delta t} \\, Z_t \\right)  <p>where:</p> <ul> <li>\\Delta t is the time increment</li> <li>Z_t is a standard normal random variable</li> </ul> <p>This formula is commonly used in financial mathematics to model stock prices and other financial instruments.</p> <p>Write a parallelized function <code>GBM_sim</code> which generates returns <code>N</code> brownian motion simulations of duration <code>T</code> each, and takes in the needed parameters. Which loops are easily parallelized and which are not?</p> <pre><code>@jit(nopython=True, parallel=True)\ndef GBM_sim(S0, mu, sigma, deltaT, T, N):\n\n    deltaT_sqrt = deltaT**0.5 # pre-compute this guy \n    increments_num = int(np.floor(T/deltaT) + 1) # need integer number of increments\n    log_GBMs = np.empty((N,increments_num))\n\n    for n in prange(N):\n        log_GBMs[n, 0] = np.log(S0)\n        for i in range(1, increments_num):\n            log_GBMs[n, i] = log_GBMs[n, i-1] + (mu - sigma**2 / 2) * deltaT + sigma * deltaT_sqrt * np.random.normal()\n\n    GBMs = np.exp(log_GBMs)\n    return GBMs\n\nGBMs = GBM_sim(S0 = 1, mu = 0.08, sigma = 1, deltaT = 0.001, T = 1, N = 5)\n</code></pre> <p>Let\u2019s plot some of these Brownian motions.</p> <pre><code># Define shades of dark grey and different linestyles\ncolors = ['#2f2f2f', '#3f3f3f', '#4f4f4f', '#5f5f5f', '#6f6f6f', '#7f7f7f', '#8f8f8f', '#9f9f9f', '#afafaf', '#bfbfbf']\nlinestyles = ['-', '--', '-.', ':', '-', '--', '-.', ':', '-', '--']\n\nfor i in range(GBMs.shape[0]):\n    plt.plot(GBMs[i], color=colors[i % len(colors)], linestyle=linestyles[i % len(linestyles)])\n\nplt.ylabel(r'$S_t$')\nplt.xlabel(r't')\nplt.show()\n</code></pre> <p></p> <p>Let\u2019s time the function:</p> <pre><code>%%timeit\nGBM_sim(S0 = 1, mu = 0.08, sigma = 1, deltaT = 0.001, T = 1, N = 5000)\n</code></pre> <pre><code>20 ms \u00b1 387 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n</code></pre> <p>Exercise: Write a function <code>call_payout(price, strike)</code>, which gives you the value of a call option at maturity if the price of the underlying are given in <code>prices</code> and you have the right (but not the obligation) to buy the underlying for the strike price <code>strike</code>.</p> <pre><code>def call_payout(prices, strike):\n    payout = (prices - strike)\n    payout[payout &lt; 0] = 0\n    return payout\n</code></pre> <p>Exercise: Write a function which simulates the mean expected payoffs of a call option on an asset initially priced at S_0 after T periods. Simulate the function for <code>100_000</code> paths per GBM run, and across \\sigma \\in \\{0.5, 1, 2\\}</p> <pre><code>def sim_payoff(S0 = 1, mu = 0.08, sigma = 1, deltaT = 0.001, T = 1, N = 10000, discount_rate=0.03):\n    GBMs = GBM_sim(S0, mu, sigma, deltaT, T, N)\n    mean_payoff = call_payout(GBMs, 1.0).mean(axis=0)\n    mean_payoff = mean_payoff / (1+discount_rate*deltaT) ** np.arange(T/deltaT+1)\n    return mean_payoff\n\nmean_payoff = sim_payoff(S0 = 1, mu = 0.08, sigma = 0.5, deltaT = 0.001, T = 1, N = 100_000, discount_rate=0.08)\nmean_payoff = mean_payoff[:,np.newaxis]\nfor i, sigma in enumerate((1., 2.)):\n    mean_payoff = np.append(mean_payoff, sim_payoff(S0 = 1, mu = 0.08, sigma = sigma, deltaT = 0.001, T = 1, N = 100_000, discount_rate=0.08)[:, np.newaxis], axis=1)\n</code></pre> <pre><code>for i, sigma in enumerate((0.5, 1., 2.)):\n    plt.plot(np.linspace(0, 1, len(mean_payoff[:, i])), mean_payoff[:, i] , label = f\"$\\sigma = {sigma}$\")\nplt.ylabel(r'$E[payoff_t] * (1+r \\Delta t)^{-t/\\Delta t}$')\nplt.xlabel(r'Number of years, $t$')\nplt.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"courses/sem/3-application_stoch_proc/","title":"Application: Stochastic Processes","text":"<p>In this notebook we put some of the techniques we just learned to good use. We will: - write a function to simulate ARMA(p,q) processes - write a function to simulate Markov-processes - Introduce the Rouwenhorst method to approximate an AR(1) process using a Markov process on a finite grid.</p> <p>Additionally, we write our own class <code>markov</code> with simulation and calibration methods.</p>"},{"location":"courses/sem/3-application_stoch_proc/#armapq","title":"ARMA(p,q)","text":"<p>Recall the definition of an ARMA(p,q) process as  $$ y_t = \\alpha_0 + \\sum_{j = 1}^p \\alpha_j L^j y_t + \\sum_{j = 1}^q \\beta_j L^j \\varepsilon_t + \\varepsilon_t$$ where L is the lag-operator and \\varepsilon_t\\sim_{i.i.d.} \\Phi(\\sigma, 0) (we assume a normal distribution on the errors).</p> <p>Let\u2019s write a function which takes in a dictionary holding \\alpha_0, \\underline{\\alpha}, \\underline{\\beta} and \\sigma to simulate the corresponding ARMA process.</p> <pre><code>import numpy as np\nfrom numba import prange, jit\n</code></pre> <pre><code>arma_dict = {\n    'alpha_0': 0.,\n    'alpha': np.array([0.2, 0.4, 0.1]),  \n    'beta': np.array([0.1]),\n    'sigma': 1\n}\n\ndef sim_arma(arma_dict, T):\n    p = len(arma_dict['alpha'])\n    q = len(arma_dict['beta'])\n    alpha = np.flip(arma_dict['alpha']) # reverse the vectors to make sure a_j is multiplied to y_t-j in np.vdot \n    beta = np.flip(arma_dict['beta'])\n\n    y = np.empty(1000+T) # 1000 burn-in draws\n    eps = np.random.normal(0., arma_dict['sigma'], T+1000)\n    y[0:max(p,q)] = eps[0:max(p,q)]  \n    for i in np.arange(max(p,q), T+1000):\n        y[i] = np.vdot(y[i-(p):(i)], alpha) + np.vdot(eps[i-(q):(i)], beta)\n    return y[-T:]\n</code></pre> <pre><code>arma_ts = sim_arma(arma_dict, 250)\n</code></pre> <p>Let\u2019s write a function to plot the time series.</p> <pre><code>import matplotlib.pyplot as plt\n\ndef plot_time_series(time_series, arma_dict, xlabel='Time', ylabel='Value'):\n    \"\"\"\n    Plots the given time series.\n\n    Parameters:\n    time_series (array-like): The time series data to plot.\n    title (str): The title of the plot.\n    xlabel (str): The label for the x-axis.\n    ylabel (str): The label for the y-axis.\n    \"\"\"\n    title='Time Series ARMA(' + str(len(arma_dict['alpha'])) + \", \" + str(len(arma_dict['beta'])) + \")\"\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(time_series, color='blue', linestyle='-', linewidth=1.)\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.grid(True)\n    plt.show()\n</code></pre> <pre><code># Plot the time series\nplot_time_series(arma_ts, arma_dict)\n</code></pre> <p></p> <p>Recall now that a given ARMA(p,q) is stationary if and only if all roots of the characteristic polynomial on the AR-part,  $$ 1 - L^1 \\alpha_1 - \u2026 - L^q \\alpha_q $$ are outside the (complex) unit circle. We write a function to check this. To do so, we use <code>np.roots(p)</code>, which return the roots of a polynomial with coefficients given in <code>p</code>.</p> <pre><code>def is_stable(alpha):\n    coefs = np.concatenate([[1], -alpha])[::-1] # [::-1] reverses an array\n    print(\"The lag polynomial to check is:\")\n    print(\"1 -\", \" - \".join([f\"{a}*L^{i}\" for i, a in enumerate(alpha)]))\n    print(\"The roots are:\")\n    roots = np.roots(coefs)\n    for root in roots:\n        print(f\" {root:.2f}\")\n\n    # Check if all roots have modulus &gt; 1\n    are_roots_outside_unit_circle = np.all(np.abs(roots) &gt; 1)\n    if are_roots_outside_unit_circle : \n        print(\"\\nThe process is stable.\")\n    else :\n        print(\"\\nThe process is unstable.\")\n    return are_roots_outside_unit_circle\n</code></pre> <p>Let\u2019s try it!</p> <pre><code>is_stable(arma_dict['alpha'])\n</code></pre> <pre><code>The lag polynomial to check is:\n1 - 0.2*L^0 - 0.4*L^1 - 0.1*L^2\nThe roots are:\n -2.60+1.23j\n -2.60-1.23j\n 1.21+0.00j\n\nThe process is stable.\n\n\n\n\n\nTrue\n</code></pre>"},{"location":"courses/sem/3-application_stoch_proc/#a-taster-of-oop","title":"A Taster of OOP","text":"<p>In Python, classes are a fundamental building block of object-oriented programming (OOP). A class is a blueprint for creating objects (instances), which can have attributes (variables) and methods (functions) associated with them.</p> <p>Basic Structure of a Class</p> <p>Here\u2019s a simple example to demonstrate the structure of a class in Python:</p> <pre><code>class Dog:\n    # Class attribute (shared by all instances)\n    species = \"Canis familiaris\"\n\n    # The initializer method (also called the constructor)\n    def __init__(self, name, age):\n        # Instance attributes\n        self.name = name\n        self.age = age\n\n    # Instance method\n    def bark(self):\n        return f\"{self.name} says woof!\"\n\n    # Another instance method\n    def get_human_years(self):\n        return self.age * 7\n\n# Creating instances (objects) of the class\ndog1 = Dog(\"Buddy\", 5)\ndog2 = Dog(\"Lucy\", 3)\n\n# Accessing attributes and methods\nprint(dog1.name)  # Output: Buddy\nprint(dog1.bark())  # Output: Buddy says woof!\nprint(dog2.get_human_years())  # Output: 21\n</code></pre> <pre><code>Buddy\nBuddy says woof!\n21\n</code></pre> <p>Key Concepts:</p> <ol> <li> <p>Class Definition:</p> <ul> <li>A class is defined using the <code>class</code> keyword followed by the class name and a colon.</li> <li>By convention, class names are written in CamelCase (e.g., <code>Dog</code>).</li> </ul> </li> <li> <p>Attributes:</p> <ul> <li>Class Attributes: These are shared across all instances of the class. In the example, <code>species</code> is a class attribute.</li> <li>Instance Attributes: These are specific to each instance of the class. They are defined inside the <code>__init__</code> method (constructor). In the example, <code>name</code> and <code>age</code> are instance attributes.</li> </ul> </li> <li> <p>Methods:</p> <ul> <li>Methods are functions defined within a class that operate on instances of the class.</li> <li>Instance Methods: These take <code>self</code> as the first parameter, which refers to the instance calling the method. For example, <code>bark</code> and <code>get_human_years</code> are instance methods in the <code>Dog</code> class.</li> <li>The <code>__init__</code> method is a special method called automatically when a new instance of the class is created. It is used to initialize the instance\u2019s attributes.</li> </ul> </li> <li> <p>Creating Objects:</p> <ul> <li>Objects (instances) are created by calling the class as if it were a function, passing any arguments required by the <code>__init__</code> method.</li> <li>For example, <code>dog1 = Dog(\"Buddy\", 5)</code> creates an instance of the <code>Dog</code> class with <code>name</code> as <code>\"Buddy\"</code> and <code>age</code> as <code>5</code>.</li> </ul> </li> <li> <p>Accessing Attributes and Methods:</p> <ul> <li>Instance attributes and methods are accessed using dot notation (e.g., <code>dog1.name</code>, <code>dog1.bark()</code>).</li> <li>Class attributes can be accessed directly via the class name or through any instance (e.g., <code>Dog.species</code> or <code>dog1.species</code>).</li> </ul> </li> </ol> <p>After we got the basic stuff out of the way, let\u2019s write a class for ARMA(p, q) processes. We call the class <code>arma</code> and have the following desiderata:</p> <ul> <li>The class is initialized with the four inputs making up <code>arma_dict</code></li> <li>It has a method allowing to simulate a the process with the process parameters</li> <li>we can update the process parameters whenever we like</li> <li>we can check whether the ARMA process is stable.</li> </ul> <p>Let\u2019s get to it.</p> <pre><code>class ARMA:\n\n    def __init__(self, alpha_0, alpha, beta, sigma):\n        self.alpha_0 = alpha_0\n        self.alpha = alpha\n        self.beta = beta\n        self.sigma = sigma\n        self.arma_dict = {\n            'alpha_0': self.alpha_0,\n            'alpha': self.alpha,\n            'beta': self.beta,\n            'sigma': self.sigma\n        }\n\n    # Methods to update the parameters help in this class\n    def set_alpha_0(self, alpha_0):\n        self.alpha_0 = alpha_0\n        self.arma_dict['alpha_0'] = alpha_0\n\n    def set_alpha(self, alpha):\n        self.alpha = alpha\n        self.arma_dict['alpha'] = alpha\n\n    def set_beta(self, beta):\n        self.beta = beta\n        self.arma_dict['beta'] = beta\n\n    def set_sigma(self, sigma):\n        self.sigma = sigma\n        self.arma_dict['sigma'] = sigma\n\n    # the simulation method\n    def sim_arma(self, T):\n        p = len(self.alpha)\n        q = len(self.beta)\n        alpha = self.alpha\n        beta = self.beta\n\n        y = np.empty(1000+T) # 1000 burn-in draws\n        eps = np.random.normal(0, arma_dict['sigma'], T+1000)\n        y[0:max(p,q)] = eps[0:max(p,q)]  \n        for i in np.arange(max(p,q)+1, T+1000):\n            y[i] = np.vdot(y[i-(p+1):(i-1)], alpha) + np.vdot(eps[i-(q+1):(i-1)], beta)\n\n        return y[-T:]\n\n    # checking for stability\n    def is_stable(self):\n        print(self.alpha)\n        coefs = np.concatenate([[1], - self.alpha])[::-1] # [::-1] reverses an array\n        print(\"-\"*70)\n        print(\"The lag polynomial to check is:\")\n        print(\"1 -\", \" - \".join([f\"{a}*L^{i+1}\" for i, a in enumerate(self.alpha)]))\n        print(\"\\nThe roots are:\")\n        roots = np.roots(coefs)\n        for root in roots:\n            print(f\" {root:.2f}\")\n\n        # Check if all roots have modulus &gt; 1\n        are_roots_outside_unit_circle = all(np.abs(roots) &gt; 1)\n        if are_roots_outside_unit_circle : \n            print(\"\\nThe process is stable.\")\n        else :\n            print(\"\\nThe process is unstable.\")\n        print(\"-\"*70)\n        return are_roots_outside_unit_circle\n</code></pre> <pre><code># initialize myarma object\nmyarma = ARMA(0, np.array([0.3,0.3]), np.array([0.3]), 1)\n# run and plot a little simulation\nplot_time_series(myarma.sim_arma(1000), myarma.arma_dict)\nmyarma.is_stable()\n\n# change the coefficient vector on AR-part \nmyarma.set_alpha(np.array([3, 1]))\nmyarma.is_stable()\n</code></pre> <p></p> <pre><code>[0.3 0.3]\n----------------------------------------------------------------------\nThe lag polynomial to check is:\n1 - 0.3*L^1 - 0.3*L^2\n\nThe roots are:\n -2.39\n 1.39\n\nThe process is stable.\n----------------------------------------------------------------------\n[3 1]\n----------------------------------------------------------------------\nThe lag polynomial to check is:\n1 - 3*L^1 - 1*L^2\n\nThe roots are:\n -3.30\n 0.30\n\nThe process is unstable.\n----------------------------------------------------------------------\n\n\n\n\n\nFalse\n</code></pre>"},{"location":"courses/sem/3-application_stoch_proc/#markov-processes","title":"Markov Processes","text":""},{"location":"courses/sem/3-application_stoch_proc/#introduction-to-discrete-markov-processes","title":"Introduction to Discrete Markov Processes","text":"<p>A Discrete Markov Process (or Markov Chain) is a mathematical model describing a system that transitions between a finite or countable number of states in discrete time steps. The key feature of a Markov process is the Markov Property, which states that the future state depends only on the current state and not on the sequence of events that preceded it.</p>"},{"location":"courses/sem/3-application_stoch_proc/#key-definitions","title":"Key Definitions:","text":"<ul> <li> <p>State Space (S): The set of all possible states the system can be in. It can be finite or countably infinite.</p> </li> <li> <p>Time Parameter: Discrete, often represented as t = 0, 1, 2, \\ldots.</p> </li> <li> <p>Transition Probability:</p> <ul> <li>Denoted as P_{ij}, it represents the probability of transitioning from state i to state j in one time step.</li> <li>Mathematically: P_{ij} = P(X_{t+1} = j \\mid X_t = i), where X_t is the state at time t.</li> <li>Collect these in a matrix, \\Pi</li> <li>The sum of probabilities in each row equals 1: \\sum_{j} P_{ij} = 1 for all i.</li> </ul> </li> <li> <p>Initial Distribution (\\pi^{(0)}):</p> <ul> <li>A probability distribution over the state space at time t = 0.</li> </ul> </li> <li> <p>n-Step Transition Probability:</p> <ul> <li>The probability of transitioning from state i to state j in n steps, denoted as \\Pi_{ij}^{(n)}.</li> <li>Calculated by raising the transition matrix to the n^{th} power: (\\Pi^{(n)})' = (\\Pi')^n.</li> </ul> </li> <li> <p>Stationary Distribution (\\pi):</p> <ul> <li>A probability distribution over states that remains unchanged as the process evolves.</li> <li>Satisfies \\pi = \\Pi' \\pi.</li> <li>Represents the long-term behavior of the Markov process if it exists and is unique.</li> </ul> </li> </ul> <p>Given a distribution \\pi_t, the next period distribution will be \\pi_{t+1} = \\Pi' \\pi_t</p> <pre><code># transition matrix\nPi = np.array([\n    [0.2, 0.4, 0.4],\n    [0.1, 0.5, 0.4],\n    [0.8, 0.1, 0.1]\n])\n\n# current distribution\npi = np.array([0.5, 0.5, 0])\npi = pi[:, np.newaxis]\n\n# next period distribution\nPi.transpose() @ pi\n</code></pre> <pre><code>array([[0.15],\n       [0.45],\n       [0.4 ]])\n</code></pre> <p>Exercise: Write a function that checks whether a given matrix is a Markov matrix.</p> <ul> <li>do the columns in a given row sum to 1?  </li> <li>are all entries between 0 and 1?</li> <li>is it a square matrix?</li> </ul> <p>Then, write a function which takes a Markov transition matrix and calculates the stationary distribution. (Hint: \\Pi^N converges to a matrix which contains the stationary distribution(s) in its rows.) </p> <pre><code># TBD\n\nM = Pi\nfor i in range(50):\n    M = Pi @ M\nM\n</code></pre> <pre><code>array([[0.35042735, 0.34188034, 0.30769231],\n       [0.35042735, 0.34188034, 0.30769231],\n       [0.35042735, 0.34188034, 0.30769231]])\n</code></pre>"},{"location":"courses/sem/3-application_stoch_proc/#rouwenhorst-method-to-approximate-an-ar1-process-with-a-markov-chain","title":"Rouwenhorst Method to Approximate an AR(1) Process with a Markov Chain","text":""},{"location":"courses/sem/3-application_stoch_proc/#advantages-of-the-rouwenhorst-method","title":"Advantages of the Rouwenhorst Method:","text":"<ul> <li>Flexibility: The Rouwenhorst method is particularly useful for approximating AR(1) processes with high persistence (i.e., when $ \\rho $ is close to 1) because it can accommodate the high persistence and the correct distribution properties of the AR(1) process.</li> <li>Accuracy: It provides a good approximation with relatively few states (even with a small $ n $), making it computationally efficient.</li> </ul> <p>For an arbitrary Markov process mapping to income states and corresponding income levels $ y $, consider the simplest case:</p>  \\begin{align*} \\log y_t &amp;= \\rho \\log y_{t-1} + \\epsilon_t, \\quad \\epsilon_t \\sim N(0, \\alpha^2), \\\\ \\alpha^2 &amp;= \\mathrm{Var}(\\log y_t) (1 - \\rho^2). \\end{align*}  <ul> <li> <p>Note that \\mathrm{Var}(\\log y_t) is the long-run variance as well as the cross sectional variance, which is typically directly estimated. So is \\rho, and we infer \\alpha.  </p> </li> <li> <p>Our goal is to approximate this continuous AR(1) process with n discrete states using the Rouwenhorst Method. This method helps us construct a Markov transition matrix \\Pi that closely matches the properties of the AR(1) process.</p> </li> <li> <p>To approximate the AR(1) process, we represent it with n discrete states. Each state is a sum e_t \\in \\{0,1,..., n-1\\} of n-1 underlying hidden binary state variables. Each binary state has a probability p of staying at its current value and a probability 1-p of switching to a different value.</p> </li> <li> <p>The parameter p is set to match the persistence of the AR(1) process, where p = \\frac{1+\\rho}{2}. The standard deviation of the underlying state e_t is given by \\frac{\\sqrt{n-1}}{2}. To match the cross-sectional standard deviation of log income, we scale (the grid of) e_t by \\frac{\\alpha}{\\sqrt{1 - \\rho^2}} \\frac{2}{\\sqrt{n-1}} = \\sigma_y \\frac{2}{\\sqrt{n-1}}.</p> </li> <li> <p>Finally, the goal is to find the discretized income process corresponding to these states.</p> </li> </ul> <p>The Markov transition matrix \\Pi^n for the states e follows the recursion:</p>  \\tilde{\\Pi}^{n} = p \\begin{bmatrix} \\Pi^{n-1} &amp; \\mathbf{0} \\\\ \\mathbf{0}' &amp; 0 \\end{bmatrix}  + (1-p) \\begin{bmatrix} \\mathbf{0} &amp; \\Pi^{n-1} \\\\ 0 &amp; \\mathbf{0} \\end{bmatrix}  + (1-p) \\begin{bmatrix} \\mathbf{0}' &amp; 0 \\\\ \\Pi^{n-1} &amp; \\mathbf{0} \\end{bmatrix}  + p \\begin{bmatrix} 0 &amp; \\mathbf{0}' \\\\ \\mathbf{0} &amp; \\Pi^{n-1} \\end{bmatrix}  \\tag{6}  <p>The final transition matrix \\Pi^n is equal to \\tilde{\\Pi}^{n} for the first and last rows, and \\tilde{\\Pi}^{n}/2 for all other rows. The base case for the recursion is:</p>  \\Pi^{2} = \\begin{bmatrix} p &amp; 1-p \\\\ 1-p &amp; p \\end{bmatrix}  <p>This procedure can be implemented in a function <code>rouwenhorst(n, rho, sd_log_y)</code> which returns a transition matrix and a grid for \\log y.</p> <p>Let\u2019s get to it:</p> <pre><code># sigma is the sd of the error, e_t\n@jit(nopython=True)\ndef rouwenhorst(n, rho, sd_log_y):\n\n    # the grid    \n    e = np.arange(n) # sd of e on this grid with Pi is sqrt(n-1)/2\n    e = e / ( (n-1)**0.5 /2 ) # now its unit sd\n    e = e * sd_log_y # now it's the sd of the cross section of log_y\n\n    # the transition matrix\n    p = (1+rho)/2\n    Pi = np.array([[p, 1-p], [1-p, p]])\n\n    while Pi.shape[0] &lt; n:\n        Pi_next = np.zeros((1+Pi.shape[0], 1+Pi.shape[1]))\n        Pi_next[0:Pi.shape[0], 0:Pi.shape[1]] += Pi * p\n        Pi_next[0:Pi.shape[0], -Pi.shape[1]:] += Pi * (1-p)\n        Pi_next[-Pi.shape[0]:, -Pi.shape[1]:] += Pi * p\n        Pi_next[-Pi.shape[0]:, 0:Pi.shape[1]] += Pi * (1-p)\n        Pi_next[1:-1, :] /= 2\n        Pi = Pi_next\n\n    return Pi, e\n\n@jit(nopython=True)\ndef stationary_dist(Pi):\n    Pi_stationary = Pi.copy()\n    eps = 1\n    while eps &gt; 10E-12:\n        Pi_old = Pi_stationary.copy()\n        Pi_stationary = Pi_stationary @ Pi_stationary\n        eps = np.max(np.abs(Pi_stationary - Pi_old))\n\n    if np.max(\n            np.abs( \n                np.sum(Pi_stationary - Pi_stationary,axis = 0) / Pi_stationary.shape[0]\n            )\n        ) &lt; 10E-10: # the ugly sum.../ .shape construction is because numpy cant handle np.mean with axis args\n        print(\"the steady state is unique.\")\n\n    return Pi_stationary\n\ndef normalize_y(log_y, pi_ss): # make y have unit mean\n        y = np.exp(log_y)\n        y = y / np.vdot(y, pi_ss)\n        return y\n</code></pre> <pre><code># lets test our code\nPi, log_y = rouwenhorst(20, 0.975, 0.7)\npi_ss = stationary_dist(Pi)[0,:]\ny_grid = normalize_y(log_y, pi_ss)\n\n# plot income and probability distribution\nplt.figure(figsize=(10, 6))\nplt.plot(y_grid, pi_ss, marker='o', linestyle='-', color='b', markersize=5, linewidth=1)\nplt.title('Steady State Income Distribution', fontsize=16)\nplt.xlabel('Income', fontsize=14)\nplt.ylabel('Probability', fontsize=14)\nplt.grid(True, which='both', linestyle='--', linewidth=0.5)\nplt.axhline(0, color='black',linewidth=0.5)\nplt.axvline(0, color='black',linewidth=0.5)\nplt.tight_layout()\nplt.show()\n</code></pre> <pre><code>the steady state is unique.\n</code></pre> <p></p>"},{"location":"courses/sem/4-optimization/","title":"Introduction to Equation Solving &amp; Optimization in Python","text":"<p>Python provides powerful tools and libraries for solving various types of equations, ranging from simple systems of linear equations to more complex polynomial and non-linear equations. This introduction will guide you through the basics of solving these equations using Python.</p>"},{"location":"courses/sem/4-optimization/#1-solving-systems-of-linear-equations","title":"1. Solving Systems of Linear Equations","text":"<p>A system of linear equations can be represented in matrix form as Ax = b, where:</p> <ul> <li>A is a matrix of coefficients,</li> <li>x is a vector of unknowns,</li> <li>b is a vector of constants.</li> </ul> <p>In Python, you can solve such systems using the <code>numpy</code> library:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Coefficient matrix A\nA = np.array([[3, 1], [1, 2]])\n\n# Constant vector b\nb = np.array([9, 8])\n\n# Solving for x\nx = np.linalg.solve(A, b)\n\nprint(x)\n</code></pre> <pre><code>[2. 3.]\n</code></pre> <p>Exercises:</p> <ol> <li>Write a function <code>fit</code> taking in a np.array <code>y</code> and a matrix <code>X</code> of conformable dimensions (X\\in \\mathbb{R}^{n\\times k}), such that it calculates the OLS estimator \\hat{\\beta}(X), as well as the residual vector \\epsilon. Do not solve the normal equations with a matrix inverse, but use <code>np.linalg.solve</code>.</li> <li>Write a function <code>robust</code> which calculates the sandwich estimator: </li> </ol> n\\text{Var}(\\hat{\\beta})_{\\text{robust}} = (X'X)^{-1} \\left( \\sum_{i=1}^n X_i' \\hat{\\epsilon}_i^2 X_i \\right) (X'X)^{-1} <ol> <li>Write a <code>class</code> called <code>olsmodel</code> which holds <code>y</code> and <code>X</code>, and which contains methods <code>fit</code>, <code>robust</code> and <code>predict</code></li> </ol> <p>Solution</p> <pre><code>def sim_some_data(size, ncov):\n    X = np.random.normal(size=(size, ncov))\n    beta = np.random.randint(-5,5, size = ncov)\n    X[:, 0] = 1\n    y = X @ beta + np.random.normal(loc=0, scale=ncov, size=size) \n    return y, X, beta \n\ny, X, beta = sim_some_data(100_000, 100)\n\ndef fit(y, X):\n    beta_hat = np.linalg.solve( X.T @ X, X.T @ y )\n    resid = y - X @ beta_hat\n    return beta_hat, resid\n\nbeta_hat, resid = fit(y, X)\n</code></pre> <pre><code>from numba import njit\n\n@njit\ndef robust(X, resid):\n    k = X.shape[1]\n    n = X.shape[0]\n    sum = np.zeros((k, k))\n    for i in range(n): # we prefer using a loop over using residuals on a diagonal matrix, so we don't have to instantiate a NxN matrix \n        sum = sum + np.outer(X[i, :],  X[i, :]) * (resid[i]**2)\n\n    XpX_inv = np.linalg.inv(X.T @ X)\n\n    sw = (XpX_inv @ sum @ XpX_inv)\n    return sw\n\n_ = robust(X, resid)\n\n## Or an alternative version using no matrix inversion:\n@njit\ndef robust_linalg(X, resid):\n    k = X.shape[1]\n    n = X.shape[0]\n    sum = np.zeros((k, k))\n    for i in range(n): # we prefer using a loop over using residuals on a diagonal matrix, so we don't have to instantiate a NxN matrix \n        sum = sum + np.outer(X[i, :],  X[i, :]) * (resid[i]**2)\n\n    XpX = X.T @ X\n\n    # steps:\n    # XpX @ sw @ XpX = sum\n    sw_XpX = np.linalg.solve(XpX , sum)\n\n    # steps:\n    # sw @ XpX = sw_XpX\n    # XpX.T @ sw.T = sw_XpX.T\n    sw_T = np.linalg.solve(XpX.T, sw_XpX.T) # transpose of sandwich sw (but sw is diagonal)\n\n    return sw_T\n\n_ = robust_linalg(X, resid) # compile function and throw result away\n</code></pre> <pre><code>%timeit robust(X, resid)\n%timeit robust_linalg(X, resid)\n</code></pre> <pre><code>1.3 s \u00b1 88.9 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n1.21 s \u00b1 45.2 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n</code></pre>"},{"location":"courses/sem/4-optimization/#2-finding-roots-of-polynomial-equations","title":"2. Finding Roots of Polynomial Equations","text":"<p>For polynomial equations, Python\u2019s <code>numpy</code> library offers straightforward methods to find roots. For example, to solve a polynomial equation like ax^2 + bx + c = 0.  This code computes the roots of the quadratic equation x^2 - 3x + 2 = 0, which are the values of x that satisfy the equation.</p> <pre><code>coefficients = [1, -3, 2]  # Coefficients of x^2 - 3x + 2\nroots = np.roots(coefficients)\n\nprint(roots)\n</code></pre> <pre><code>[2. 1.]\n</code></pre> <p>Exercise: Write a function <code>IRR</code> to calculate the internal rate of return of a payment stream. The function takes as arguments a stream of future payments x_1,...,x_n and an initial payment C_0, and finds the roots of the equation $$ C_0 = \\sum_i x_i (1+r)^{-i}.$$ It then checks which of the roots \\{r_1,...,r_n\\} are real, and picks among those the internal rate of return. Does the function work well for large n?</p> <pre><code>C_0 = 100  # Initial investment\nx = np.array([20, 26, 40, 55])  # Cash flows, the last payment comes last in this sequence\n\ndef IRR(C_0, x):\n    # Reverse the cash flows array to match the polynomial root finding convention\n    x = np.flip(x)\n\n    # Create the coefficients array for the polynomial equation\n    coefficients = np.concatenate([x, [-C_0]])\n\n    # Find the roots of the polynomial equation\n    roots = np.roots(coefficients)\n\n    # Filter out the complex roots, keep only real roots\n    is_real_solution = np.real(roots) == roots\n    roots = roots[is_real_solution]\n    roots = np.real(roots)\n\n    # Calculate IRR candidates from the real roots\n    IRR_candidates = roots**(-1) - 1\n\n    # Filter out IRR candidates that are greater than -1\n    IRR = IRR_candidates[IRR_candidates &gt; -1]\n\n    # Return the IRR if there is a unique solution, otherwise print a message\n    if IRR.size == 1:\n        return IRR[0]\n    else:\n        print(\"non-unique IRR\")\n\n# Call the IRR function with the initial investment and cash flows\nIRR(C_0, x)\n</code></pre> <pre><code>0.1280272166910017\n</code></pre>"},{"location":"courses/sem/4-optimization/#3-newton-methods-for-general-non-linear-equations","title":"3. Newton Methods for General Non-Linear Equations","text":"<p>We now try to understand Newton\u2019s workhorse optimization routine.</p>"},{"location":"courses/sem/4-optimization/#newtons-method","title":"Newton\u2019s Method","text":""},{"location":"courses/sem/4-optimization/#1-basic-idea","title":"1. Basic Idea","text":"<p>Newton\u2019s method iteratively approximates the root of a function using the following update rule:</p>  x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}  <p>where:</p> <ul> <li>x_n is the current estimate of the root.</li> <li>f'(x_n) is the derivative (or Jacobian, in the multivariate case) of f(x) at x_n.</li> </ul>"},{"location":"courses/sem/4-optimization/#2-algorithm","title":"2. Algorithm","text":"<ol> <li>Start with an initial guess x_0.</li> <li>Compute the function value f(x_n) and its derivative f'(x_n).</li> <li>Update the estimate using the formula x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}.</li> <li>Repeat until the change in x is smaller than a specified tolerance, or the function value f(x_n) is sufficiently close to zero.</li> </ol> <p>Exercise: With pen and paper, prove that Newton\u2019s method converges in one step for any linear equation Ax = b</p> <pre><code>from scipy.optimize import fsolve\n\n# varaible intercept for equation below\ninterc = 5\n\ndef equation(x, interc):\n    return x**3 - x + interc\n\nprint(\"roots found by numpy:\", np.roots([1, 0, -1, + interc]))\n\ninitial_guess = -2\nx_root, fsolve_dict, code, info = fsolve(equation, initial_guess, args=(interc), full_output=True)\nprint(fsolve_dict)\n\nplt.plot(np.linspace(-3, 3, 100),equation(np.linspace(-3, 3, 100), interc))\nplt.axhline(0, color='red', linestyle='--', label='y=0')  # Add horizontal line at y=0\nplt.scatter(x_root, equation(x_root, interc))\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Plot of the Equation with Horizontal Line at y=0')\nplt.legend()\nplt.grid(True)\nplt.show()\n\nprint(\"Note that the fsolve routine gets stuck for initial values in the region (-1, 1).\")\n</code></pre> <pre><code>roots found by numpy: [-1.90416086+0.j          0.95208043+1.31124804j  0.95208043-1.31124804j]\n{'nfev': 7, 'fjac': array([[-1.]]), 'r': array([-9.87749]), 'qtf': array([1.12003029e-09]), 'fvec': array([0.])}\n</code></pre> <p></p> <pre><code>Note that the fsolve routine gets stuck for initial values in the region (-1, 1).\n</code></pre> <p>Let\u2019s write a multivariate Newton solver able to solve equations of type F(x)=0, \\; F: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n. The solver should take as inputs a funtion to solve, <code>f</code>, a vector <code>x0</code> as a starting point, and a tolerance level <code>tol</code> for convergence, as well as a <code>maxiter</code> number of iterations after which it stops the solution process. We proceed in a few steps, in particular, first we need a method to obtain the jacobian, <code>Jf</code> at an arbitrary point:</p> <pre><code># example function I\ndef f(x):\n    return np.array([\n        x[0]**2 - 2 + 4*x[1], \n        - x[1] + x[0]**5\n    ])\nx0 = np.array([1., 1.])\n\n# # example function II\n# def f(x):\n#     return np.array([\n#         x[0]**2, \n#         x[1]**5\n#     ])\n# x0 = np.array([1., 1.])\n\n# # example function III\n# def f(x):\n#     return np.array([\n#         x[0]**2\n#     ])\n# x0 = np.array([1.])\n\nf(x0)\n</code></pre> <pre><code>array([3., 0.])\n</code></pre> <pre><code># run-off-the-mill method to calculate a jacobian numerically\ndef jacobian(f, x0):\n\n    x0 = np.array(x0, dtype='float64') \n\n    fx0 = f(x0)\n    M, N = *fx0.shape, *x0.shape\n    Jf = np.empty((M, N))\n    epsilon = 1E-8\n\n    for i in range(N):\n        x_eps = x0.copy()\n        x_eps[i] += epsilon\n        Jf[i, :] = (f(x_eps) - fx0) / epsilon\n\n    return Jf\n\n# test the function\njacobian(f, x0)\n</code></pre> <pre><code>array([[ 1.99999999,  5.00000008],\n       [ 3.99999998, -0.99999999]])\n</code></pre> <pre><code># newton solver\ndef newton(f, x0, tol = 1E-12, maxiter=1_000):\n\n    x_old = x0\n    x_new = x_old.copy()\n    Jf = jacobian(f, x_old)\n\n    for i in range(maxiter):\n\n        x_old = x_new.copy()\n        f_old = f(x_new)\n        if np.all( np.abs(f_old) &lt; tol ) :\n            print(f\"convergence achieved after {i} iterations\")\n            return x_new, f_old, Jf\n\n        Jf = jacobian(f, x_old)\n        #print(f_old)\n        x_new = x_old - np.linalg.inv(Jf) @ f_old\n\n    print(\"convergence not achieved\")\n    return x_old, f_old, Jf\n</code></pre> <pre><code># it works!\nnewton(f, x0, maxiter=10_000)\n</code></pre> <pre><code>convergence achieved after 124 iterations\n\n\n\n\n\n(array([0.804978  , 0.33800261]),\n array([-8.11350986e-13,  1.27675648e-13]),\n array([[ 1.60995601,  2.09945251],\n        [ 4.        , -1.        ]]))\n</code></pre> <p>Exercise: Secant Method</p> <p>The Secant method is a derivative-free variation of Newton\u2019s method. Instead of using the exact derivative f'(x), it approximates the derivative using two recent points:</p>  x_{n+1} = x_n - f(x_n) \\frac{x_n - x_{n-1}}{f(x_n) - f(x_{n-1})}  <ul> <li>Advantages: Does not require computing derivatives, which can be advantageous when the derivative is difficult to calculate.</li> <li>Disadvantages: Typically converges more slowly than Newton\u2019s method.</li> </ul> <p>Write a univariate root solver <code>secant_newton</code> in the spirit of the <code>newton</code> solver we just developed, which uses the secant method. </p>"},{"location":"courses/sem/4-optimization/#4-application-optimal-life-time-consumption","title":"4. Application: Optimal Life-Time Consumption","text":"<p>Let\u2019s use the solver we just wrote to solve a class of simple optimal consumption problems. In T periods, an agent can decide to save or consume, given an initial endowment \\omega and some income y_t, which varies every period.</p>   U = \\sum_{0\\leq t \\leq T-1} \\beta^t \\log(c_t), \\text{  s.t.  } a_{t+1} = y_t + a_t*(1+r) - c_t,\\; a_{-1} = \\omega,\\; a_{T} \\geq 0   <p>Giving us FOCs: $$ \\begin{equation}     f_0(\\omega, a_0, a_1) = 0,  \\end{equation} $$</p>  \\begin{equation*}     f_t(a_{t-1}, a_t, a_{t+1}) \\equiv \\beta (1+r) ( y_{t-1} + a_{t-1}(1+r) - a_t ) - ( y_t + a_t(1+r) -a_{t+1}) = 0 ,\\; \\forall 1 \\leq t \\leq T-2  \\end{equation*}   \\begin{equation*}     f_{T-2}(a_{T-2}, a_{T-1}, 0) =0  \\end{equation*}  <p>to solve simultaneously by choosing a_0, ..., a_{T-1}. We could do this in a recursive way, but lets attack the FOCs directly.</p> <pre><code>beta = 0.98\nr = 1/beta - 1\nomega = 5\n\n# y has T elements \ny = np.full(10, 1)\n\n# a_choice has T elements \na_choice = np.full(10, 0)\n\ndef F(beta, r, omega, y, a_choice):\n\n    a = np.zeros((1+len(y))) # accommodate initial and terminal condition\n    a[0:-1] = a_choice\n\n    F = np.zeros(len(y))\n    F[0] = beta*(1+r) * ( 0 + omega * (1+r) - a[0] ) - ( y[0] + a[0]*(1+r) - a[1] )\n\n    for t in range(1, len(F)):\n        F[t] = beta*(1+r) * ( y[t-1] + a[t-1] * (1+r) - a[t] ) - ( y[t] + a[t]*(1+r) - a[t+1] )\n\n    return F\n</code></pre> <pre><code>F(beta, r, omega, y, a_choice)\n</code></pre> <pre><code>array([4.10204082, 0.        , 0.        , 0.        , 0.        ,\n       0.        , 0.        , 0.        , 0.        , 0.        ])\n</code></pre> <pre><code># try the function\nprint(\"F =\", f\"{F(beta, r, omega, y, a_choice)}\")\n\n# Does it jacobe? Yes, it does!\nJ = jacobian(lambda a_choice : F(beta, r, omega, y, a_choice), a_choice)\n\nassert np.linalg.det(J) != 0 # check that the jacobian is not ill conditioned\n</code></pre> <pre><code>F = [4.10204082 0.         0.         0.         0.         0.\n 0.         0.         0.         0.        ]\n</code></pre> <p>Let\u2019s try whether this works out, and whether our solver can find a sequence of assets a = (a_0, ..., a_{T-1}) to solve the first order conditions:</p> <pre><code>a_choices, F_values, _ = newton(lambda a_choice : F(beta, r, omega, y, a_choice), a_choice, maxiter=10_000)\n</code></pre> <pre><code>convergence achieved after 10 iterations\n</code></pre> <p>Indeed, we have solved the consumption-savings problem with the output of our Newton-solver. Let\u2019s plot these results in a figure.</p> <pre><code>import matplotlib.pyplot as plt\n\n# Plot the asset path\nplt.figure(figsize=(5, 3))\nplt.plot(a_choices, marker='o', linestyle='-', color='b', markersize=5, linewidth=1)\nplt.title('Asset Path in Consumption-Savings Problem', fontsize=16)\nplt.xlabel('Time Period', fontsize=14)\nplt.ylabel('Assets', fontsize=14)\nplt.grid(True, which='both', linestyle='--', linewidth=0.5)\nplt.axhline(0, color='black', linewidth=0.5)\nplt.axvline(0, color='black', linewidth=0.5)\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <p>Looks great!</p>"},{"location":"courses/sem/4-optimization/#a-consumption-savings-class","title":"A Consumption-Savings Class","text":"<p>Now let\u2019s go all in and package the problem nicely. We write a class <code>ConSavProb</code> which takes as inputs <code>beta, r, y, omega</code> and an initial guess for <code>a</code>. It has a <code>solve</code> method, which solves for the optimal asset and consumption path.</p> <p>Packaging the consumption-savings problem into a class, in this case <code>ConSavProb</code>, offers several benefits:</p> <ol> <li> <p>Modularity: By encapsulating the problem within a class, we can organize related variables and functions together. This improves code organization and makes it easier to understand and maintain. It also allows us to reuse the class in different parts of our code or even in other projects.</p> </li> <li> <p>Abstraction: Instead of exposing all the inner workings of the consumption-savings problem, we can provide a clean interface through class methods. </p> </li> <li> <p>Encapsulation: Classes allow us to encapsulate data and methods together. This means that the variables and functions related to the consumption-savings problem are contained within the class, reducing the chances of naming conflicts with other parts of the codebase. It also provides a clear boundary for the problem, making it easier to reason about and test.</p> </li> <li> <p>Code Reusability: Once we have defined the <code>ConSavProb</code> class, we can create multiple instances of it with different input parameters.</p> </li> <li> <p>Readability: Using a class can improve the readability of the code. </p> </li> </ol> <p>Overall, using a class to package the consumption-savings problem provides a clean, modular, and reusable solution that enhances code organization, abstraction, and readability.</p> <pre><code>class ConSavProb:\n    \"\"\"\n    A class representing a consumption-savings problem.\n\n    Attributes:\n        beta (float): The discount factor.\n        r (float): The interest rate.\n        y (float): The income.\n        omega (float): The initial endowment.\n        asset_path (numpy.ndarray): The path of assets over time.\n        a_guess (float): The initial guess for assets.\n        euler_error (float): The Euler equation error.\n        solved (bool): Indicates whether the problem has been solved.\n\n    Methods:\n        update_parameters: Update the parameters of the problem.\n        solve_asset_path: Solve the consumption-savings problem and compute the asset path.\n        plot_asset_path: Plot the asset path.\n\n    \"\"\"\n\n    def __init__(self, beta, r, y, omega):\n        \"\"\"\n        Initialize a ConSavProb object.\n\n        Args:\n            beta (float): The discount factor.\n            r (float): The interest rate.\n            y (float): The income.\n            omega (float): The probability of receiving income.\n\n        \"\"\"\n        self.beta = beta\n        self.r = r\n        self.y = y\n        self.omega = omega\n        self.asset_path = None\n        self.euler_error = None\n        self.solved = False\n\n    def update_parameters(self, beta=None, r=None, y=None, omega=None):\n        \"\"\"\n        Update the parameters of the problem.\n\n        Args:\n            beta (float, optional): The discount factor.\n            r (float, optional): The interest rate.\n            y (float, optional): The income.\n            omega (float, optional): The probability of receiving income.\n\n        \"\"\"\n        if beta is not None:\n            self.beta = beta\n        if r is not None:\n            self.r = r\n        if y is not None:\n            self.y = y\n        if omega is not None:\n            self.omega = omega\n\n    def solve_asset_path(self, a_guess=None):\n        \"\"\"\n        Solve the consumption-savings problem and compute the asset path.\n\n        Args:\n            a_guess (float): The initial guess for assets.\n\n        \"\"\"\n        if a_guess is None:\n            a_guess = np.zeros(len(self.y))\n\n        # solve\n        self.asset_path, self.euler_error, _ = newton(self.FOC, a_guess, maxiter=10_000)\n        self.solved = True\n\n    def FOC(self, a_choice):\n        beta, r, omega, y = self.beta, self.r, self.omega, self.y  # unpack the parameters\n        a = np.zeros((1+len(y))) # accommodate initial and terminal condition\n        a[0:-1] = a_choice\n\n        F = np.zeros(len(y))\n        F[0] = beta*(1+r) * ( 0 + omega * (1+r) - a[0] ) - ( y[0] + a[0]*(1+r) - a[1] )\n\n        for t in range(1, len(F)):\n            F[t] = beta*(1+r) * ( y[t-1] + a[t-1] * (1+r) - a[t] ) - ( y[t] + a[t]*(1+r) - a[t+1] )\n\n        return F\n\n    def plot_asset_path(self, figsize=(10, 6)):\n        \"\"\"\n        Plot the asset path.\n\n        Args:\n            figsize (tuple, optional): The figure size. Defaults to (10, 6).\n\n        \"\"\"\n        if self.solved == True:\n            # Plot the asset path\n            plt.figure(figsize=figsize)\n            plt.plot(np.concatenate([self.asset_path, [0.]]), marker='o', linestyle='-', color='b', markersize=5,\n                     linewidth=1)\n            plt.title('Asset Path in Consumption-Savings Problem')\n            plt.xlabel('Time Period')\n            plt.ylabel('Assets')\n            plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n            plt.axhline(0, color='black', linewidth=0.5)\n            plt.axvline(0, color='black', linewidth=0.5)\n            plt.tight_layout()\n            plt.show()\n</code></pre> <pre><code>model = ConSavProb(beta, r, y, omega)\nmodel.solve_asset_path(a_guess = np.full(10, 0))\n\nmodel.plot_asset_path(figsize=(7, 4))\n</code></pre> <pre><code>convergence achieved after 10 iterations\n</code></pre> <p></p> <pre><code>model.update_parameters(beta = 0.85)\nmodel.solve_asset_path(model.asset_path)\nmodel.plot_asset_path(figsize=(7, 4))\n</code></pre> <pre><code>convergence achieved after 30 iterations\n</code></pre> <p></p> <p>What, if income were decreasing from 6 to 1 over time, and we had T=20 periods instead?</p> <pre><code>model.update_parameters(y = np.linspace(6,0, 25), beta = 0.85)\nmodel.solve_asset_path()\nmodel.plot_asset_path(figsize=(7, 4))\n</code></pre> <pre><code>convergence achieved after 149 iterations\n</code></pre> <p></p>"},{"location":"courses/sem/4-optimization/#3-the-scipy-library-for-solving-and-optimization","title":"3. The <code>scipy</code> Library for Solving and Optimization","text":"<p>For more complex equations, including non-linear systems, Python\u2019s <code>scipy</code> library provides powerful tools. </p>"},{"location":"courses/sem/4-optimization/#1-basic-usage-of-scipyoptimize","title":"1. Basic Usage of <code>scipy.optimize</code>","text":""},{"location":"courses/sem/4-optimization/#example-finding-the-minimum-of-a-function","title":"Example: Finding the Minimum of a Function","text":"<pre><code>import numpy as np\nfrom scipy.optimize import minimize\n\n# Define the function to minimize\ndef f(x):\n    return x**2 + 5*np.sin(x)\n\n# Initial guess\nx0 = 2.0\n\n# Perform the minimization\nresult = minimize(f, x0)\n\nprint(\"Minimum value:\", result.fun)\nprint(\"At x =\", result.x)\n</code></pre> <pre><code>Minimum value: -3.2463942726915187\nAt x = [-1.11051058]\n</code></pre>"},{"location":"courses/sem/4-optimization/#2-solving-a-system-of-linear-equations","title":"2. Solving a System of Linear Equations","text":""},{"location":"courses/sem/4-optimization/#example-using-scipylinalgsolve","title":"Example: Using <code>scipy.linalg.solve</code>","text":"<pre><code>import numpy as np\nfrom scipy.linalg import solve\n\n# Coefficient matrix\nA = np.array([[3, 2], [1, 2]])\n\n# Right-hand side vector\nb = np.array([2, 0])\n\n# Solve the system\nx = solve(A, b)\n\nprint(\"Solution:\", x)\n</code></pre> <pre><code>Solution: [ 1.  -0.5]\n</code></pre>"},{"location":"courses/sem/4-optimization/#3-integration-using-scipyintegrate","title":"3. Integration using <code>scipy.integrate</code>","text":""},{"location":"courses/sem/4-optimization/#example-numerical-integration-with-quad","title":"Example: Numerical Integration with <code>quad</code>","text":"<pre><code>from scipy.integrate import quad\n\n# Define the function to integrate\ndef f(x):\n    return np.exp(-x**2)\n\n# Perform the integration\nresult, error = quad(f, 0, 1)\n\nprint(\"Integral result:\", result)\nprint(\"Estimated error:\", error)\n</code></pre> <pre><code>Integral result: 0.7468241328124271\nEstimated error: 8.291413475940725e-15\n</code></pre>"},{"location":"courses/sem/4-optimization/#4-interpolation-using-scipyinterpolate","title":"4. Interpolation using <code>scipy.interpolate</code>","text":""},{"location":"courses/sem/4-optimization/#example-1d-interpolation-with-interp1d","title":"Example: 1D Interpolation with <code>interp1d</code>","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import interp1d\n\n# Sample data points\nx = np.linspace(0, 10, 10)\ny = np.sin(x)\n\n# Create the interpolating function\nf = interp1d(x, y, kind='cubic')\n\n# Interpolated values\nx_new = np.linspace(0, 10, 100)\ny_new = f(x_new)\n\n# Plot the results\nplt.plot(x, y, 'o', label='data points')\nplt.plot(x_new, y_new, '-', label='cubic interpolation')\nplt.legend()\nplt.show()\n</code></pre> <p>These examples should give you a good starting point for using <code>scipy</code> in various scientific and technical computing tasks.</p>"},{"location":"courses/sem/5-endogenous_grid_method/","title":"Endogeneous Grid Method","text":"<p>In this notebook we discuss how to solve the household problem a la Aiyagari\u2013this is the main building block of most HANK models\u2013with fast, optimized methods. The main reference for this notebook is Matt Rognlie\u2019s code on which you can find in his repository (2024). The endogenous grid method was introduced by Carroll (2006).</p>"},{"location":"courses/sem/5-endogenous_grid_method/#1-incomplete-markets-model","title":"1. Incomplete Markets Model","text":"<p>The standard incomplete markets model features the following timing:</p> <ul> <li>begin of period with asset returns (1+r)a and stochastic income y.</li> <li>allocate to assets tomorrow a' and consumption today c</li> <li>all subject to a borrowing constraint a\\geq \\underline a and no ability to insure against idiosyncratic shocks: </li> </ul>   \\begin{align*}   V(y, a) = \\max_{c, a'} u( c ) + \\beta \\mathbb E[V(e', a') | y]  \\end{align*}    \\begin{align*}   s.t.\\; a' = (1+r)a + y - c  \\end{align*}    \\begin{align*}   a' \\geq \\underline a  \\end{align*}  <p>We model the income process as an AR(1), so    $$ y_t = \\rho y_{t-1} + e_t.$$   Since we would like to solve the whole model on a finite grid \\mathcal{Y} \\times \\mathcal{A} with indices (i_y, i_a), we need to discretize the income and the asset space. We already have functions to do this, applying the double-exponential grid space for assets, and the Rouwenhorst AR(1) process. </p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n# some useful plot defaults$\nplt.rcParams.update({'font.size' : 10, 'lines.linewidth' : 1.5, 'figure.figsize' : (4,3)})\n</code></pre> <p>Exercise: Write and import a class called <code>Grids</code> which if supplied the correct parameters outputs asset and income grids, as well as transition matrix and steady state for income.</p> <p>Solution: A script containing this and other classes (to be defined later in this document) can be found on my github. A non-maintained version is at the bottom of this notebook.</p> <pre><code>from utils_simm import Grid\n</code></pre> <pre><code>Grids = Grid(n_y = 10, rho = 0.975,  sd_log_y = 0.7, n_a = 100, min_a = 0, max_a = 10_000)\n</code></pre> <pre><code>the steady state is unique.\n</code></pre>"},{"location":"courses/sem/5-endogenous_grid_method/#2-backwards-iteration-to-obtain-policy-functions","title":"2. Backwards Iteration to Obtain Policy Functions","text":"<p>It is more efficient and accurate to use envelope condition and FOC to iterate on marginal value function V_a instead of finding the value function itself. We do backwards iteration in time. Let a_t'(y_t, a_t) be the policy function for next-period asset holdings. Assume that u(c) = \\frac{c^{1-\\sigma}}{1-\\sigma}, where \\sigma is the elasiticity of intertemporal substitution (eis).</p> <p>For backward iteration, we use the Envelope condition, $$ V_{a,t}(e, a) = (1+r_t)u\u2019(c_t(e, a))$$</p> <p>and the First-Order Condition (inequality binds if borrowing limit binds) </p> u'(c_t(y, a)) \\geq \\beta \\mathbb E [V_{a, t+1}(y', a_t'(y, a))]|e].  <p>repeatedly:</p> <p>[Algorithm: Backward iteration in time] </p> <p>Start at t = T, initialize V_{a, T} = 1. For t&lt; T: 1. Use V_{a, t+1} to calculate RHS of FOC 2. Solve for today\u2019s policies a_t'(y, a), c_t(y, a) 3. Using envelope condition, obtain marginal value function of today V_{a, t}</p> <p>We go through the steps in detail.</p>"},{"location":"courses/sem/5-endogenous_grid_method/#step-1-initialize-set-up-grids-and-parameters","title":"Step 1 - Initialize, Set up Grids and Parameters","text":"<pre><code>model_params = {\n    'beta' : 0.95,\n    'r' : 0.03,\n    'eis' : 1.5,\n    'rho' : 0.975,\n    'sd_log_y' : 0.7\n}\n\nGrids = Grid(n_y = 15, rho = model_params['rho'],  sd_log_y = model_params['sd_log_y'], n_a = 100, min_a = 0, max_a = 10_000)\n</code></pre> <pre><code>the steady state is unique.\n</code></pre> <pre><code># initial Va\nVa = np.ones((Grids.n_y, Grids.n_a))\n\nW = model_params['beta'] * Grids.Pi @ Va\n</code></pre>"},{"location":"courses/sem/5-endogenous_grid_method/#step-2-obtain-aprime_taprime_t-w_tw_t","title":"Step 2 - Obtain a^\\prime_{t}, W_{t}","text":"<p>We now write policy functions, marginal value function and associated objects as functions on the grid indices i_y and i_a whenever useful. We would like to solve for consumption policy using the FOC (assuming the constraint is slack) $$ u\u2019(c_t) = W_{a,t}(y, a\u2019) \\Rightarrow c_t = \\left( W_{a,t}(y, a\u2019) \\right)^{-1/\\sigma}$$ for each possible future asset level a'. Then we use the envelope condition and can obtain V_t(y, a), where a solves a' = (1+r)a + y - c_t(y, a').</p> <p>Problem: The implied a may not lie on the grid. Generally, we want V_{t, a}(y, a) for fixed values of a on the grid, not V_{t, a}(y, a(a')), where a(a') depends on the values of a'\\in \\mathcal{A}.</p> <p>Simple solution: For each fixed level of y\u2026</p> <ul> <li>Obtain the points c_t(y, a), store in <code>c_endog[i_y, :]</code> (these are also called \u2018endogeneous grid points\u2019)</li> <li>Compute (1+r)^{-1} (a' + c_t(y, a') - y) = a, and save the a vector as <code>a_endog[i_y,:]</code>. We now have essentially a function a(y, a')</li> <li>To invert for the policy function, a'(y, a), use linear interpolation evaluated at \\mathcal{A}: <code>np.interpolate(grid_a, a_endog[i_y,:], grid_a)</code></li> <li>Enforce the borrowing constraint by <code>a_prime = np.maximum(a_prime, Grids.grid_a[0])</code></li> </ul> <p>There is a slightly more efficient version of this algorithm using cash-on-hand. See Rognlie (2024).</p> <pre><code>c_endog = W ** (-1/model_params['eis'])\na_endog = (1 + model_params['r'])**(-1) * (Grids.grid_a[np.newaxis, :] - Grids.grid_y[:, np.newaxis] + c_endog)\na_prime = np.empty((Grids.n_y, Grids.n_a))\n\nfor i_y in range(Grids.n_y):\n    a_prime[i_y, :] = np.interp(Grids.grid_a, a_endog[i_y, :], Grids.grid_a)\n\n#a_prime = np.maximum(a_prime, Grids.grid_a[0]) # enforce borrowing constraint. actually not needed because interp already does this\n\n# obtain the consumption policy\nc = (1 + model_params['r']) * (Grids.grid_a[np.newaxis, :] + Grids.grid_y[:, np.newaxis]) - a_prime\n</code></pre> <p>We can look at the policy function after one iteration:</p> <pre><code># plot policy function\nfig, ax = plt.subplots()\nfor i_y in range(Grids.n_y):\n    ax.plot(Grids.grid_a[0:40], a_prime[i_y, 0:40], label = f'y = {Grids.grid_y[i_y]:.2f}')\nax.set(xlabel = r'$a$', ylabel = r'$a^{\\prime}$', title = 'Policy function after 1 iteration')\nplt.show()\n</code></pre> <p></p>"},{"location":"courses/sem/5-endogenous_grid_method/#step-3-obtain-v_t-av_t-a","title":"Step 3 - Obtain V_{t, a}","text":"<pre><code>V_a = (1 + model_params['r']) * c **(-1/model_params['eis']) # update value function derivative\n</code></pre>"},{"location":"courses/sem/5-endogenous_grid_method/#combine-steps-into-single-backward-iteration","title":"Combine Steps into single Backward Iteration","text":"<p>Now we write a function which takes as input a marginal value function, income and asset grids, preference parameters and transition matrices to compute a single backward iteration and output objects <code>V_a, a, c</code>.</p> <pre><code>def backward_iteration(V_a, beta, eis, r, grid_a, grid_y, Pi):\n\n    n_y, n_a = grid_y.size, grid_a.size\n    W = beta * Pi @ V_a\n\n    c_endog = W ** (-1/eis)\n    a_endog = (1 + r)**(-1) * (grid_a[np.newaxis, :] - grid_y[:, np.newaxis] + c_endog)\n    a_prime = np.empty((n_y, n_a))\n\n    for i_y in range(Grids.n_y):\n        a_prime[i_y, :] = np.interp(grid_a, a_endog[i_y, :], grid_a)\n\n    #a_prime = np.maximum(a_prime, Grids.grid_a[0]) # enforce borrowing constraint. actually not needed because interp already does this\n\n    # obtain the consumption policy\n    c = (1 + r) * (grid_a[np.newaxis, :] + grid_y[:, np.newaxis]) - a_prime\n\n    return c, a_prime\n\n# test the function\nc, a_prime = backward_iteration(V_a, model_params['beta'], model_params['eis'], model_params['r'], Grids.grid_a, Grids.grid_y, Grids.Pi)\n</code></pre> <p>And we can solve the entire household problem for steady-state policies.</p> <pre><code>grid_params = {\n    'n_y' : 7,\n    'n_a' : 500,\n    'min_a' : 0,\n    'max_a' : 10_000\n}\n\nmodel_params = {\n    'beta' : 1-0.08/4, # quarterly discount factor\n    'r' : 0.01/4, # quarterly interest rate\n    'eis' : 1,\n    'rho' : 0.975,\n    'sd_log_y' : 0.7\n}\n\nclass SteadyStateHH:\n\n    def __init__(self, model_params, grid_params, tol = 1e-6, max_iter = 1_000):\n        self.model_params = model_params\n        self.grid_params = grid_params\n        self.Grids = Grid(n_y = grid_params['n_y'], rho = model_params['rho'],  sd_log_y = model_params['sd_log_y'], n_a = grid_params['n_a'], min_a = grid_params['min_a'], max_a = grid_params['max_a'])\n        self.tol = tol\n        self.max_iter = max_iter\n        self.c = None\n        self.a_prime = None\n        self.V_a = None\n\n    def backward_iteration(self, V_a):\n\n        W = self.model_params['beta'] * self.Grids.Pi @ V_a\n\n        c_endog = W ** (-1/self.model_params['eis'])\n        a_endog = (1 + self.model_params['r'])**(-1) * (self.Grids.grid_a[np.newaxis, :] - self.Grids.grid_y[:, np.newaxis] + c_endog)\n        a_prime = np.empty((self.grid_params['n_y'], self.grid_params['n_a']))\n\n        for i_y in range(self.grid_params['n_y']):\n            a_prime[i_y, :] = np.interp(self.Grids.grid_a, a_endog[i_y, :], self.Grids.grid_a)\n\n        #a_prime = np.maximum(a_prime, self.Grids.grid_a[0]) \n\n        # obtain the consumption policy\n        c = (1 + self.model_params['r']) * (self.Grids.grid_a[np.newaxis, :] + self.Grids.grid_y[:, np.newaxis]) - a_prime\n\n        return c, a_prime\n\n    def solve_ss(self):\n\n        # initialize value function derivative with guess\n        if self.V_a is None:\n            V_a = np.ones((self.grid_params['n_y'], self.grid_params['n_a']))\n        else:\n            V_a = self.V_a\n\n        for i in range(self.max_iter):\n            c, a_prime = self.backward_iteration(V_a)\n            V_a_new = (1 + self.model_params['r']) * c **(-1/self.model_params['eis'])\n\n            if np.max(np.abs(V_a_new - V_a)) &lt; self.tol:\n                break\n\n            V_a = V_a_new\n\n        self.c = c\n        self.a_prime = a_prime\n        self.V_a = V_a\n\n        return c, a_prime\n\n    def plot_policy(self, bound_grid = 0.4):\n        \"\"\" \n        Plot the policy function for the first 4 income states\n        bound_grid: float, fraction of the grid to plot\n        \"\"\"\n        rng_asset_grid = int(grid_params['n_a']*bound_grid)\n        fig, ax = plt.subplots()\n        for i_y, y in enumerate(self.Grids.grid_y[0:4]):\n            ax.plot(self.Grids.grid_a[0:rng_asset_grid], self.c[i_y, 0:rng_asset_grid], label = f'y = {y:.2f}')\n        ax.set(xlabel = r'$a$', ylabel = r'$c(y,a)$', title = 'Steady State Policy Function')\n        plt.legend(fontsize = 'small')\n        plt.show()\n\nss = SteadyStateHH(model_params, grid_params)\nss.solve_ss()\nss.c, ss.a_prime\nss.plot_policy(0.2)\n</code></pre> <pre><code>the steady state is unique.\n</code></pre> <p></p> <p>Exercise: Refactor the code in order to use <code>@njit</code>.</p> <pre><code>from numba import njit\n\n@njit\ndef backward_iteration(V_a, beta, eis, r, grid_a, grid_y, Pi):\n    W = beta * Pi @ V_a\n\n    c_endog = W ** (-1/eis)\n    a_endog = (1 + r)**(-1) * (grid_a[np.newaxis, :] - grid_y[:, np.newaxis] + c_endog)\n    a_prime = np.empty((grid_y.shape[0], grid_a.shape[0]))\n\n    for i_y in range(grid_y.shape[0]):\n        a_prime[i_y, :] = np.interp(grid_a, a_endog[i_y, :], grid_a)\n\n    c = (1 + r) * (grid_a[np.newaxis, :] + grid_y[:, np.newaxis]) - a_prime\n\n    return c, a_prime\n\nclass SteadyStateHH:\n\n    def __init__(self, model_params, grid_params, tol = 1e-6, max_iter = 1_000):\n        self.model_params = model_params\n        self.grid_params = grid_params\n        self.Grids = Grid(n_y = grid_params['n_y'], rho = model_params['rho'],  sd_log_y = model_params['sd_log_y'], n_a = grid_params['n_a'], min_a = grid_params['min_a'], max_a = grid_params['max_a'])\n        self.tol = tol\n        self.max_iter = max_iter\n        self.c = None\n        self.a_prime = None\n        self.V_a = None\n\n    # adding the model_params as an argument allows solving for different parameterizations\n    def solve_ss(self, model_params):\n\n        # update grid if necessary\n        if (self.model_params['rho'], self.model_params['sd_log_y']) != (model_params['rho'], model_params['sd_log_y']):\n            self.Grids = Grid(n_y = self.grid_params['n_y'], rho = model_params['rho'],  sd_log_y = model_params['sd_log_y'], n_a = self.grid_params['n_a'], min_a = self.grid_params['min_a'], max_a = self.grid_params['max_a'])\n        # update model_params if necessary\n        if self.model_params != model_params:\n            self.model_params = model_params\n\n        # initialize value function derivative with guess\n        if self.V_a is None:\n            V_a = np.ones((self.grid_params['n_y'], self.grid_params['n_a']))\n        else:\n            V_a = self.V_a\n\n        for i in range(self.max_iter):\n            c, a_prime = backward_iteration(V_a, model_params['beta'], model_params['eis'], model_params['r'], self.Grids.grid_a, self.Grids.grid_y, self.Grids.Pi)\n            V_a_new = (1 + model_params['r']) * c **(-1/model_params['eis'])\n\n            if np.max(np.abs(V_a_new - V_a)) &lt; self.tol:\n                break\n\n            V_a = V_a_new\n\n        self.c = c\n        self.a_prime = a_prime\n        self.V_a = V_a\n\n        return c, a_prime\n\n    def plot_policy(self, bound_grid = 0.4):\n        \"\"\" \n        Plot the policy function for the first 4 income states\n        bound_grid: float, fraction of the grid to plot\n        \"\"\"\n        rng_asset_grid = int(grid_params['n_a']*bound_grid)\n        fig, ax = plt.subplots()\n        for i_y, y in enumerate(self.Grids.grid_y[0:4]):\n            ax.plot(self.Grids.grid_a[0:rng_asset_grid], self.c[i_y, 0:rng_asset_grid], label = f'y = {y:.2f}')\n        ax.set(xlabel = r'$a$', ylabel = r'$c(y,a)$', title = 'Steady State Policy Function')\n        plt.legend(fontsize = 'small')\n        plt.show()\n</code></pre> <pre><code>ss = SteadyStateHH(model_params, grid_params)\nss.solve_ss(model_params=ss.model_params)\nss.c, ss.a_prime\nss.plot_policy(0.2)\n</code></pre> <pre><code>the steady state is unique.\n</code></pre> <p></p> <pre><code>ss = SteadyStateHH(model_params, grid_params)\nss.solve_ss(model_params=ss.model_params)\n</code></pre> <pre><code>the steady state is unique.\n\n\n\n\n\n(array([[1.41722822e-01, 1.46412415e-01, 1.50292317e-01, ...,\n         1.86182818e+02, 1.94981292e+02, 2.04215800e+02],\n        [2.50991933e-01, 2.55681526e-01, 2.60415096e-01, ...,\n         1.86403939e+02, 1.95202357e+02, 2.04436700e+02],\n        [4.44508157e-01, 4.49197750e-01, 4.53931320e-01, ...,\n         1.86684758e+02, 1.95483026e+02, 2.04717044e+02],\n        ...,\n        [1.34562866e+00, 1.34617631e+00, 1.34672238e+00, ...,\n         1.87539703e+02, 1.96337168e+02, 2.05569687e+02],\n        [2.11335992e+00, 2.11362938e+00, 2.11390126e+00, ...,\n         1.88211194e+02, 1.97007799e+02, 2.06238802e+02],\n        [3.17854812e+00, 3.17874042e+00, 3.17893450e+00, ...,\n         1.89156862e+02, 1.97952041e+02, 2.07180594e+02]]),\n array([[0.00000000e+00, 0.00000000e+00, 8.53668052e-04, ...,\n         8.93360537e+03, 9.36572181e+03, 9.82092592e+03],\n        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n         8.93349352e+03, 9.36561001e+03, 9.82081429e+03],\n        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n         8.93340622e+03, 9.36552286e+03, 9.82072746e+03],\n        ...,\n        [4.85540026e-02, 5.26959516e-02, 5.68834457e-02, ...,\n         8.93350095e+03, 9.36561839e+03, 9.82082450e+03],\n        [3.55745601e-01, 3.60165727e-01, 3.64627417e-01, ...,\n         8.93390438e+03, 9.36602268e+03, 9.82123030e+03],\n        [1.19425196e+00, 1.19874925e+00, 1.20328874e+00, ...,\n         8.93486241e+03, 9.36698214e+03, 9.82219221e+03]]))\n</code></pre>"},{"location":"courses/sem/5-endogenous_grid_method/#3-forward-iteration-to-obtain-distribution","title":"3. Forward Iteration to Obtain Distribution","text":"<p>With steady-state policies at hand, we can compute the distribution of next-period asset holdings, D_{t+1}(y, a) given the current distribution D_t. Assume for a moment that a' maps assets on the grid \\mathcal A. Then </p> D_{t+1}(y, a) = \\sum_{\\bar y \\in \\mathcal Y} \\sum_{\\bar a \\in \\mathcal A} D_{t}(\\bar y, \\bar a) \\mathbb P(\\bar y | y) \\mathbb I(a'(\\bar y, \\bar a) = a)  <p>Problem: a'(e, a) does not map into \\mathcal A. Possible solution: Lotteries.</p> <p>Basic idea is that if a'(e, a) = a' \\in [a_i, a_{i+1}] for two consecutive grid points a_i, a_{i+1}, then a fraction q(y, a) = \\frac{a_{i+1} - a'}{a_{i+1} - a_{i}} of the population lands on the lower gridpoint.</p> <p>Let a^+ be the next highest grid point on the asset grid, and a^- the next lowest. </p> \\begin{align} D_{t+1}(y, a) &amp;= \\sum_{\\bar y \\in \\mathcal Y} \\sum_{\\bar a \\in \\mathcal A} D_{t}(\\bar y, \\bar a) \\mathbb P(\\bar y | y) \\underbrace{\\left[ \\mathbb I(a'(\\bar y, \\bar a)^+ = a) \\frac{ a' - a^-}{a^+ - a^-} + \\mathbb I(a'(\\bar y, \\bar a)^- = a) \\frac{ a^+ - a'}{a^+ - a^-} \\right]}_{\\equiv \\mu( \\bar y, \\bar a, a)} \\\\ &amp;= \\sum_{\\bar y \\in \\mathcal Y} \\sum_{\\bar a \\in \\mathcal A} D_{t}(\\bar y, \\bar a) \\mu( \\bar y, \\bar a, a) \\mathbb P(\\bar y | y) \\\\ &amp;= \\sum_{\\bar y \\in \\mathcal Y}  \\mathbb P(\\bar y | y) \\sum_{\\bar a \\in \\mathcal A} D_{t}(\\bar y, \\bar a) \\mu( \\bar y, \\bar a, a)  \\end{align} <p>We can pre-compute the lottery array \\mu to handle the forward iteration. Still, this approach is very inefficient.</p> <p>Exercise: Explain what is so inefficient about our approach?</p> <p>Exercise: Write a function to compute <code>mu</code></p> <pre><code># Inefficient way to compute lotteries\n@njit\ndef get_mu(policy, grid_a, grid_y):\n\n    assert (policy - grid_a.max()).max() &lt;= 0 and (policy - grid_a.min()).min() &gt;= 0 # make sure policy is within bounds of grid_a\n\n    n_a = np.shape(grid_a)[0]\n    n_y = np.shape(grid_y)[0]\n    mu = np.zeros((n_y, n_a, n_a), dtype=np.float64)\n    for index_a in range(len(grid_a)):\n        for index_a_bar in range(len(grid_a)):\n            for index_y_bar in range(len(grid_y)):\n\n                if (grid_a[index_a] &gt;= policy[index_y_bar, index_a_bar]) and (grid_a[index_a - 1] &lt;= policy[index_y_bar, index_a_bar]) :\n                    p_plus = (policy[index_y_bar, index_a_bar] - grid_a[index_a - 1]) / (grid_a[index_a] - grid_a[index_a-1])\n                    mu[index_y_bar, index_a_bar, index_a]   += p_plus \n                    continue\n\n                if (grid_a[index_a] &lt;= policy[index_y_bar, index_a_bar]) and (grid_a[index_a + 1] &gt;= policy[index_y_bar, index_a_bar]) :\n                    p_minus = (grid_a[index_a + 1] - policy[index_y_bar, index_a_bar]) / (grid_a[index_a+1] - grid_a[index_a])\n                    mu[index_y_bar, index_a_bar, index_a]   += p_minus \n                    continue\n\n    return mu\n\nmu = get_mu(ss.a_prime, ss.Grids.grid_a, ss.Grids.grid_y)\n\n%timeit get_mu(ss.a_prime, ss.Grids.grid_a, ss.Grids.grid_y)\n</code></pre> <pre><code>1.86 ms \u00b1 27.2 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 1,000 loops each)\n</code></pre> <p>Instead, consider where the mass of D_t(y, a) is sent to. For y fixed, D_t(y, a) \\dfrac{a'(y, a) - a'(y, a)^-}{a'(y, a)^+ - a'(y, a)^-} = D_t(y, a) q(y, a) is sent to a'(y, a)^+ and D_t(y, a) (1-q(y, a)) is sent to a'(y, a)^-. Proceeding over all (y, a), we obtain \\tilde D_t(\\cdot, \\cdot), the distribution after asset choices were made and before income shocks realized.</p> <p>We now write a function to obtain the q (the lotteries) and the indices of a'(y, a)^+, where the masses in the distribution are sent to. Once we got <code>q</code> and <code>indexes</code>, we can use these objects in every forward iteration on D_t.</p> <pre><code>def get_lotteries(policy, grid_a):\n\n    indexes = np.searchsorted(grid_a, policy) # indexes corresponding to a'(y, a)+  (function returns i with a[i-1] &lt; v &lt;= a[i])\n    q = (policy - grid_a[indexes - 1]) / (grid_a[indexes] - grid_a[indexes - 1]) # lotteries\n    return indexes, q\n\n# forward iteration\n@njit\ndef forward_iteration(indexes, q, Pi, D):\n    n_y, n_a = D.shape\n    D_new = np.zeros((n_y, n_a))\n    for y in range(n_y):\n        for a in range(n_a):\n\n            D_new[y, indexes[y, a]]   += q[y, a] * D[y, a]\n            D_new[y, indexes[y, a]-1]     += (1 - q[y, a]) * D[y, a]\n\n    # D_new is D_tilde right now. Now we need to update D_tilde using Pi\n    D_new = Pi @ D_new\n\n    return D_new\n</code></pre> <p>Note that, when calculating <code>D_new = Pi @ D_new</code>, row i_y corresponding to state y will hold the vector </p>  [\\Pi \\tilde D]_{i_y} = (\\pi(i_y, 1), ...,\\pi(i_y, n_y)) \\tilde D = [\\pi(i_y, 1)\\tilde D(1, i_a) + ... +\\pi(i_y, n_y)\\tilde D(n_y, i_a)]_{i_a =1,...,n_a}.  <p>Finally, we compute the steady state distribution by iterating until convergence:</p> <pre><code>def distribution_ss(Pi, policy, grid_a, maxiter=10_000, tol=1E-10, verbose=False):\n\n    indexes, q = get_lotteries(policy, grid_a)\n\n    # initialize distribution\n    D = np.ones_like(policy)/np.size(policy)\n\n    count, error = 0, 1\n    while error &gt; tol and count &lt; maxiter:\n        D_new = forward_iteration(indexes, q, Pi, D)\n        error = np.max(np.abs(D - D_new))\n        D = D_new.copy()\n        count += 1\n\n\n    if verbose : \n        print(\"max |D_t - D_t+1| = \", error, \"\\nnum iterations:\", count)\n\n    return D\n</code></pre> <pre><code>D_ss = distribution_ss(ss.Grids.Pi, ss.a_prime, ss.Grids.grid_a, maxiter=1000, tol=1E-10, verbose=True)\n# check how long it takes\n%time distribution_ss(ss.Grids.Pi, ss.a_prime, ss.Grids.grid_a, maxiter=1000, tol=1E-10, verbose=True)\n</code></pre> <pre><code>max |D_t - D_t+1| =  9.662340372251776e-11 \nnum iterations: 536\nmax |D_t - D_t+1| =  9.662340372251776e-11 \nnum iterations: 536\nCPU times: user 7.77 ms, sys: 33 \u00b5s, total: 7.8 ms\nWall time: 7.72 ms\n\n\n\n\n\narray([[1.40918274e-001, 1.12836882e-004, 7.66408375e-005, ...,\n        4.63400194e-114, 6.22448773e-116, 4.23457364e-118],\n       [1.38212429e-001, 2.53033570e-004, 1.90803709e-004, ...,\n        4.61175517e-114, 6.19620063e-116, 4.21646007e-118],\n       [1.29247539e-001, 6.69139940e-004, 5.20800102e-004, ...,\n        4.61134519e-114, 6.19614397e-116, 4.21685452e-118],\n       ...,\n       [4.76938191e-003, 8.11450720e-005, 5.90862252e-005, ...,\n        4.73711752e-114, 6.35938753e-116, 4.32452420e-118],\n       [1.49636758e-004, 2.56112858e-006, 1.86456018e-006, ...,\n        4.92295035e-114, 6.59920835e-116, 4.48156752e-118],\n       [3.77194925e-006, 6.47532936e-008, 4.71375717e-008, ...,\n        5.27257915e-114, 7.04886178e-116, 4.77491899e-118]])\n</code></pre>"},{"location":"courses/sem/5-endogenous_grid_method/#using-the-steadystatehh-module","title":"Using the SteadyStateHH Module","text":"<p>Exercise: Add the computation of steady state D to the <code>SteadyStateHH</code> class. Import it from another file and run it.</p> <p>Note: restart the kernel before re-importing the classes. </p> <pre><code>from utils_simm import *\n\ngrid_params = {\n    'n_y' : 7,\n    'n_a' : 500,\n    'min_a' : 0,\n    'max_a' : 10_000\n}\n\nmodel_params = {\n    'beta' : 1-0.08/4, # quarterly discount factor\n    'r' : 0.01/4, # quarterly interest rate\n    'eis' : 1,\n    'rho' : 0.975,\n    'sd_log_y' : 0.7\n}\n\nprint(model_params, \"\\n\",grid_params, sep=\"\")\n# create steady state object\nss = SteadyStateHH(model_params, grid_params)\n</code></pre> <pre><code>{'beta': 0.98, 'r': 0.0025, 'eis': 1, 'rho': 0.975, 'sd_log_y': 0.7}\n{'n_y': 7, 'n_a': 500, 'min_a': 0, 'max_a': 10000}\nthe steady state is unique.\n</code></pre> <pre><code># solve for steady state\nss.solve_ss(ss.model_params)\n\nss.distribution_ss()\n</code></pre> <pre><code>array([[1.40918274e-001, 1.12836882e-004, 7.66408375e-005, ...,\n        4.63400194e-114, 6.22448773e-116, 4.23457364e-118],\n       [1.38212429e-001, 2.53033570e-004, 1.90803709e-004, ...,\n        4.61175517e-114, 6.19620063e-116, 4.21646007e-118],\n       [1.29247539e-001, 6.69139940e-004, 5.20800102e-004, ...,\n        4.61134519e-114, 6.19614397e-116, 4.21685452e-118],\n       ...,\n       [4.76938191e-003, 8.11450720e-005, 5.90862252e-005, ...,\n        4.73711752e-114, 6.35938753e-116, 4.32452420e-118],\n       [1.49636758e-004, 2.56112858e-006, 1.86456018e-006, ...,\n        4.92295035e-114, 6.59920835e-116, 4.48156752e-118],\n       [3.77194925e-006, 6.47532936e-008, 4.71375717e-008, ...,\n        5.27257915e-114, 7.04886178e-116, 4.77491899e-118]])\n</code></pre>"},{"location":"courses/sem/5-endogenous_grid_method/#the-result-utils_simmpy","title":"The result: utils_simm.py","text":"<p>For reference, here is the code for the standard incomplete markets module which we have developed in this notebook.</p> <pre><code>import numpy as np\n\n\nclass Grid:\n\n    def __init__(self, n_y, rho, sd_log_y, n_a, min_a, max_a):\n        self.n_y = n_y\n        self.rho = rho\n        self.sd_log_y = sd_log_y\n        self.n_a = n_a\n        self.min_a = min_a\n        self.max_a = max_a\n        self.Pi, self.grid_y = self.rouwenhorst(n_y, rho, sd_log_y)\n        self.pi_ss = self.stationary_dist(self.Pi)[0,:]\n        self.grid_y = self.normalize_y(self.grid_y, self.pi_ss)\n        self.grid_a = self.discretize_assets(min_a, max_a, n_a)\n\n    # sigma is the sd of the error, e_t\n    def rouwenhorst(self, n, rho, sd_log_y):\n\n        # the grid    \n        e = np.arange(n) # sd of e on this grid with Pi is sqrt(n-1)/2\n        e = e / ( (n-1)**0.5 /2 ) # now its unit sd\n        e = e * sd_log_y # now it's the sd of the cross section of log_y\n\n        # the transition matrix\n        p = (1+rho)/2\n        Pi = np.array([[p, 1-p], [1-p, p]])\n\n        while Pi.shape[0] &lt; n:\n            Pi_next = np.zeros((1+Pi.shape[0], 1+Pi.shape[1]))\n            Pi_next[0:Pi.shape[0], 0:Pi.shape[1]] += Pi * p\n            Pi_next[0:Pi.shape[0], -Pi.shape[1]:] += Pi * (1-p)\n            Pi_next[-Pi.shape[0]:, -Pi.shape[1]:] += Pi * p\n            Pi_next[-Pi.shape[0]:, 0:Pi.shape[1]] += Pi * (1-p)\n            Pi_next[1:-1, :] /= 2\n            Pi = Pi_next\n\n        return Pi, e\n\n    def stationary_dist(self, Pi):\n        Pi_stationary = Pi.copy()\n        eps = 1\n        while eps &gt; 10E-12:\n            Pi_old = Pi_stationary.copy()\n            Pi_stationary = Pi_stationary @ Pi_stationary\n            eps = np.max(np.abs(Pi_stationary - Pi_old))\n\n        if np.max(\n                np.abs( \n                    np.sum(Pi_stationary - Pi_stationary,axis = 0) / Pi_stationary.shape[0]\n                )\n            ) &lt; 10E-10:\n            print(\"the steady state is unique.\")\n\n        return Pi_stationary\n\n    def normalize_y(self, log_y, pi_ss): # make y have unit mean\n        y = np.exp(log_y)\n        y = y / np.vdot(y, pi_ss)\n        return y\n\n\n    # write a function which discretizes the asset space\n    def discretize_assets(self, amin, amax, n_a):\n        # find ubar \n        ubar = np.log(np.log(amax - amin + 1)+1)\n        # make linar grid for the u's\n        grid_u = np.linspace(0,ubar, n_a)\n        # transform back to a\n        grid_a = amin + np.exp(np.exp(grid_u)-1)-1\n        return grid_a\n\n\nfrom numba import njit\n\n@njit\ndef backward_iteration(V_a, beta, eis, r, grid_a, grid_y, Pi):\n    W = beta * Pi @ V_a\n\n    c_endog = W ** (-1/eis)\n    a_endog = (1 + r)**(-1) * (grid_a[np.newaxis, :] - grid_y[:, np.newaxis] + c_endog)\n    a_prime = np.empty((grid_y.shape[0], grid_a.shape[0]))\n\n    for i_y in range(grid_y.shape[0]):\n        a_prime[i_y, :] = np.interp(grid_a, a_endog[i_y, :], grid_a)\n\n    c = (1 + r) * (grid_a[np.newaxis, :] + grid_y[:, np.newaxis]) - a_prime\n\n    return c, a_prime\n\ndef get_lotteries(policy, grid_a):\n\n    indexes = np.searchsorted(grid_a, policy) # indexes corresponding to a'(y, a)+  (function returns i with a[i-1] &lt; v &lt;= a[i])\n    q = (policy - grid_a[indexes - 1]) / (grid_a[indexes] - grid_a[indexes - 1]) # lotteries\n    return indexes, q\n\n# forward iteration\n@njit\ndef forward_iteration(indexes, q, Pi, D):\n    n_y, n_a = D.shape\n    D_new = np.zeros((n_y, n_a))\n    for y in range(n_y):\n        for a in range(n_a):\n\n            D_new[y, indexes[y, a]]   += q[y, a] * D[y, a]\n            D_new[y, indexes[y, a]-1]     += (1 - q[y, a]) * D[y, a]\n\n    # D_new is D_tilde right now. Now we need to update D_tilde using Pi\n    D_new = Pi @ D_new\n\n    return D_new\n\nclass SteadyStateHH:\n\n    def __init__(self, model_params, grid_params, tol = 1e-6, max_iter = 1_000):\n        self.model_params = model_params\n        self.grid_params = grid_params\n        self.Grids = Grid(n_y = grid_params['n_y'], rho = model_params['rho'],  sd_log_y = model_params['sd_log_y'], n_a = grid_params['n_a'], min_a = grid_params['min_a'], max_a = grid_params['max_a'])\n        self.tol = tol\n        self.max_iter = max_iter\n        self.c = None\n        self.a_prime = None\n        self.V_a = None\n        self.D = None\n\n    # adding the model_params as an argument allows solving for different parameterizations\n    def solve_ss(self, model_params):\n\n        # update grid if necessary\n        if (self.model_params['rho'], self.model_params['sd_log_y']) != (model_params['rho'], model_params['sd_log_y']):\n            self.Grids = Grid(n_y = self.grid_params['n_y'], rho = model_params['rho'],  sd_log_y = model_params['sd_log_y'], n_a = self.grid_params['n_a'], min_a = self.grid_params['min_a'], max_a = self.grid_params['max_a'])\n        # update model_params if necessary\n        if self.model_params != model_params:\n            self.model_params = model_params\n\n        # initialize value function derivative with guess\n        if self.V_a is None:\n            V_a = np.ones((self.grid_params['n_y'], self.grid_params['n_a']))\n        else:\n            V_a = self.V_a\n\n        for i in range(self.max_iter):\n            c, a_prime = backward_iteration(V_a, model_params['beta'], model_params['eis'], model_params['r'], self.Grids.grid_a, self.Grids.grid_y, self.Grids.Pi)\n            V_a_new = (1 + model_params['r']) * c **(-1/model_params['eis'])\n\n            if np.max(np.abs(V_a_new - V_a)) &lt; self.tol:\n                break\n\n            V_a = V_a_new\n\n        self.c = c\n        self.a_prime = a_prime\n        self.V_a = V_a\n\n        return c, a_prime\n\n    def distribution_ss(self, maxiter=10_000, tol=1E-10, verbose=False):\n\n        assert self.a_prime is not None, \"solve_ss must be called first\"\n\n        Pi = self.Grids.Pi\n        grid_a = self.Grids.grid_a\n        policy = self.a_prime\n\n        indexes, q = get_lotteries(policy, grid_a)\n\n        # initialize distribution\n        D = np.ones_like(policy)/np.size(policy)\n\n        count, error = 0, 1\n        while error &gt; tol and count &lt; maxiter:\n            D_new = forward_iteration(indexes, q, Pi, D)\n            error = np.max(np.abs(D - D_new))\n            D = D_new.copy()\n            count += 1\n\n\n        if verbose : \n            print(\"max |D_t - D_t+1| = \", error, \"\\nnum iterations:\", count)\n\n        self.D = D\n\n        return D\n\n    def plot_policy(self, bound_grid = 0.4):\n        \"\"\" \n        Plot the policy function for the first 4 income states\n        bound_grid: float, fraction of the grid to plot\n        \"\"\"\n        rng_asset_grid = int(grid_params['n_a']*bound_grid)\n        fig, ax = plt.subplots()\n        for i_y, y in enumerate(self.Grids.grid_y[0:4]):\n            ax.plot(self.Grids.grid_a[0:rng_asset_grid], self.c[i_y, 0:rng_asset_grid], label = f'y = {y:.2f}')\n        ax.set(xlabel = r'$a$', ylabel = r'$c(y,a)$', title = 'Steady State Policy Function')\n        plt.legend(fontsize = 'small')\n        plt.show()\n</code></pre>"},{"location":"cv/cv/","title":"curriculum vitae [w/o publications]","text":""},{"location":"cv/cv/#employment","title":"Employment","text":"<p>Doktorand (PhD) \u2014 University of Z\u00fcrich (UZH) Z\u00fcrich, CH PhD Student at the Zurich Graduate School of Economics Advisor: Prof. Florian Scheuer Aug. 2021 \u2013 today</p> <ul> <li>Long-Term Research Vistis: London School of Economics (Aug. 2024 \u2013 Jan. 2025), De Nederlandsche Bank (Apr. 2025 \u2013 Aug. 2025), Paris School of Economics (planned in 2026)</li> <li>Teaching: Macroeconomics (PhD), Programming Practices for Research Students (PhD), Advanced Statistics (MSc)</li> <li>Other:<ul> <li>Specialized coursework: Recursive Methods, Macro-Finance, Public Finance (UZH), Advanced Machine Learning (ETH Z\u00fcrich)</li> <li>Workshops: Dynamic Structural Econometrics (Lausanne, 2023), Heterogeneous Agents Macroeconomics (by Auclert, Rognlie, Straub) (Frankfurt, 2024)</li> </ul> </li> </ul> <p> Research Specialist \u2014 University of Chicago Chicago (IL), US Researcher at the Center of the Economics of Human Development Sep. 2019 \u2013 Jul. 2021</p> <ul> <li>Research specialist in public sector research projects for James J. Heckman at the University of Chicago.</li> <li>Statistical life-cycle evaluation of economic costs and benefits of a childhood education programme.</li> </ul> <p> Research Assistant \u2014 Center for Economic Studies (CESifo) Munich, DE Research assistant at the Center for Macroeconomics and Surveys (Prof. Andreas Peichl) Jul. 2018 \u2013 Sep. 2018</p> <p> Intern \u2014 KPMG Corporate Valuation Services and Consulting D\u00fcsseldorf/Cologne, DE Company evaluation projects Mar. 2016 \u2013 May 2016</p> <ul> <li>Evaluation of non-listed companies using DCF and WACC, joined KPMG HighQ talent pool.</li> </ul>"},{"location":"cv/cv/#education","title":"Education","text":"<p>University of Cambridge (Trinity Hall) Cambridge, UK MPhil in Economic Research and Advanced Diploma in Economics Sep. 2017 \u2013 Jul. 2019</p> <ul> <li>Graduated MPhil with high distinction and award (GPA: 79/100), and Diploma best in class (1/25), with distinction and award (GPA: 74/100).</li> <li>Specialization in time-series statistics, MPhil dissertation in econometrics (Professor Oliver B. Linton)</li> </ul> <p> London School of Economics London, UK Mathematics; General Course Programme (Year abroad) Sep. 2016 \u2013 Jun. 2017 </p> <ul> <li>GPA: 79/100, distinction level.</li> </ul> <p> University of M\u00fcnster M\u00fcnster, DE BSc. in Business Administration Apr. 2013 \u2013 Sep. 2016</p> <ul> <li>Graduated top 5% of year, specialization &amp; thesis in asset pricing, corporate finance, financial accounting.</li> </ul>"},{"location":"cv/cv/#awards-and-honors","title":"Awards and Honors","text":"<p>Doc.Mobility Studentship Z\u00fcrich, CH Award for an outstanding research project to be pursued abroad (LSE), CHF 30,000 2024</p> <p> Bateman Scholar Cambridge, UK Awarded by Trinity Hall (Cambridge college) for outstanding performance in an M.Phil. programme, \u00a3425 2021</p> <p> Awarded Cambridge Trust Scholar &amp; Trinity Hall Research Studentship Cambridge, UK Total award of \u00a333,115 (full stipend for MPhil degree, including cost of living) 2018\u20132019</p> <p> Stevenson Prize Cambridge, UK Award for best overall performance in the Advanced Diploma in Economics, \u00a3500 2018</p>"},{"location":"research/research/","title":"working papers, projects, publications","text":"<p>macroeconomics</p> <ul> <li> <p>Not-So-Cleaning Recessions      Igli Bajo, Frederik H. Bennhoff, Alessandro Ferrari  draft in preparation Conferences: SED Annual Meeting 2025 (F. Bennhoff); ESADE Macro Meetings (A. Ferrari)</p> Summary <p> Recessions are periods in which the least productive firms in the economy exit, and as the economy recovers, they are replaced by new and more productive entrants. These cleansing effects imply that business cycles generate improvements in the average firm productivity. We argue that this is not sufficient to induce long-run gains in GDP and welfare. We show that these are driven by the intensity of love-for-variety in aggregate production. It turns out that CES is the only HSA aggregator for which TFP are always the same before and after the crisis. Assuming that the household has CES preferences, recessions do not bring about any improvement in GDP and TFP. If the economy features an additional, positive love-for-variety externality, the social planner finds it optimal to subsidize economic activity in recessions to avoid firm exit. In an empirical exercise, we find that this is externality is indeed present. We plug out estimates into a quantitative model. We find that optimal policy can improve steady state output by 65%, and that a policy maker would have found it optimal to subsidize fixed cost heavily during the great financial crisis. </p> </li> <li> <p>The Competition Channel of Skewness      Frederik H. Bennhoff, Timo Haber, Niklas Schmitz  draft in preparation </p> Summary <p> Firm growth rates in times of crisis take are strongly negatively skewed (left-skewed), cf. Salgado et al (2019). Examining the Compustat universe of firms, we find that this pro-cyclical left-skew is concentrated on very largest companies in the market. Smaller firms exhibit much less skewness in growth rates when hit by adverse shocks. Furthermore, using a factor decomposition, we show that not the shocks themselves, but rather the reactions of firms to shocks exhibit skewness. We rationalize these observation in a simple framework of a profit maximizing firm. A version of Marshall\u2019s second law of demand implies that price setting firms react to shocks with left-skewed output growth rates, while price taking firms respond symmetrically. Furthermore, left-skewness is increasing in the degree of market power and in the standard deviation of the shock. In light of our model, left-skewed downside risk is not a consequence of scary disaster shocks, but the result of monopolization and market power. </p> </li> </ul> <p>(public) finance </p> <ul> <li> <p>Capital Gains Taxation in Life and Death      Frederik H. Bennhoff, Florian Scheuer  work in progress Conferences: Taxing Billionaires (2025) @ Paris School of Economics (F. Bennhoff)</p> Summary <p> End-of-life provisions determine the tax base of capital gains, when assets are bequeathed. Up until today, there existed no quantitative model to simulate the effects of changing end-of-life provisions, which jointly takes into account the reactions of households at two margins: (1) composition of the asset portfolio and (2) total size of the bequeathed estate. We build a novel, unifying framework in which one can simulate the consequences of different end-of-life provisions, bequest taxes and other income taxes simultaneously, thereby surpassing the current state-of-the-art at several margins. We do so by recasting the definition of asset portfolios, which makes the household problem theoretically and quantitatively tractable. </p> </li> <li> <p>Portfolios, and the Taxation of Capital Gains      Frederik H. Bennhoff (Job Market Paper)  work in progress </p> </li> <li> <p>Who Gains from Capital Gains?      Frederik Bennhoff, Moritz Kuhn, Lorenzo Ranaldi, Florian Scheuer  work in progress </p> </li> </ul> <p>other publications</p> <ul> <li> <p>The dynastic benefits of early-childhood education: participant benefits and family spillovers      Frederik H. Bennhoff, Jorge L. Garcia, Duncan Ermini Leaf  Journal of Human Capital 18 (1), 44-73 </p> Summary <p> We demonstrate the social efficiency of investing in high-quality early-childhood education using newly collected data from the HighScope Perry Preschool Project. The data analyzed are the longest follow-up of any randomized early-childhood education program. Annual observations of participant outcomes up to midlife allow us to provide a cost-benefit analysis without relying on forecasts. Adult outcomes on the participants\u2019 children and siblings allow us to quantify spillover benefits. The program generates a benefit-cost ratio of 6.0 (p-value .03). Spillover benefits increase this ratio to 7.5 (p-value = 0.00). </p> </li> </ul>"}]}